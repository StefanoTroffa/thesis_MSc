{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf6bd74",
   "metadata": {},
   "source": [
    "## This is the most clear cut version of the notebook for illustrative purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4497116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import compgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b08ed5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 19:17:10.204137: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-16 19:17:14.109059: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-16 19:17:14.109279: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-03-16 19:17:14.109289: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import networkx as nx\n",
    "from graph_nets import utils_np, utils_tf\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from graph_nets import utils_np\n",
    "from graph_nets import utils_tf\n",
    "from graph_nets import graphs\n",
    "from graph_nets.demos_tf2 import models\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix, eye\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.sparse import kron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e6213ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef process_batch(batch):\\n    graph_tuple, gnn, N_sweeps = batch\\n    return monte_carlo_update(graph_tuple, gnn, N_sweeps)\\n\\nif __name__ == '__main__':\\n    # Prepare your batches (replace this with your actual batches)\\n    batches = [(graph_tuple_1, gnn, N_sweeps), (graph_tuple_2, gnn, N_sweeps), ...]\\n\\n    # Create a pool of workers\\n    with Pool(processes=4) as pool:  # Adjust the number of processes as needed\\n        results = pool.map(process_batch, batches)\\n#updated_graph_tuples = parallel_monte_carlo_update(graph_tuples, gnn, 9)\\nprint(updated_graph_tuples[0].nodes)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def monte_carlo_update(graph_tuple, gnn, N_sweeps):\n",
    "    \"\"\"Perform N_sweeps Monte Carlo updates on a single graph tuple and its corresponding configuration.\"\"\"\n",
    "    for _ in range(N_sweeps):\n",
    "        # Propose a new graph tuple\n",
    "        proposed_nodes = graph_tuple.nodes.numpy().copy()  # Convert to numpy array for mutability\n",
    "        i = np.random.randint(len(proposed_nodes))  # Choose a random node\n",
    "        proposed_nodes[i, 0] *= -1  # Flip the spin at this node\n",
    "\n",
    "        # Create a new graph tuple with the proposed nodes\n",
    "        proposed_graph_tuple = graph_tuple.replace(nodes=tf.constant(proposed_nodes))\n",
    "\n",
    "        # Calculate the acceptance probability\n",
    "        psi_old = gnn(graph_tuple)[0][0]\n",
    "        psi_new = gnn(proposed_graph_tuple)[0][0]\n",
    "        p_accept = min(1, np.abs(psi_new / psi_old)**2)\n",
    "\n",
    "        # Accept or reject the new graph tuple\n",
    "        if np.random.rand() < p_accept:\n",
    "            graph_tuple = proposed_graph_tuple\n",
    "            \n",
    "            # Update the corresponding configuration\n",
    "            value = 0\n",
    "            for j in range(len(proposed_nodes)):\n",
    "                b = int(-1 * (proposed_nodes[j, 0] - 1) * 2 ** (j - 1))\n",
    "                value += b\n",
    "            one_hot_vector = csr_matrix(([1], ([0], [value])), shape=(1, 2 ** len(proposed_nodes)), dtype=np.int8)\n",
    "            configuration = one_hot_vector\n",
    "\n",
    "    return graph_tuple, configuration\n",
    "\n",
    "###FIND OUT WHY THIS DOES NOT WORK\n",
    "def parallel_monte_carlo_update(graph_tuples, gnn, N_sweeps):\n",
    "    \"\"\"Perform N_sweeps Monte Carlo updates on each graph tuple in a batch.\"\"\"\n",
    "    # Apply the monte_carlo_update function to each graph tuple in the batch\n",
    "    updated_graph_tuples = Parallel(n_jobs=-1)(delayed(monte_carlo_update)(graph_tuple, gnn, N_sweeps) for graph_tuple in graph_tuples)\n",
    "\n",
    "    return updated_graph_tuples\n",
    "\n",
    "def sequential_monte_carlo_update(graph_tuples, gnn, N_sweeps):\n",
    "    updated_graph_tuples_and_configs = [monte_carlo_update(graph_tuple, gnn, N_sweeps) for graph_tuple in graph_tuples]\n",
    "    updated_graph_tuples, updated_configurations = zip(*updated_graph_tuples_and_configs)\n",
    "    return list(updated_graph_tuples), list(updated_configurations)\n",
    "#print(graph_tuples[0].nodes)\n",
    "#updated_graph_tuples, new_config = sequential_monte_carlo_update(graph_tuples[:1], gnn, 9)\n",
    "def process_batch(batch):\n",
    "    graph_tuple, gnn, N_sweeps = batch\n",
    "    return monte_carlo_update(graph_tuple, gnn, N_sweeps)\n",
    "\"\"\"\n",
    "def process_batch(batch):\n",
    "    graph_tuple, gnn, N_sweeps = batch\n",
    "    return monte_carlo_update(graph_tuple, gnn, N_sweeps)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Prepare your batches (replace this with your actual batches)\n",
    "    batches = [(graph_tuple_1, gnn, N_sweeps), (graph_tuple_2, gnn, N_sweeps), ...]\n",
    "\n",
    "    # Create a pool of workers\n",
    "    with Pool(processes=4) as pool:  # Adjust the number of processes as needed\n",
    "        results = pool.map(process_batch, batches)\n",
    "#updated_graph_tuples = parallel_monte_carlo_update(graph_tuples, gnn, 9)\n",
    "print(updated_graph_tuples[0].nodes)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8cbed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This function computes the stochastic energy given a sample of configurations, here they are specifically computed through\n",
    "#Markov chains using Metropolis algorithm, and the variational wave_function with the weights, in this case it is represented\n",
    "#by a GNN. Further we need the Hamiltonian. Ansatz are the trained GNN at step i. \n",
    "def StochasticEnergy(random_config_batch, graph_tuples_batch, ansatz, Hamiltonian):\n",
    "    factor_list=[]\n",
    "    ansatz_list=[]\n",
    "    configurations=random_config_batch\n",
    "    for idx, graph_tuple in enumerate(graph_tuples_batch):\n",
    "        ansatz_amplitude, ansatz_phase = ansatz(graph_tuple)[0]\n",
    "        amplitude=tf.cast(ansatz_amplitude, tf.float32)\n",
    "        ansatz_list.append(amplitude)\n",
    "        \n",
    "        phase=tf.cast(ansatz_phase, tf.float32)\n",
    "        complex_coefficient = tf.complex(amplitude, phase)\n",
    "\n",
    "        factor_list.append(complex_coefficient)\n",
    "        print(\"index\", idx, \"amplitude\", amplitude, configurations[idx])\n",
    "    energy=0\n",
    "    #wave_function_csr = compute_wave_function_csr(graph_tuples_batch, ansatz, random_config_batch)\n",
    "    #print(\"Confronting the wave fucntion\", wave_function_csr, \"with the factor list \\n\" , factor_list,)\n",
    "    for i in range(len(configurations)):\n",
    "\n",
    "        v2= configurations[i].transpose()\n",
    "        v2_factor= factor_list[i]\n",
    "        en=0\n",
    "        for index in range(len(configurations)):\n",
    "            v1= configurations[index]\n",
    "            v1_factor= factor_list[index]\n",
    "            psi2=v2_factor*v2\n",
    "            psi1=v1_factor*v1\n",
    "            value = psi1.conj().dot(Hamiltonian.dot(psi2))\n",
    "            #print(\"this is value\", value,\"\\n\",\"this is v2\", v2, \"\\n\", \"this is v1\", v1, \"\\n\")\n",
    "            en+=value\n",
    "        energy += en    \n",
    "        \n",
    "    return energy\n",
    "\n",
    "\n",
    "\n",
    "def Overlap(random_config_batch, graph_tuples_batch, wave1, wave2):\n",
    "    amplitude1_list= []\n",
    "    phase1_list=[]\n",
    "    amplitude2_list= []\n",
    "    phase2_list=[]\n",
    "    configurations=random_config_batch\n",
    "    for graph in range(len(graph_tuples_batch)):\n",
    "        ansatz1_amplitudes, ansatz1_phases = wave1(graph_tuples_batch[graph])[0]\n",
    "        amplitude1_list.append(ansatz1_amplitudes)\n",
    "        phase1_list.append(ansatz1_phases)\n",
    "        ansatz2_amplitudes, ansatz2_phases = wave2(graph_tuples_batch[graph])[0]\n",
    "        amplitude2_list.append(ansatz2_amplitudes)\n",
    "        phase2_list.append(ansatz2_phases)   \n",
    "    pass     \n",
    "def compute_wave_function_csr(graph_tuples_batch, ansatz, configurations):\n",
    "    #TO BE FIXED the wave function currently sums up same configurations coefficients if they are presented multiple times. What should I do here? \n",
    "    \n",
    "    data = []  # List to store the non-zero entries\n",
    "    row_indices = []  # List to store the row indices\n",
    "    col_indices = [0] * len(configurations)  # Column indices are all 0 for a vector\n",
    "    size= 2**len(graph_tuples_batch[0].nodes)\n",
    "\n",
    "    # Compute the wave function components for each graph tuple\n",
    "    for idx, graph_tuple in enumerate(graph_tuples_batch):\n",
    "        amplitude, phase = ansatz(graph_tuple)[0]\n",
    "        amplitude = tf.cast(amplitude, tf.float32)\n",
    "        phase = tf.cast(phase, tf.float32)\n",
    "        \n",
    "        # Now create the complex coefficient\n",
    "        complex_coefficient = tf.complex(amplitude, phase)\n",
    "        # Compute the complex coefficient using TensorFlow operations\n",
    "        #print(complex_coefficient,configurations[idx])\n",
    "        \n",
    "        # Extract the row index from the configuration\n",
    "        row_index = configurations[idx].indices[0]\n",
    "        \n",
    "        # Append the data and indices to the lists\n",
    "        data.append(complex_coefficient.numpy())\n",
    "        row_indices.append(row_index)\n",
    "    \n",
    "    # Construct the csr_matrix using the accumulated data and indices \n",
    "    #Shape it is tbd by other means\n",
    "    wave_function_csr = csr_matrix((data, (row_indices, col_indices)), shape=(size, 1))\n",
    "    \n",
    "    return wave_function_csr\n",
    "def compute_wave_function_sparse_tensor(graph_tuples_batch, ansatz, configurations):\n",
    "    values = []  # List to store the non-zero entries\n",
    "    indices = []  # List to store the indices of non-zero entries\n",
    "    \n",
    "    # Compute the wave function components for each graph tuple\n",
    "    for idx, graph_tuple in enumerate(graph_tuples_batch):\n",
    "        amplitude, phase = ansatz(graph_tuple)[0]\n",
    "        \n",
    "        # Convert amplitude to complex tensor with zero imaginary part\n",
    "        amplitude_complex = tf.complex(real=amplitude, imag=tf.zeros_like(amplitude))\n",
    "        \n",
    "        # Compute the complex coefficient using TensorFlow operations\n",
    "        complex_coefficient = amplitude_complex * tf.math.exp(tf.complex(real=0.0, imag=phase))\n",
    "        \n",
    "        # Extract the row index from the configuration\n",
    "        row_index = configurations[idx].indices[0]\n",
    "        \n",
    "        # Append the data and indices to the lists\n",
    "        values.append(complex_coefficient)\n",
    "        indices.append([row_index, 0])\n",
    "    \n",
    "    # Convert lists to tensors\n",
    "    values_tensor = tf.stack(values, axis=0)\n",
    "    indices_tensor = tf.constant(indices, dtype=tf.int64)\n",
    "    \n",
    "    # Create a sparse tensor\n",
    "    sparse_tensor = tf.sparse.SparseTensor(indices=indices_tensor, values=values_tensor, dense_shape=[512, 1])\n",
    "    \n",
    "    return sparse_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa70d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def are_configs_identical(config1, config2):\n",
    "    # Use numpy array equality for vectorized comparison\n",
    "    return np.array_equal(config1, config2)\n",
    "\n",
    "def configs_differ_by_two_sites(config1, config2):\n",
    "    # Use numpy to count the differences in a vectorized manner\n",
    "    return np.sum(config1 != config2) == 2\n",
    "\n",
    "def apply_raising_operator(config, site):\n",
    "    new_config = config.copy()\n",
    "    if config[site] == -1:\n",
    "        new_config[site] = 1  # Spin flip from down to up\n",
    "        return new_config\n",
    "    else:\n",
    "        return None  # State is annihilated\n",
    "\n",
    "def apply_lowering_operator(config, site):\n",
    "    new_config = config.copy()\n",
    "    if config[site] == 1:\n",
    "        new_config[site] = -1  # Spin flip from up to down\n",
    "        return new_config\n",
    "    else:\n",
    "        return None  # State is annihilated\n",
    "\n",
    "def apply_edge_contribution(config, i, j):\n",
    "    # Apply the spin raising operator on site i and lowering on site j\n",
    "    new_config_raised = apply_raising_operator(config, i)\n",
    "    if new_config_raised is not None:\n",
    "        new_config_lowered = apply_lowering_operator(new_config_raised, j)\n",
    "    else:\n",
    "        new_config_lowered = None\n",
    "\n",
    "    # Apply the spin lowering operator on site i and raising on site j\n",
    "    new_config_lowered_initial = apply_lowering_operator(config, i)\n",
    "    if new_config_lowered_initial is not None:\n",
    "        new_config_raised = apply_raising_operator(new_config_lowered_initial, j)\n",
    "    else:\n",
    "        new_config_raised = None\n",
    "\n",
    "    # Combine the new configurations if they are not None\n",
    "    new_configs = []\n",
    "    if new_config_raised is not None:\n",
    "        new_configs.append(new_config_raised)\n",
    "    if new_config_lowered is not None:\n",
    "        new_configs.append(new_config_lowered)\n",
    "\n",
    "    return new_configs\n",
    "\n",
    "                       \n",
    "def construct_sparse_hamiltonian(Graph, spin_operators, J2):\n",
    "    Hamiltonian = csr_matrix((2**Graph.number_of_nodes(), 2**Graph.number_of_nodes()))\n",
    "    # Define the coupling constants\n",
    "    J1 = 1. \n",
    "    node_to_index=nd_to_index(Graph)\n",
    "\n",
    "    # Iterate over the edges of the graph\n",
    "    for i, j in Graph.edges:\n",
    "        print(i,j)\n",
    "        # Map nodes to indices\n",
    "        i_index = node_to_index[i]\n",
    "        j_index = node_to_index[j]\n",
    "\n",
    "        # Add the interaction term to the Hamiltonian\n",
    "        term_to_be_add = (0.5*spin_operators[0][i_index]*(spin_operators[1][j_index]) + \n",
    "                          0.5*spin_operators[1][i_index]*(spin_operators[0][j_index]) + \n",
    "                          spin_operators[2][i_index]*(spin_operators[2][j_index]))\n",
    "        Hamiltonian += J1 * csr_matrix(term_to_be_add)\n",
    "\n",
    "    # Add next nearest neighbour interactions\n",
    "    for i in Graph.nodes:\n",
    "        i_index = node_to_index[i]\n",
    "        for j in Graph.neighbors(i):\n",
    "            j_index = node_to_index[j]\n",
    "            for k in Graph.neighbors(j):\n",
    "                if k != i:\n",
    "                    k_index = node_to_index[k]\n",
    "                    term= csr_matrix(0.5*spin_operators[0][i_index]*spin_operators[1][k_index] \n",
    "                                     + 0.5*spin_operators[1][i_index]*spin_operators[0][k_index] \n",
    "                                     +spin_operators[2][i_index]*spin_operators[2][k_index])\n",
    "\n",
    "                    Hamiltonian += J2 * term\n",
    "    return Hamiltonian                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a291c",
   "metadata": {},
   "source": [
    "## Initialization of the Graph encoding for different configurations and the problem parameters, constant seed for repetibility\n",
    "\n",
    "\n",
    "The following is a sublattice encoding of a square \n",
    "with a Neel State symmetry, i.e. alternated sublattices for adjacent sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f852e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 19:17:18.711882: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-16 19:17:18.772991: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-16 19:17:18.778910: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-03-16 19:17:18.779083: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-03-16 19:17:18.784906: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end time: 1.5725646018981934\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed\n",
    "start=time.time()\n",
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Define the lattice size\n",
    "lattice_size = (2,2)\n",
    "#Batch size, the number of graphs that will be computed simultaneously by the GNN\n",
    "batch_size= 32\n",
    "\n",
    "# Create a square lattice\n",
    "G = nx.grid_2d_graph(*lattice_size, periodic=True)\n",
    "# Number of sites\n",
    "num_sites = lattice_size[0] * lattice_size[1]\n",
    "\n",
    "# Relabel the nodes to use integers\n",
    "mapping = {node: i for i, node in enumerate(G.nodes())}\n",
    "G = nx.relabel_nodes(G, mapping)\n",
    "# Initialize the sublattice encoding\n",
    "sublattice_encoding = np.zeros((num_sites, 2))  # Two sublattices\n",
    "sublattice_encoding[::2, 0] = 1  # Sublattice 1\n",
    "sublattice_encoding[1::2, 1] = -1  # Sublattice 2\n",
    "# Create a dictionary where the keys are the node indices and the values are dictionaries\n",
    "# containing the 'features' field and the corresponding sublattice encoding\n",
    "node_dict = {i: {\"features\": sublattice_encoding[i]} for i in range(num_sites)}\n",
    "# Use the dictionary to set the node attributes in the graph\n",
    "#nx.set_node_attributes(G, node_dict)\n",
    "# Add 'features' to nodes\n",
    "for node in G.nodes():\n",
    "    G.nodes[node]['features'] = sublattice_encoding[node]\n",
    "# Add 'features' to edges\n",
    "# Add 'features' to edges\n",
    "for edge in G.edges():\n",
    "    u, v = edge\n",
    "    G.edges[u, v]['features'] = [1.0]  # Replace with your actual edge features\n",
    "    G.edges[v, u]['features'] = [1.0]  # Add undirected edge # Replace with your actual edge features\n",
    "# Now convert the networkx graph to a GraphsTuple\n",
    "graph_tuple = utils_np.networkxs_to_graphs_tuple([G])\n",
    "\n",
    "# Number of configurations to generate\n",
    "n_configs = 6\n",
    "n_graph=n_configs*batch_size\n",
    "# Generate the basis configurations\n",
    "basis_configs = np.random.randint(2, size=(n_graph, num_sites)) * 2 - 1  # Random spins (-1 or 1)\n",
    "\n",
    "# Concatenate the basis configurations and the sublattice encoding to form the node features\n",
    "node_features = np.concatenate([basis_configs[:, :, np.newaxis], np.repeat(sublattice_encoding[np.newaxis, :, :], n_graph, axis=0)], axis=2)\n",
    "\n",
    "# Get the edge indices\n",
    "edge_index = np.array(G.edges()).T\n",
    "edge_index_duplicated = np.concatenate([edge_index, edge_index[::-1]], axis=1)\n",
    "bias_value=0.05\n",
    "# Create a list of graph dicts\n",
    "graph_tuples = []\n",
    "for i in range(n_graph):\n",
    "    graph_dict = {\n",
    "        'globals': np.array([0.5]),\n",
    "        'nodes': node_features[i],\n",
    "        'edges': np.full((edge_index_duplicated.shape[1], 1), bias_value),\n",
    "        'senders': edge_index_duplicated[0],\n",
    "        'receivers': edge_index_duplicated[1]\n",
    "    }\n",
    "    \n",
    "    # Convert to a GraphsTuple and append to the list\n",
    "    graph_tuples.append(utils_tf.data_dicts_to_graphs_tuple([graph_dict]))\n",
    "\n",
    "\n",
    "print(\"end time:\", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "151d4a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_configurations(N):\n",
    "    num_configs = 2 ** N\n",
    "    configurations = np.zeros((num_configs, N), dtype=int)\n",
    "    \n",
    "    for k in range(num_configs):\n",
    "        binary_str = format(k, '0' + str(N) + 'b')\n",
    "        configuration = np.array([int(bit) for bit in binary_str])\n",
    "        \n",
    "        # Map 0 to -1 to represent down spins\n",
    "        configuration[configuration == 0] = -1\n",
    "        \n",
    "        configurations[k, :] = configuration\n",
    "    \n",
    "    return configurations\n",
    "\n",
    "N = 4  # Number of spins\n",
    "configurations_ordered = generate_configurations(N)\n",
    "print(len(configurations_ordered))\n",
    "node_features_2 = np.concatenate([configurations_ordered[:, :, np.newaxis], np.repeat(sublattice_encoding[np.newaxis, :, :], len(configurations_ordered), axis=0)], axis=2)\n",
    "\n",
    "graph_tuples2 = []\n",
    "for i in range(len(configurations_ordered)):\n",
    "    graph_dict = {\n",
    "        'globals': np.array([0.005]),\n",
    "        'nodes': node_features_2[i],\n",
    "        'edges': np.zeros((edge_index_duplicated.shape[1], 1)),\n",
    "        'senders': edge_index_duplicated[0],\n",
    "        'receivers': edge_index_duplicated[1]\n",
    "    }\n",
    "    # Convert to a GraphsTuple and append to the list\n",
    "    graph_tuples2.append(utils_tf.data_dicts_to_graphs_tuple([graph_dict]))\n",
    "configurations_new=[]\n",
    "b=0\n",
    "value_list=[]\n",
    "for configuration in configurations_ordered:\n",
    "        value=0\n",
    "        for j in range(len(configuration)):\n",
    "            b= int(-1*(configuration[j]-1)*2**(j-1))\n",
    "            value+=b\n",
    "        value_list.append(value)\n",
    "        #print(value)\n",
    "        one_hot_vector = csr_matrix(([1], ([0], [value])), shape=(1, 2 ** len(configuration)), dtype=np.int8)\n",
    "        configurations_new.append(one_hot_vector) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c76812f",
   "metadata": {},
   "source": [
    "##### The next subroutine transforms all the spin configurations in one hot basis vector representation, this is needed for sparse Hamiltonian representation, not for the new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7db86bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030942916870117188\n",
      "  (0, 12)\t1 [ 1  1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "from compgraph.sparse_ham import sites_to_sparse\n",
    "start_time=time.time()\n",
    "b=0\n",
    "configurations, value_list= sites_to_sparse(basis_configs)\n",
    "\n",
    "\n",
    "print(time.time()-start_time)  \n",
    "\n",
    "\n",
    "print(configurations[0], basis_configs[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b5820d",
   "metadata": {},
   "source": [
    "### Test of the new Hamiltonian representation wrt to sparse matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba064516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  2  0 -2]\n",
      "[ 1  1 -1 -1]\n",
      "[-1  1  1 -1]\n",
      "[ 1  1 -1 -1] !\n",
      "[1 1 1 1] !\n",
      "[ 1 -1 -1  1] !\n",
      "[-1  1  1 -1] !\n",
      "[0, 1, 2, 3]\n",
      "[12, 0, 6, 9, 13, 13, 14, 14, 0, 14, 0, 4, 6, 3, 10, 9, 0, 3, 15, 8, 6, 2, 13, 8, 4, 8, 15, 0, 8, 15, 1, 8, 9, 13, 1, 4, 13, 1, 13, 11, 2, 14, 7, 11, 9, 11, 7, 15, 12, 8, 15, 8, 12, 9, 8, 0, 13, 10, 4, 2, 10, 2, 0, 3, 7, 14, 3, 0, 6, 7, 5, 15, 12, 5, 6, 13, 5, 1, 5, 8, 13, 3, 9, 1, 0, 15, 7, 15, 1, 14, 10, 14, 7, 7, 9, 9, 10, 12, 14, 3, 3, 4, 13, 10, 14, 13, 0, 14, 2, 9, 9, 0, 13, 7, 15, 6, 9, 10, 14, 5, 0, 5, 15, 12, 11, 1, 2, 13, 14, 0, 15, 2, 3, 9, 7, 15, 10, 1, 11, 15, 0, 6, 14, 13, 5, 15, 6, 2, 8, 15, 7, 7, 5, 3, 0, 7, 11, 12, 9, 12, 11, 13, 15, 12, 15, 4, 11, 8, 3, 8, 10, 15, 15, 5, 3, 3, 2, 1, 10, 0, 1, 11, 12, 14, 7, 12, 10, 1, 13, 1, 10, 14]\n"
     ]
    }
   ],
   "source": [
    "print(basis_configs[0]+basis_configs[3])\n",
    "print(basis_configs[0])\n",
    "print(basis_configs[3])\n",
    "for config in basis_configs[:4]:\n",
    "    print(config, \"!\")\n",
    "print(G.nodes)\n",
    "print(value_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebaca044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efd62334c50>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.sort(value_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2b2d3bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jelly beans {0: 0, 1: 1, 2: 2, 3: 3}\n",
      "Configs of psi [ 1 -1 -1  1] [-1  1 -1 -1]\n",
      "till here fine \n",
      "\n",
      "   (0, 13)\t1 [-1  1 -1 -1]\n",
      "end of square 2d function\n",
      "Expectation Value: (9.9-2.7j)\n",
      "0 2\n",
      "0 1\n",
      "1 3\n",
      "2 3\n",
      "Expectation Value from sparse Hamiltonian:   (0, 0)\t(9.9-2.7j)\n",
      "Expectation Value from CG notation: (9.9-2.7j)\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from compgraph.sparse_ham import create_spin_operators, construct_sparse_hamiltonian\n",
    "from compgraph.cg_repr import Square_2DHam_exp\n",
    "import qutip as qt\n",
    "from qutip import tensor, jmat, qeye, Qobj\n",
    "from compgraph.useful import nd_to_index\n",
    "\n",
    "J2=2.0\n",
    "#compute_wave_function_csr\n",
    "# Example graph definition using networkx\n",
    "node_to_index = nd_to_index(G)\n",
    "print(\"Jelly beans\",node_to_index)\n",
    "# Define the psi and phi vectors with example amplitudes\n",
    "psi = np.array([2. +1j, 3.2 ])\n",
    "phi = np.array([1.5 +0.3j])\n",
    "print(\"Configs of psi\", basis_configs[2], basis_configs[4])\n",
    "# Define the configurations for psi and phi, they must be given as list of arrays or directly as multidimensional arrays\n",
    "configs_psi = np.array([basis_configs[2], basis_configs[4]])\n",
    "configs_phi = np.array([basis_configs[2]])\n",
    "print(\"till here fine \")\n",
    "print(\"\\n\", configurations[4],basis_configs[4])\n",
    "# Calculate the expectation value\n",
    "size=2**len(G.nodes)\n",
    "expectation_value = Square_2DHam_exp(psi, G, phi, J2, configs_psi, configs_phi)\n",
    "print(\"Expectation Value:\", expectation_value)\n",
    "psi_sparse=csr_matrix((psi, ([configurations[2].indices[0], configurations[4].indices[0]], [0,0])),shape=(size, 1))\n",
    "phi_sparse=csr_matrix((phi, ([configurations[2].indices[0]], [0])),shape=(size, 1))\n",
    "# Assuming `construct_sparse_hamiltonian` is already defined and returns the Hamiltonian matrix\n",
    "spin_operators=create_spin_operators(G)\n",
    "Hamiltonian = construct_sparse_hamiltonian(G, spin_operators, J2)\n",
    "# Calculate the expectation value using the Hamiltonian matrix\n",
    "sparse_expectation_value = psi_sparse.conj().transpose().dot(Hamiltonian.dot((phi_sparse)))\n",
    "# Output the expectation value for comparison\n",
    "print(\"Expectation Value from sparse Hamiltonian:\", sparse_expectation_value)\n",
    "print(\"Expectation Value from CG notation:\", expectation_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75adfddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApQAAAHzCAYAAACe1o1DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNWElEQVR4nO3dd5Cc+X3f+c/TeXpywuSABRa7CFwsMjAbKJJbtCSueUWdrmiL1PlE09w6y3Kx6myfpP9s1cnn8l2V/3AoSqySzBNl0rTuVCbXNu0VzdC/QU6LxWZgcsLk1NM9HZ77A9sDDDA96MaEp5/u96tqS0vgh5lvA3j0fPb7S5Zt27YAAACAp+RxugAAAAC4G4ESAAAAW0KgBAAAwJYQKAEAALAlBEoAAABsCYESAAAAW0KgBAAAwJYQKAEAALAlBEoAAABsCYESAAAAW0KgBAAAwJYQKAEAALAlBEoAAABsCYESAAAAW0KgBAAAwJYQKAEAALAlBEoAAABsCYESAAAAW0KgBAAAwJYQKAEAALAlBEoAAABsCYESAAAAW+JzugC4j23bStlS0raVTksej+SzLHktybIsp8sDAAC7jECJTdm2rZl4SuPRpMajSY1FkxpfSSqZfnyszyM1l/nUEvap+ZN/6oJeQiYAAEXOsm3bdroIFJ7ZeErXp2K6OR1TPHX/r4hH0gY58jEPjwt6LR2tD+lYQ0i1Qe8OVQsAAJxEoMSatG3rzsKqrk7G1L+YkCVpO/5yZL5Od6VfJxpD2lcVkIeuJQAARYNACUnS0FJCbw4sam41vW1B8lGZr1sT8OgLXZXqqPDvwHcBAAC7jUBZ4hJpWz8bXdaVydiOBclHZb7PycaQPt1aLr+HbiUAAG5GoCxhQ0sJ/WhgUQur6V0Jko+yJFUFPHqdbiUAAK5GoCxRVyZX9Nbw8q51JbPJfP/X2st1srHMwUoAAMDTIlCWGNu21Tuxol+MRZ0u5TGvtITV01TGMUMAALgMN+WUmEINk5L0i7GoeidWnC4DAADkiUBZQq7cK9wwmfGLsaiuTBIqAQBwEwJliRhaSuitkWWny8jJW8PLGlpKOF0GAADIEYGyBCTStn40sCi3rEy0JP1oYFGJNMt7AQBwAwJlCfjZ6LJjRwM9DVvSwmpaPx91R0cVAIBSR6AsckNLCV2ZjLkmTGbYki5Pxpj6BgDABQiURSxt23rTRVPdj7IkvTmwqDQnWwEAUNAIlEXszsKq5lw01f0oW9Lcalp3F+hSAgBQyAiURezqJ/dzu5kl6SrHCAEAUNAIlEVqNp5S/2LCtd3JDFtS32JCs/GU06UAAIAsCJRF6vqU+7uTGZakG1Mxp8sAAABZECiLkG3bujntvp3d2diSbkzHxLXzAAAUJgJlEZqJpxRPFVf4iqdszcbTTpcBAAA2QKAsQuPRZM5jQ15Lv3OkTtWB3f+r8MXuSp3eU5bz+Hw+FwAA2D0+pwvA9huPJuWRlEs/r6c5rI/mVzW/+mD0a23laq/wqyHk1XQspT/5YC7vGhpCXr3SElZzmU/VQa/eGl7Slcn16yB7x6P6yrPVujkVU/wJ1yx6LGl8JalDCuZdCwAA2Fl0KIvQWDSZU5j0WdIL9UG9Pf34hpe3p2N6fy7+1DX4PJbm4in9dHRZS4mNq5mKpTQXT+lw3ZNDYtqWRpc5jxIAgEJEh7LI2Lat8ZXcpob3VQeUSkujj0wlvzVy/w7tsC+sxtDT1TEeTa5NUf9Sa/bu48cLqzpYG9S1HHZxj68kZdu2LKtY9q8DAFAc6FAWmZQtJXPcu9JR7s85fO6U0eWkWsI+eXPIiMn0/U4lAAAoLATKIpPM42idqoAn63T0bllKpOXzWCr35fZXMZ/PBwAAdgeBssik88iHPo+lpMMtv0xA9Htym8ZOcXIQAAAFh0BZZDx5/ImuJNMK5TLXvINC3vsFR3Ocp/fyNxYAgILDppwi48tjw8rESkqHa509hqcx5NXCakorOR7E/o/+wf+m7s5OdXd3q6urS93d3aqtrWWjDgAADiJQFhmvJfk8uW3M6VtY1adbwwp6rXU369QEPAp4LZX7Lfk80p4yr6T7x/zkOkPuse6fRSnd75pW+j3aU+bVasrW3ENnXnZU+NW3mNtxQKnVuN76r/9V/f39ikajaz9eWVmp7u7udSHz4X/q6uoInAAA7CDL5oLkovNnH85peDm33dv/84FqvT0d142HzqL8jf3V6qz0Pzb239yeWTsA/XePNejNgUXdmtn4rMrqgEf/6+G6x358cDGhP/94XtL98Ps7R+r07+8sPHZ00Ubay3366oEa2batqakp9ff3r/0zMDCw7n8vLy+v/bry8vLHQubD4bOhoYHACQDAFhAoi9BfDS/p6mQsp8PN91X59ZnWcn37/bmcv351wKNvHKrVt9+b3dL92scaQjpQHdD37yw8cazHkk42lumzbeVPHGvbtqanpx8LmZng2dfXp6WlpbXx4XB4w6CZ+aexsZHACQDAJgiURej2TEw/HFh68sBPnGwM6YO5VS3meITQ8YaQ6kNe/bfh5ScP3sQL9UENLyU1E0/lNP6LXZU6lMOtOk9i27ZmZ2ezdjj7+vq0uLi4Nr6srGzDqfTMjzU1NRE4AQAljUBZhKZjSf3xe3NOl7HtvnGwVnWfrMvcSbZta25ubsMOZyZ8zs3NrY0PhULrAuej4bOpqUmefLbfAwDgMgTKImTbtv7FrZl1G23cLui19M1PFc7mmkcD56Phc3Z2dm1sMBhUV1dX1i5nS0sLgRMA4GoEyiL1k5FlXb63omL4w7Uknd5Tps/ksH6yUMzPz2tgYCDrOs7p6em1sYFAQJ2fHIW0UZezpaVFXu/Od2YBAHhaBMoiNRtP6Vvvzj55oEu8cahWtcHiCVWLi4uPhc2H//fU1NTaWL/fr87Ozqwdzra2NgInAMBRBMoi9r2P5zWwmHB1l9KS1F3p15f3Vztdyq5aWlratMN57969tbE+n08dHR1ZO5xtbW3y+ThyFgCwcwiUReyj+bj+4u7ikwcWuF9/pkr7qwNOl1FQlpeXNTg4mLXDOTExsTbW6/WuBc6Nupzt7e0ETgDAlhAoi1jatvVH785qfjXtyi6lpQdnXnoKZDOOW0SjUQ0ODmbtcI6Nja2N9Xg8am9vz9rh7OjokN//+EH3AABkECiL3NBSQt/9aN7pMp7aV5+tVnsFYWa7xWKxTTuco6Oja2M9Ho/a2tqydjg7OjoUCNBBBoBSRqAsAW99cnOOm/6gLd0/cP1z7RVOl1KS4vF41g5nJnBm/l+HZVlqbW3NevB7Z2engsGtH0gPAChcBMoSkEjb+vZ7s1pwydS3Jakq4NHXD9bK72GquxCtrq5qaGgoa4dzZGRE6fSDm5cygXOjDmdnZ6dCoZCDnwYAsFUEyhLhtqnvrzxbrQ6mul1rdXVVw8PDWTucw8PD6wJnc3Nz1g5nV1eXysrKHPw0AIAnIVCWkCuTK3pri/dv74bX2st1spEAUcwSiYRGRkY23DDU39+voaEhpVIP7nhvamrKerVlV1eXwuGwg58GAECgLDFmPKpfjEWdLiOrV1rCeqmZcFDqksnkWuDcqMs5NDSkZDK5Nr6xsfGxDmcmbHZ1damigrW4ALCTCJQlxrZt9U6sFGSofLUlrHNNZQVzXzcKVyqV0ujoaNYO5+DgoBKJxNr4hoaGTTuclZWVDn4aAHA/AmWJykx/W5KjG3Uy359pbmynVCqlsbGxrB3OwcFBra6uro2vr6/PerVld3e3qqqqHPw0AFD4CJQlbGgpoR8NLDq2+zuzm/v1rko24GBXpdNpjY+PZ+1wDgwMKB6Pr42vra3NevB7d3e3qqtL62pQAHgUgbLEJdK2fja6rCuTsV3rVma+z6nGkF5tLedoIBScdDqtiYmJrB3OgYEBxWKxtfE1NTUbdjgz4bOmpoalHACKGoESku53K98cWNTcanrHgmXm69YEPPoCXUm4mG3bunfvXtYOZ39/v1ZWVtbGV1VVbdrhrK2tJXACcDUCJdakbVt3FxK6OrmivsXEtgXLzNfZW+nXicYyPVPl525uFDXbtjU5OZm1w9nf369o9MHGuMrKyqwHv3d1dam+vp7ACaCgESixodl4SjemYroxHVM8df+viEdSevNfdn+cJaU/+VsV9Fp6sT6kFxtCqg16d6xewE1s29b09HTWDmdfX5+Wlx+cGVteXp51w1B3d7caGhoInAAcRaDEpmzb1lff+G2lymv1jX/w+xpdTmh8JankBsnS55Gay3xqLferucyn5rBPtUEPLzogT7Zta2ZmZsOp9Mw/i4uLa+PD4XDWDmd3d7caGxt5DgHsKAIlNmXbtlpaWvS1r31Nf/iHf7j2Y2lbStq2UmnJ65F8liWPJV5awC6wbVtzc3MbTqUPDAyor69PCwsLa+PLyso2PH8z8+9NTU08u0AebNtW6pP3YDoteT55D3pL+D1IoMSm7ty5o/379+vNN9/Ur/7qrzpdDoAcPRw4N+pwzs3NrY0NhUJrtwpt1OFsamqSx+Nx7sMADrJtWzPxlMajSY1HkxqLJp84U9cSvj9L1xz2qS7oLYmQSaDEpr7zne/ob/2tv6WZmRnV1tY6XQ6AbTI/P5/1SKT+/n7NzMysjQ0EApse/N7S0kLgRNGZjad0fSqmm0+zl+ChcUGvpaP1IR0r8r0EBEps6o033pAxRu+8847TpQDYRQsLC+sOen80eE5PT6+NDQQC6uzszLqOs6WlRV5v8b5IUTzStq07C6u6OhlT/w6cdtJd6deJxpD2VQWK7rQTAiU2dfjwYb388sv61re+5XQpAArI0tLSph3OycnJtbF+v18dHR1ZO5xtbW0ETjiO85i3hkCJrGZmZlRfX6/vfOc7+s3f/E2nywHgIsvLy5t2OO/du7c21ufzrQucj3Y529ra5PP5HPw0KGZO3hh3sjGkTxfJjXEESmT15ptv6vXXX9edO3f0zDPPOF0OgCISjUY1ODiYtcM5Pj6+Ntbr9aq9vT3r1Zbt7e3y+4un04PdM7SU0I8GFrWwmt6VIPkoS1JVwKPXi6BbSaBEVr/3e7+nP/3TP9Xo6GhJ7FADUDhWVlbWAudGHc6xsbG1sR6PZ13gfLTD2dHRQeDEY65Mruit4eVd60pmk/n+r7WX62RjmYOVbA2BElm9+uqrampq0g9+8AOnSwGAdWKxmIaGhrKexTk6OqrM683j8ai1tTVrh7Ojo0PBYNDhT4TdYtu2eidW9Iux6JMH77JXWsLqaSpzZROHQIkNra6uqrq6Wv/0n/5TffOb33S6HADISzweXxc4H+1yjoyMrAVOy7LWBc5HO5ydnZ0EziJixqMFGSYzXmkJ66XmsNNl5I1AiQ1duHBB586d06VLl3Tq1CmnywGAbbW6uqqhoaGsO9WHh4eVTj84cbC1tTXrwe+dnZ0KhUIOfhrk6sq9Fb01sux0GU/kxulvts1hQ5FIROFwWC+++KLTpQDAtgsEAtq3b5/27du34c8nEgkNDw9v2OHs7e3V0NDQusDZ3Nyc9WrLrq4ulZW5KxwUo6GlhCvCpCS9NbyspjKfqzbq0KHEhr70pS9pfn5eP/nJT5wuBQAKTiKR0MjISNYO5+DgoFKp1Nr4pqamrB3Orq4uhcPum+J0k0Ta1rffm3VsN3e+Mru/v36w1jVHChEo8RjbttXU1KQ33nhDf/AHf+B0OQDgOslkUqOjo1nXcA4ODiqZTK6Nb2xs3LTDWVFR4eCncb+3hpd0dTLmijCZYen+OZWfa3fHnz2BEo/58MMP9dxzz+k//+f/rF/+5V92uhwAKDqpVEqjo6NZO5wDAwNKJBJr4xsaGrJebdnV1aXKykoHP01hG1pK6LsfzTtdxlP7yrPVrpj6JlDiMX/yJ3+iv/23/7ZmZ2dVXV3tdDkAUHLS6bTGxsaydjgHBga0urq6Nr6uri7r1Zbd3d2qqqpy8NM4J23b+qN3ZzXvkqnuR1mSqgMefeNQbcHf/U2gxGO+/vWv6/Lly7p586bTpQAANpBOpzU+Pr7pferxeHxtfG1tbdYOZ3d3d9E2Dz6aj+sv7i46XcaW/fozVdpfHXC6jE0RKPGY559/Xp/97Gf1r//1v3a6FADAU0in07p3796GQTPzTywWWxtfXV2ddcNQd3e3ampqXHnY9vc+ntfAYsKV3ckMS1J3pV9f3l/YoZ9AiXWmpqbU2NioP/uzP9NXvvIVp8sBAOwA27bXAme2Lmc0+uDw76qqqqwHv3d3d6u2trbgAudsPKVvvTvrdBnb5o1DtaoNep0uIyvOocQ6vb29kqSXX37Z4UoAADvFsiw1NTWpqalJZ86ceeznbdvW1NTUhh3On/zkJ+rv79fy8oMzHSsqKjbtcNbX1+964Lw+FXP8nu7tYkm6MRXTZ9rKnS4lKwIl1jHGqK2tTZ2dnU6XAgBwiGVZamxsVGNj44a3pdm2renp6Q07nD/96U/V39+vpaWltfHl5eWbdjgbGhq2NXDatq2b0+46JmgztqQb0zH9Umu44DrBGUx5Y52XXnpJ7e3t+v73v+90KQAAl7JtW7Ozs1nXcPb19Wlx8cFmmXA4nPVIpO7ubu3ZsyevIDUdS+qP35vbgU/mrG8crFVdqDCnvelQYk0sFtOVK1f0N/7G33C6FACAi1mWpbq6OtXV1en48eOP/bxt25qbm9uww9nb26t/9+/+nebm5tbGl5WVPXbY+8PBs6mpaV3gHI8mH/ue2YS8lv7OwVp958M5za+mn/wLttFvHqjWpYkVfTC/+uTBuv+5CJQoeFevXtXq6qpeeuklp0sBABQxy7JUW1ur2tpaHTt2bMMxc3NzG56/efHiRX3/+9/X7OyDDTehUEidnZ0PQuZf+7Ks7iOS5XliLT3NYX00v7ouTFb5Pfp8R4W6Kv1aTdl6Zyamn45G85pC7yj36UxTWE1hryr9Xv3F3QV99Ehw7B2P6nNtFTkFSo8lja8kdUjBPKrYPQRKrIlEIiovL9cLL7zgdCkAgBJXU1OjmpoaHT16dMOfn5+fX7tV6OHQeeXKFflf+pLaZOlJk+Q+S3qhPqh///HC2o9Zkn59X5WWE2n9Px/OqcLv0eudlUrZ0s/Hotm/2CP8XksTK0m9PR3Trz2z8cHydxcS+pVOS/uq/LqzkNhwTEbalkaXNx/jJAIl1hhjdPbsWfl8/LUAABS26upqvfDCC481QWzb1v/99rSSOcxe76sOKJWWRh+aIt9b5VdDyKvvfTyvaNLWvZWUfj4W1S+1hRUZjyqdY5vy7kJCd58QEm1JdxdWdbA2+MRAKd3vUNq2XZAbc57cC0ZJsG1bvb29HBcEAHC1lK2cwqQkdZT7Nb6yfr1lW9ivyZWUoskHybFvcVUhr0eNO7B+cXQ5qY7y3O7qTqaVc6DdbQRKSJI++OADTU9Ps34SAOBqyTwOr6kKeLSUWJ8+y/0eLT+SSJc/GVPu3/7YtJRIqzKQ+9fN5/PtJgIlJN1fP+nxeHT27FmnSwEA4Kml89io7fNYSjrc8kvatjyWJV+Os9ip3d2InjMCJSTdXz959OhRVVZWOl0KAABPzZNHsllJphXyrk9yy4m0yn3rv0imM7mc2P40F/JaWk3ZSuaYa70FmtwKtCzsNmMM090AANfz5bFhZWIlpYbQ+o2oI9GEGsu8Cj/UMuyu9CuWSmsqltq2OjMay3yaWMn93Mx8Pt9uIlBCExMT+uijjwiUAADX81qSL8d007ewqoYyr4IPdSn7FhKaiqX0elel9pR5tbfSr1dbynVtMqZUHrPjfo+0p8yrPWX3N/LUBDzaU+ZV1SPrMDvK/epbyO1gc5/n/nmUhYhACfX29koSgRIA4HqWZam5LLfj7yZjKU1EkzpY8+CwcFvSf7izINuWfvNAjf56V6XemYnpFw+dQVkd8Oh3jzWosyL77uyWsF9fe75WX3u+VpL0ufYKfe35Wr3SEl4bU+H3qK3cp1sz8ZzqbS7zFeSRQRLnUEL3p7s7OzvV0dHhdCkAAGxZS9in0eWkclnxaMaj+kxruW5Mx9Z+bCGR1g/uLmT9NdUBr2LJ9KZT1YNLCf2f16c2/d4nG0O6NRPXYg5rMz2W1Jrj8UJOIFCC9ZMAgKLSHPblFCYl6c5CQrXBmCr9npyCnSTtq/Krd2JF8XzmwDcQTdq6dG85p7FpWzl3Xp1QuJVhV6ysrOjq1av66le/6nQpAABsi+ZwfvHmymTsyYMe8t9Hc7+CcTOX7q3kNT7fz7WbWENZ4i5fvqxEIsENOQCAolEXXL/RphgEvZZqg4Ub2wq3MuwKY4yqqqp05MgRp0sBAGBbWJalo/UhFUuktCS9WB8q2A05EoGy5EUiEZ09e1Ze7/bfTwoAgFOONYRUmJcU5s+W9GJDyOkyNkWgLGHpdFq9vb1MdwMAik5t0KvuSr/ru5SWpL2VftUGC7vxQ6AsYe+9957m5ubY4Q0AKEonGt3fpbQlnWgsc7qMJyJQlrBIJCKv16szZ844XQoAANtuX1VANQGPa7uUlu7fsPNMVeGeP5lBoCxhxhi9+OKLKi8vd7oUAAC2ncey9IWuStd2KW1Jr3dVylPAm3EyCJQlzBjD+kkAQFHrqPDrZKP7dnxbkk41htS+yfWOhYRAWaLGxsZ09+5d1k8CAIrep1vLVeWiqW9LUlXAo1db3TODSKAsUcYYSSJQAgCKnt9j6XUXTX1nprr9HrdEYAJlyTLGaO/evWptbXW6FAAAdlxHhV+vtbuj4/dae7k6XDLVnUGgLFHGGLqTAICScrKxTK+0hJ0uY1OvtIR10gXHBD2KQFmClpeXde3aNQIlAKDk9DQVbqh8tSWsnib3hUmJQFmSLl26pFQqRaAEAJQcy7L0UnN4bfrb6VWKme//Wnu5eprDBX1f92Z8TheA3WeMUXV1tQ4fPux0KQAAOOJkY5maynz60cCiFlbTjmzYyezmfr2r0nVrJh9l2bbtlk1P2Ca/8iu/Isuy9J/+039yuhQAAByVSNv62eiyrkzGZEm7Eiwz3+dUY0ivtpa7ajd3Nkx5l5hUKqXe3l6muwEA0P0jhV5rr9BXnq1WdeB+LNqpeJf5utUBj77ybLU+115RFGFSYsq75Ny+fVsLCwvckAMAwEM6Kvz6xqFa3V1I6OrkivoWE9vWscx8ne5Kv040lumZKr8rrlPMB4GyxBhj5PP5dOrUKadLAQCgoHgsS/urA9pfHdBsPKUbUzHdmI4pnrofKz2S0jl9HSn9SRINei29WB/Siw0h1Qa9O1a701hDWWK+8pWv6OOPP9bFixedLgUAgIJn27b+p//l6yrb067f+uY/0uhyQuMrSSU3SJY+j9Rc5lNruV/NZT41h32qDXpcu3M7H3QoS4wxRr/2a7/mdBkAALiCbdv6q//4/+qb3/ymPttWvvZjaVtK2rZSacnrkXyWJY+lkgiPGyFQlpCRkRENDAywfhIAgBy99957mpubW7eZ1bIseS3JK0sq3lnsvLDLu4QYYySJHd4AAOTIGCOv16szZ844XUpBI1CWkEgkon379qmpqcnpUgAAcAVjjI4eParKykqnSyloBMoSYoxhuhsAgDwYY5jZywGBskQsLi7qxo0bPBQAAORoYmJCd+7c4d2ZAwJlibh48aLS6TQPBQAAOWLvQe4IlCXCGKPa2lo9//zzTpcCAIArRCIRdXZ2qr293elSCh6BskRk1oB4PPyRAwCQC9ZP5o50UQKSyaTOnz/PQwEAQI6i0aiuXbvGZtYcEShLwK1bt7S0tESgBAAgR5cvX1YymeTdmSMCZQkwxigQCOjUqVNOlwIAgCsYY1RVVaUjR444XYorEChLgDFGJ06cUCgUcroUAABcwRijs2fPyuvlbsVcEChLQCQSoWUPAECO0um0ent7eXfmgUBZ5AYHBzU8PMxDAQBAjt59913Nzc3x7swDgbLIcSgrAAD5McbI6/XqzJkzTpfiGgTKIheJRHTgwAE1NjY6XQoAAK5gjNHRo0dVUVHhdCmuQaAschzKCgBAfowxnD+ZJwJlEVtYWNCtW7d4KAAAyNH4+Lju3r1LMyZPBMoiduHCBaXTaR4KAAByxN6Dp0OgLGKRSEQNDQ06cOCA06UAAOAKxhh1dXWpra3N6VJchUBZxIwx6unpkWVZTpcCAIArcHbz0yFQFqlEIqGLFy+yfhIAgBxFo1Fdv36dQPkUCJRF6ubNm1peXuahAAAgR5cuXVIymeTd+RQIlEXKGKNgMKgTJ044XQoAAK5gjFFVVZWOHDnidCmuQ6AsUsYYnTp1SsFg0OlSAABwBWOMzp07J6/X63QprkOgLEK2bXOgOQAAeUin0zp//jzvzqdEoCxC/f39Gh0d5aEAACBH7777rubm5nh3PiUCZRHKHMra09PjcCUAALhDJBKR1+vVmTNnnC7FlQiURcgYo4MHD6q+vt7pUgAAcAVjjF588UWVl5c7XYorESiLEIeyAgCQH/YebA2BssjMzc3p9u3bPBQAAORobGxMfX19XAayBQTKInP+/HnZts1DAQBAjjJ7D2jGPD0CZZGJRCLas2eP9u3b53QpAAC4gjFG3d3dam1tdboU1yJQFpnMGhDLspwuBQAAV2D95NYRKItIIpHQpUuXmO4GACBHy8vLun79OoFyiwiUReT69etaWVnhoQAAIEeXLl1SMpnk3blFBMoiEolEFAqFdOzYMadLAQDAFYwxqqqq0uHDh50uxdUIlEXEGKPTp08rEAg4XQoAAK5gjFFPT4+8Xq/TpbgagbJI2LYtYwzrJwEAyFE6ndb58+eZ7t4GBMoicefOHU1MTPBQAACQo9u3b2t+fp535zYgUBaJzKGs586dc7gSAADcwRgjr9er06dPO12K6xEoi4QxRkeOHFFtba3TpQAA4ArGGB07dkzl5eVOl+J6BMoiwaGsAADkJxKJ8O7cJgTKIjAzM6N3332XhwIAgByNjo6qv7+fd+c2IVAWgd7eXklcag8AQK4yew94d24PAmURMMaopaVFe/fudboUAABcwRijvXv3qrW11elSigKBsghk1oBYluV0KQAAuAJ7D7YXgdLl4vG4Ll++zEMBAECOlpeXdf36dd6d24hA6XLXrl1TPB7nhhwAAHJ06dIlpVIpAuU2IlC6XCQSUTgc1tGjR50uBQAAV4hEIqqurtbhw4edLqVoEChdzhijM2fOyO/3O10KAACuYIzRuXPn5PEQg7YLv5MuZtu2ent7adkDAJCjVCql8+fPs1RsmxEoXeyjjz7S5OQkDwUAADm6ffu2FhYWaMZsMwKli0UiEVmWpbNnzzpdCgAArmCMkc/n0+nTp50upagQKF3MGKNPfepTqq6udroUAABcwRijY8eOKRwOO11KUSFQupgxhuluAADywIHmO4NA6VKTk5P64IMPeCgAAMjRyMiI+vv7eXfuAAKlS/X29kriUnsAAHJljJHEu3MnEChdyhijtrY2dXZ2Ol0KAACuYIzRM888o5aWFqdLKToESpfKrJ+0LMvpUgAAcAXWT+4cAqULxWIxXblyhYcCAIAcLS0t6caNG7w7dwiB0oWuXLmi1dVVHgoAAHJ06dIlpVIp3p07hEDpQsYYVVRU6IUXXnC6FAAAXMEYo5qaGh06dMjpUooSgdKFIpGIzp49K5/P53QpAAC4QiQS0blz5+TxEH12Ar+rLpNOp9Xb20vLHgCAHKVSKZ0/f5535w4iULrMBx98oJmZGR4KAABy9M4772hxcZF35w4iULqMMUYej0dnz551uhQAAFzBGCOfz6fTp087XUrRIlC6TCQS0dGjR1VZWel0KQAAuIIxRsePH1c4HHa6lKJFoHQZDmUFACA/vDt3HoHSRSYmJvTxxx/r5ZdfdroUAABcYXh4WAMDAwTKHUagdBEutQcAID+8O3cHgdJFjDHq7OxUe3u706UAAOAKxhg988wzam5udrqUokagdBFjDNPdAADkgfWTu4NA6RLRaFRXr17loQAAIEdLS0u6efMmzZhdQKB0icuXLyuZTBIoAQDI0cWLF5VKpXh37gICpUsYY1RVVaUjR444XQoAAK5gjFFNTY0OHjzodClFj0DpEsYYnTt3Tl6v1+lSAABwBWOMenp65PEQd3Yav8MukE6n1dvbS8seAIAcpVIpnT9/nnfnLiFQusC7776rubk5HgoAAHJ069YtLS4u8u7cJQRKFzDGyOv16syZM06XAgCAKxhj5PP5dOrUKadLKQkESheIRCI6duyYysvLnS4FAABXMMboxIkTCofDTpdSEgiULsChrAAA5Id35+4iUBa4sbEx9fX18VAAAJCj4eFhDQ4O8u7cRQTKAsel9gAA5Id35+4jUBa4SCSivXv3qrW11elSAABwBWOM9u3bp6amJqdLKRkEygLHGhAAAPITiUR4d+4yAmUBW15e1vXr17nUHgCAHC0uLurmzZsEyl1GoCxgXGoPAEB+Ll68qHQ6TTNmlxEoC1jmUvtDhw45XQoAAK5gjFFtba2ef/55p0spKQTKAmaM0blz57jUHgCAHBlj1NPTw7tzl/G7XaAyl9rTsgcAIDepVEoXLlxgqZgDCJQF6p133tHCwgIPBQAAObp165YWFxd5dzqAQFmguNQeAID8RCIR+f1+3p0OIFAWKC61BwAgP8YYHT9+XGVlZU6XUnIIlAWKQ1kBAMiPMYa9Bw4hUBYgLrUHACA/Q0NDGhoa4t3pEAJlAeJSewAA8pN5d/b09DhcSWkiUBagSCSi/fv3c6k9AAA5Msbw7nQQgbIAGWPoTgIAkAfenc4iUBYYLrUHACA/vDudR6AsMFxqDwBAfi5cuKB0Ok2gdBCBssBEIhHV1dXpueeec7oUAABcwRijuro6Pf/8806XUrIIlAWGS+0BAMgP707n8TtfQJLJJJfaAwCQB96dhYFAWUDefvttLS0tsX4SAIAc3bp1S0tLSwRKhxEoC4gxRoFAQCdPnnS6FAAAXMEYI7/fz7vTYQTKAmKM0YkTJxQKhZwuBQAAV4hEIjpx4oTKysqcLqWkESgLhG3bikQiTHcDAJAHDjQvDATKAjE4OKiRkREeCgAAcjQ4OKjh4WHenQWAQFkguNQeAID8ZN6dBErnESgLhDFGBw4cUGNjo9OlAADgCsYYPfvss9qzZ4/TpZQ8AmWBYP0kAAD5Yf1k4SBQFoD5+XndunWLhwIAgBwtLCzo7bff5t1ZIAiUBeDChQuybZuHAgCAHF24cEHpdJp3Z4EgUBYAY4waGhp04MABp0sBAMAVjDGqq6vTc88953QpEIGyIEQiEb300kuyLMvpUgAAcAVjjHp6euTxEGUKAX8KDkskErp48SItewAAcpRMJnXhwgU2sxYQAqXDbt68qWg0ykMBAECO3n77bS0vL9OMKSAESodFIhEFg0EdP37c6VIAAHAFY4wCgYBOnjzpdCn4BIHSYcYYnTp1SsFg0OlSAABwBWOMTpw4oVAo5HQp+ASB0kG2bXMoKwAAebBte20zKwoHgdJBfX19GhsbY/0kAAA5Ghwc1MjICIGywBAoHZS51L6np8fhSgAAcAfenYWJQOkgY4wOHjyouro6p0sBAMAVjDE6cOCA9uzZ43QpeAiB0kHGGKa7AQDIA3sPChOB0iGzs7N65513eCgAAMjRwsKCbt26xbuzABEoHXL+/HlJ4qEAACBHFy5cUDqd5t1ZgAiUDjHGaM+ePdq3b5/TpQAA4ArGGNXX1+u5555zuhQ8gkDpkEgkopdfflmWZTldCgAArhCJRNTT08O7swARKB2wurqqS5cu0bIHACBHyWRSFy9e5N1ZoAiUDrh+/bpisRgPBQAAObp586aWl5c5HaVAESgdYIxRWVmZjh075nQpAAC4gjFGgUBAJ06ccLoUbIBA6YBIJKLTp08rEAg4XQoAAK5gjNHJkycVCoWcLgUbIFDuMtu2OZQVAIA88O4sfATKXXbnzh3du3ePhwIAgBwNDg5qZGSEd2cBI1DuskgkIsuydO7cOadLAQDAFSKRiCSpp6fH4UqQDYFylxljdPjwYdXW1jpdCgAArmCM0YEDB9TY2Oh0KciCQLnLWAMCAEB+jDEcF1TgCJS7aHp6Wu+99x4PBQAAOZqfn9etW7doxhQ4AuUu6u3tlSQeCgAAcnThwgXZts27s8ARKHeRMUYtLS3q7u52uhQAAFzBGKOGhgYdOHDA6VKwCQLlLsqsn+RSewAAcmOMUU9PD+/OAkeg3CXxeFyXL19m/SQAADlKJBK6cOEC090uQKDcJVevXlU8HuehAAAgRzdv3lQ0GuXd6QIEyl1ijFE4HNbRo0edLgUAAFcwxigYDOrkyZNOl4InIFDukkgkorNnz8rv9ztdCgAArmCM0cmTJxUMBp0uBU9AoNwFtm2rt7eXlj0AADmybZvLQFyEQLkLPvzwQ01NTfFQAACQo4GBAY2OjvLudAkC5S4wxsiyLJ09e9bpUgAAcAVjjCSpp6fH4UqQCwLlLohEInrhhRdUXV3tdCkAALhCJBLRc889p4aGBqdLQQ4IlLuANSAAAOSHd6e7ECh32OTkpD788EMeCgAAcjQ3N6d33nmHd6eLECh3WGYNCDfkAACQmwsXLsi2bd6dLkKg3GHGGLW3t6uzs9PpUgAAcAVjjBobG/Xss886XQpyRKDcYawBAQAgP8YY9fT0yLIsp0tBjgiUO2hlZUVXrlyhZQ8AQI4SiYQuXrxIM8ZlCJQ76MqVK0okEjwUAADk6MaNG4pGo7w7XYZAuYOMMaqoqNCnPvUpp0sBAMAVjDEKBoM6ceKE06UgDwTKHWSM0dmzZ+Xz+ZwuBQAAVzDG6OTJkwoGg06XgjwQKHdIOp2WMYb1kwAA5Mi2bd6dLkWg3CHvv/++ZmdnWQMCAECO+vv7NTY2xrvThQiUO8QYI4/HozNnzjhdCgAArpC5DKSnp8fhSpAvAuUOMcboxRdfVGVlpdOlAADgCsYYPf/886qvr3e6FOSJQLlDIpEILXsAAPLAu9O9CJQ7YGJiQnfu3OGhAAAgR3Nzc7p9+zbvTpciUO6AzBoQHgoAAHJz/vx52bbNu9OlCJQ7IBKJqKurS+3t7U6XAgCAKxhj1NjYqGeffdbpUvAUCJQ7wBjDf2EBAJCHzLvTsiynS8FTIFBus2g0qmvXrhEoAQDIUSKR0MWLF3l3uhiBcptdunRJyWSSU/4BAMjRjRs3tLKyQqB0MQLlNjPGqKqqSocPH3a6FAAAXMEYo2AwqOPHjztdCp4SgXKbGWN07tw5eb1ep0sBAMAVIpGITp06pWAw6HQpeEoEym2UTqfV29tLyx4AgBzZts1m1iJAoNxGt2/f1vz8POsnAQDIUV9fn8bHx3l3uhyBchsZY+T1enX69GmnSwEAwBUyl4H09PQ4XAm2gkC5jYwxOnbsmMrLy50uBQAAVzDG6ODBg6qrq3O6FGwBgXIbRSIRWvYAAOSB9ZPFgUC5TUZHR9Xf389DAQBAjmZnZ3X79m3enUWAQLlNMmtAeCgAAMjN+fPnZds2784iQKDcJsYY7d27Vy0tLU6XAgCAKxhj1NjYqP379ztdCraIQLlNWD8JAEB+jDF6+eWXZVmW06VgiwiU22BpaUk3btygZQ8AQI4SiYQuXbrEu7NIECi3waVLl5RKpXgoAADI0fXr17WyssK7s0gQKLdBJBJRTU2NDh065HQpAAC4gjFGoVBIx48fd7oUbAMC5TYwxqinp0ceD7+dAADkwhijU6dOKRAIOF0KtgEJaItSqZTOnz9Pyx4AgBzZtq1IJMK7s4gQKLfonXfe0eLiIg8FAAA5unv3riYmJnh3FhEC5RZFIhH5/X6dOnXK6VIAAHCFzGUgPT09DleC7UKg3CJjjI4fP65wOOx0KQAAuIIxRocOHVJdXZ3TpWCbECi3iEvtAQDID+/O4kOg3IKhoSENDg5yQw4AADmanZ3V7du3CZRFhkC5BawBAQAgP+fPn5ckAmWRIVBugTFG+/fvV1NTk9OlAADgCpFIRHv27NG+ffucLgXbiEC5BZyhBQBAfjLrJy3LcroUbCMC5VNaXFzU22+/zfpJAABytLq6qkuXLtGMKUIEyqd04cIFpdNpHgoAAHJ0/fp1xWIxmjFFiED5lIwxqqur03PPPed0KQAAuIIxRqFQSMeOHXO6FGwzAuVTyqyf9Hj4LQQAIBfGGJ0+fVqBQMDpUrDNSENPIZlM6sKFC0x3AwCQI9u2OdC8iBEon8Lbb7+t5eVlHgoAAHJ0584dTUxM8O4sUgTKpxCJRBQIBHTy5EmnSwEAwBUyl4GcO3fO4UqwEwiUT8EYo5MnTyoUCjldCgAArmCM0aFDh1RXV+d0KdgBBMo8sQYEAID8GWM4LqiIESjzNDg4qJGREQIlAAA5mpmZ0bvvvsu7s4gRKPMUiUQkST09PQ5XAgCAO5w/f16SCJRFjECZJ2OMnnvuOTU2NjpdCgAArmCMUVNTk5555hmnS8EOIVDmifWTAADkJ3MZiGVZTpeCHUKgzMPc3Jxu3brFomIAAHK0urqqy5cv04wpcgTKPFy4cEG2bfNQAACQo2vXrikWi/HuLHIEyjwYY9TY2Khnn33W6VIAAHAFY4zKysp07Ngxp0vBDiJQ5iESiainp4c1IAAA5MgYo9OnTysQCDhdCnYQgTJHiURCFy9eZP0kAAA54jKQ0kGgzNGNGze0srLCQwEAQI7u3Lmje/fu8e4sAQTKHBljFAwGdfz4cadLAQDAFYwxkqRz5845XAl2GoEyR5FIRKdPn1YwGHS6FAAAXCESiejw4cOqra11uhTsMAJlDlgDAgBA/nh3lg4CZQ76+vo0Pj7OQwEAQI5mZmb03nvvsZm1RBAocxCJRCRJPT09DlcCAIA79Pb2ShLNmBJBoMyBMUaHDh1SXV2d06UAAOAKxhg1Nzdr7969TpeCXUCgzAFrQAAAyE/m3cllIKWBQPkEs7Ozun37NoESAIAcxeNxXb58mXdnCSFQPkFmDQiLigEAyM21a9cUi8UIlCWEQPkExhg1NTXpmWeecboUAABcwRijsrIyHTt2zOlSsEsIlE/AGhAAAPJjjNGZM2fk9/udLgW7hEC5idXVVV26dImWPQAAOeIykNJEoNxEZg0I6ycBAMjNxx9/rMnJSQJliSFQboI1IAAA5McYI8uydO7cOadLwS4iUG7CGKPTp0+zBgQAgBwZY3T48GHV1NQ4XQp2UUkHStu2lUzbiqXSiibSiqXSSqZt2fb9fyKRCNPdAADkIRKJMN1dgnxOF7BbbNvWTDyl8WhS49GkxqJJja8klUw/PtbnkaqV0Kmv/j0d+txf03Qsqbqgl53eAABsYnp6Wu+//75+//d/3+lSsMss27Ztp4vYSbPxlK5PxXRzOqZ46v5H9UjaIEeuZ9tKJRPy+gOSpKDX0tH6kI41hFQb9O5ozQAAuNEPf/hDffGLX9Tdu3e5w7vEFGWHMm3burOwqquTMfUvJmRJejg1PzFMSpJlrYVJSYqnbF2+t6JL91bUXenXicaQ9lUF5KFrCQCApPvrJ1taWtTd3e10KdhlRRcoh5YSenNgUXOraWWi3na1YDNfZ2Axof7FhGoCHn2hq1IdFWzaAQCAy0BKV9Fsykmkbb01vKTvfjSv+dX7PcidmsvPfN351bS++9G83hpeUiJd1CsHAADYVDwe1+XLl9mQU6KKokM5tJTQjwYWtbDDQfJRme9zdTKmj+ZX9TrdSgBAibp27Zri8TiBskS5vkN5ZXJF3/1oXgur6V0Lko+yJS180q28MrniUBUAADgnEokoHA7rxRdfdLoUOMC1HUrbttU7saJfjEXv/2+n6/nk/741vKx4ylZPUxlrSAAAJYPLQEqbazuUD4fJQvOLsah6J+hUAgBKg23b6u3t5TKQEubKQHnlXuGGyYxfjEWZ/gYAlISPPvpIk5OTrJ8sYa4LlENLCb01sux0GTl5a3hZQ0sJp8sAAGBHGWNkWZbOnTvndClwiKsCZSJt60cDi3LLykRL0o8GFjlSCABQ1IwxOnLkiKqrq50uBQ5xVaD82eiyo7u585XZ/f3zUXd0VAEAeBqZA81RulwTKIeWEroyGXNNmMywJV2ejDH1DQAoSlNTU3r//fcJlCXOFYEybdt600VT3Y+yJL05sKi07bY4DADA5np7eyWJQFniXBEo7yysas5FU92PsiXNraZ1d4EuJQCguBhj1NLSou7ubqdLgYNcESivTsZc253MsCRd5RghAECRMcbo5Zdf5jKPElfwgXI2nlL/YsK13ckMW1LfYkKz8ZTTpQAAsC3i8biuXLnCdDcKP1Ben3J/dzLDknRjKuZ0GQAAbIurV68qHo8TKFHYgdK2bd2cdt/O7mxsSTemY7LZnAMAKALGGIXDYR09etTpUuCwgg6UM/GU4qniCl/xlK3ZeNrpMgAA2LJIJKIzZ87I7/c7XQocVtCBcjyazGlcyGvpd47UqTqw+x/nNw9U67nqQF6/JtfPBQBAobJtW729vUx3Q5Lkc7qAzYxHk/JIelI/r6c5rI/mVzW/+mDka23laq/wqyHk1XQspT/5YO6paniuJqBXW8KqDng1E0/pp6PL647/6R2P6nNtFfpgfjWnr+expPGVpA4p+FT1AABQCD788ENNTU0RKCGpwDuUY9HkE8Okz5JeqA/q7enHN7u8PR3T+3Pxp/7+beU+/Q/dlbo5HdefvD+nj+ZX9T/urVJDyLs25u5CQgGvpX1VubX707Y0usx5lAAAdzPGyLIsnTt3zulSUAAKNlDatq3xlSdPDe+rDiiVlkYfmUZ+a2RZ16ZimtvCesWTjWW6u5DQpXsrmo6n9IuxqMZXkjrRGHpQp6S7C6s6WJt7x3F8JcnGHACAqxlj9KlPfUrV1dVOl4ICULCBMmVLyRyyYEe5P6fg+TRay33qX1w/ld23kFBb+fpu5OhyUh3luS9ITqbvdyoBAHArYwzT3VhTsIEymWMHryrg0VJiZ3ZNV/g8Wn4k1S4n0yr3rf9tW0qkVZnnhqBcPx8AAIVmampKH3zwAYESawo2UKZzzIg+j6Wkw+2+pG3LY1ny5XECe4qTgwAALtXb2ytJBEqsKdhA6cmxspVkWiHvztyls7RBN7J8g65lyGtpNWUrmUeu9Rbs7zwAAJuLRCJqbW1VV1eX06WgQBTssUG+HC+Zn1hJ6XAeG2LyMbqcVHdlQFcmH+wg7670a+SRXdqNZT5N5LmO8/f+93+k7s5OdXd3q7u7W11dXSxsBgC4Qmb9pJXjuxrFr2ADpdeSfJ4nb8zpW1jVp1vDCnqtdbfq1AQ8Cngtlfst+TzSnrL7R/1MxVI5b4i5Mrmi33i2Wqf3lOnj+VUdqg2qJezTfxlaWjeuo9yvvoXczqGUpNRqXG/+8IcaGBhQPP7gWKOampp1AfPRf6+pqeHhBQA4KhaL6cqVK/ryl7/sdCkoIAUbKC3LUnOZT8PLm3f+JmMpTUSTOlgT1I2HzqL81c5KdVY+2Hn9tedrJUn/5vbM2gHov3usQW8OLOrWzMZnVY4sJ/Uf+xf1aktYr7aENRtP6S/6FjQVS62NqfB71Fbu0w8HFnP+bF215frggw+UTqc1MTGhgYEB9ff3q7+/f+3ff/zjH6u/v1+x2IPPVFVVlTVsdnd3q66ujsAJANhRV69e1erqKusnsU7BBkpJagn7NLr85MPNzXhUn2ktXxco//zj+U1/TXXAo5Rta/gJh4x/MLeqD+aydx9PNoZ0ayauxRx3mnssqfWTI4Y8Ho9aWlrU0tKis2fPPjbWtm1NTk4+Fjb7+/v1V3/1V+rv71c0Gl0bX1FRsS5gPho4GxoaCJwAgC0xxqi8vFxHjx51uhQUkIIOlM1h3xPDpCTdWUioNhhTpd+Tc7DbVxXQjamYZrdw8LkkRZO2Lt1bznl82paay3L7bbcsS3v27NGePXt0+vTpx37etm1NT09vGDh//vOf69/+23+rpaUH0/PhcDhrd7Orq0tNTU0ETgDApowxOnPmjHy+go4Q2GWWXcBXtkzHkvrj9+acLmPbfeNgreoeur5xp9i2rdnZ2cfCZubf+/r6tLCwsDY+FAqthcyNgmdzc7M8uW6/BwAUHdu21djYqL/7d/+u/sk/+SdOl4MCUtD/eVEX9D622cbtgl5LtcHdCWWWZamurk51dXU6fvz4hmPm5ubWhc1M4Lx8+bJ+8IMfaHZ2dm1sIBBQV1dX1mn1lpYWeb07H5QBAM744IMPND09zfpJPKagA6VlWTpaH9LleysqhkhpSXqxPlRQ08o1NTWqqanJuhZmYWFhw+7m9evX9Zd/+ZeamppaG+v3+9XR0ZF1DWdraytTJADgYsYYWZa14bp/lLaCnvKWpNl4St96d/bJA13ijUO1qg0WTxdvaWlpLWRuFDzv3bu3Ntbr9a4LnI92Otva2uT3534nOgBgd33ta1/TtWvXdOPGDadLQYEp+EApSd/7eF4DiwlXdykt3T8U/cv7S+vw8mg0qoGBgQ2n1fv7+zU+Pr421uPxqL29fcOw2dXVpY6ODgUCAQc/DQCUtueee06vvfaa/tW/+ldOl4IC44pA+dF8XH9xN/dzHgvVrz9Tpf3VBKKHxWIxDQ4Obhg2+/v7NTY2psxfUcuy1NbWlnUNZ2dnp4LBnbk1CQBK3eTkpPbs2aPvfve7+o3f+A2ny0GBccWCtn1VAdUEPJpfTbuyS2np/rmXz1QxnfuoUCikAwcO6MCBAxv+fDwe19DQ0IZh82c/+5lGRkb08H8TtbS0ZF3D2dnZqbKyst36aABQVHp7eyWJDTnYkCsCpcey9IWuSn33o80PKy9UtqTXuyrlKaDNOG4RDAa1f/9+7d+/f8OfX11d1fDw8GNhs7+/X729vRoaGlI6/eCs0aampqxrOLu6uhQOh3frowGAqxhj1NbWps7OTqdLQQFyxZR3xlvDS7o6GXNVl9LS/dt0Ptde4XQpJSmRSGhkZCTrGs6hoSElkw+u92xsbMwaNru7u1VRwZ8jgNLU09Ojjo4Off/733e6FBQgVwXKRNrWt9+b1YJLpr4tSVUBj75+sFZ+D93JQpRMJjU6OrrhDvX+/n4NDg4qkXhwPWd9ff2m96lXVVU5+GkAYGfEYjFVV1frn//zf66///f/vtPloAC5KlBK0tBSwlVT3195tlodFayddKtUKqXx8fENw2YmcMbj8bXxtbW1WcNmd3e3ampqnPswAPCUIpGIXnnlFV29ejXrRRkoba4LlJJ0ZXJFbw3nfn+2U15rL9fJRjaBFLN0Oq2JiYkNw2bmf8disbXxVVVVWTcNdXV1qa6urqAOvgcASfpn/+yf6Q/+4A80NzfHBRXYkCsDpSSZ8ah+MRZ1uoysXmkJ66VmNniUOtu2de/evawHv/f39ysaffD3uKKiImvY7O7uVkNDA4ETwK774he/qGg0qrfeesvpUlCgXBsobdtW78RKQYbKV1vCOtdUxosfT2TbtqamprKGzf7+fi0tLa2ND4fDm67h3LNnD3/vAGwr27bV2Nio3/7t39Y//sf/2OlyUKBcGygzMtPfluToRp3M92eaG9vJtm3Nzs5mPfi9v79fCwsLa+NDoVDWHerd3d1qamqSx+Nx8BMBcJv3339fBw8e1I9//GN9/vOfd7ocFCjXB0rp/kadHw0sOrb7O7Ob+/WuSjbgYNfNzc1tGDYz/z47O7s2NhAIZO1udnV1qaWlRV5v8dw1D2Drvv3tb+uNN97Q7OwsJ1kgq6IIlNL9I4V+NrqsK5OxXetWZr7PqcaQXm0t52ggFKT5+fnH7lN/+N+np6fXxvr9fnV2dmY9i7OtrY3ACZSY3/qt39L169d148YNp0tBASuaQJkxtJTQmwOLmltN71iwzHzdmoBHX6ArCZdbWlrKukO9v79fk5OTa2N9Pp86OjqyTqu3t7ezAxQoMgcOHNDnP/95/ct/+S+dLgUFrOgCpSSlbVt3FxK6OrmivsXEtgXLzNfZW+nXicYyPVPl5zpFFL3l5WUNDg5mXcM5MTGxNtbr9aqtrS3rGs729nYFAgEHPw2AfNy7d09NTU368z//c/3Nv/k3nS4HBawoA+XDZuMp3ZiK6cZ0TPHU/Y/qsaR0Dp/64XFBr6UX60N6sSGk2iBTfkDGysrKWuDcqNM5Ojq6Ntbj8ai1tTXrwe8dHR0KBoMOfhoAD/vLv/xLfelLX9LAwAB3eGNTRR8oM2zb1mw8rfFoUuMrSY0uJzS+klQy/fhYn0dqLvOptdyv5jKfmsM+1QY9HMcCPIVYLKahoaGsm4ZGRkaU+X9DlmWppaUl6xrOzs5OlZVxigKwXWzbVsqWkratdFryeCSfZclr3X8e/+E//If63ve+p6GhIadLRYErmUC5Edu2lf7kQUqlJe8nD5LnkwcJwM5bXV3V0NBQ1k1Dw8PDSqcf/Jdfc3Nz1jWcXV1dCoe5UADYiG3bmomn7jdWokmNfdJg2ayx8rP/+B/kXZ7T//G/f1N1QS/vRmRV0oESQOFLJBIaGRnJumloaGhIqVRqbfyePXs2PRqpoqLCwU8D7L7ZeErXp2K6+fDSL0kb5MjHpBIJef33N54GvZaO1od0jKVf2ACBEoCrJZNJjY6OZj2Lc3BwUIlEYm18fX191jWcXV1dnLOHopC2bd1ZWNXVyZj6d2BzanelXycaQ9pXFWBzKiQRKAEUuVQqpbGxsaxrOAcGBrS6uro2vra2dtP71Gtqapz7MEAOOD4PTiBQAihp6XRa4+PjWc/iHBgYUCwWWxtfXV296X3qtbW1rDODI5y84ONkY0if5oKPkkagBIBN2Late/fuZV3DOTAwoGg0uja+srIya9js7u5WfX09gRPbjiuI4TQCJQBsgW3bmpqaynrwe39/v5aXl9fGh8PhrAe/d3V1ac+ePQRO5OXK5IreGl7eta5kNpnv/1p7uU42crxXqSFQAsAOsm1bMzMzWQ9+7+vr0+Li4tr4srKydccgPRo8m5qa5PF4HPxEKBS2bat3YkW/GIs+efAue6UlrJ6mMv7jqIQQKAHAQbZta25ubtP71Ofm5tbGB4NBdXV1ZT2Ls6WlhcBZIsx4tCDDZMYrLWG91My5sKWCQAkABW5+fj7rwe/9/f2amZlZGxsIBNTR0ZF1Wr21tVVeL2cIut2Veyt6a2T5yQMdxvR36SBQAoDLLS4urtuV/minc3Jycm2sz+dbFzgf7XS2tbXJ5/M5+GnwJENLCX33o3mny8jZV56tZqNOCSBQAkCRW15e1sDAQNZp9YmJibWxXq9X7e3tWQ9+7+jokN9POHBKIm3r2+/NOrabO1+Z3d9fP1jLkUJFjkAJACUuGo1qcHAw67T62NjY2liPx6O2trasazg7OjoUDAYd/DTF7a3hJV2djLkiTGZYun9O5efaufa0mBEoAQCbisViGhoayrqGc3R0VJlXiWVZamlpybqGs7OzU6FQyOFP5E5um+p+FFPfxY1ACQDYktXV1ayBc2BgQMPDw0qn02vjm5ubs67h7OzsVDjMzuBHpW1bf/TurOZdMtX9KEtSdcCjbxyq5e7vIkWgBADsqEQioeHh4az3qQ8NDSmVSq2N37NnT9Y1nF1dXaqoKL2p04/m4/qLu4tPHljgfv2ZKu2vDjhdBnYAgRIA4KhkMqmRkZGsm4YGBweVTCbXxjc0NGx6n3plZaWDn2ZnfO/jeQ0sJlzZncywJHVX+vXl/dVOl4IdQKAEABS0VCqlsbGxrAe/Dw4OanV1dW18XV3dpvepV1e7K9DMxlP61ruzTpexbd44VKvaIGehFhsCJQDA1dLptMbHx7Ou4ezv71c8Hl8bX11dvel96rW1tQV1ZeBPRpZ1+d6Kq7uTGZak03vK9Jm2cqdLwTYjUAIAilo6nda9e/eyHvze39+vlZWVtfGVlZVZw2Z3d7fq6+t3LXDatq1/cWtG8VTxvKqDXkvf/FRdQYV2bB2BEgBQ0mzb1uTk5Kb3qS8vP7jmsLy8fNM1nI2NjdsWlqZjSf3xe3Pb8rUKyTcO1qouxLR3MSFQAgCwCdu2NTMzkzVs9vf3a3HxwQ7ssrKyrAe/d3d3q6mpKefAeXsmph8OLD1xXMhr6e8crNV3PpzT/Gr6ieO3i8eS3jhYq/+vb1HjK8kn/4JPfLGrUofqOAC/mBAoAQDYAtu2NTc3lzVsDgwMaG5ubm18MBjM2t3s6upSS0uLPB6PJOmvPrkZ50kR8bNt5Qp4LP2XoQfhs8rv0ec7KtRV6ddqytY7MzH9dDSa91rM4w0hndlTpnK/R/dWkvpvw8saiybX/fyBmoC+9/FCTl/PY0knG8v0WdZRFhUCJQAAO2xubm7T+9RnZmbWxgYCAXV2dqq7u1s93/xDhVq6N+1o+izp732qTv/+4wWNfhL0LEm/9XyNlhNp/ffRZVX4PXq9s1I3pmP6+Vg057qfrwno9a5K/XhoSaPRpE41lun5moD+6L1ZRZP340PQa+l3jtTpTz+Y01Qs9YSveF97uU9fPVCTcx0ofD6nCwAAoNjV1NSopqZGR48e3fDnFxcXNwyb/vqWJ06P76sOKJXWWpiUpL1VfjWEvPrex/OKJm3dW0np52NR/VJbWJHxqNI5tpJO7ynTzemYbs3c3yX/X4aWtK+qVi/Uh3Rh4v5GpnjK1shyQgdrg/pFjmF1fCUp27bZmFNECJQAADissrJSR44c0ZEjR9Z+LJm29X/dnH7ir+0o9z+2frEt7NfkSmqtiyhJfYur+mVvhRpDXk2sPLmT6LGk5rBP5ydW1v14/2JCbeH18WE0mlRHee73dCfTUtqWvOTJouFxugAAAPC4ZI4r0qoCHi0l1q+yLPd7tJxc/2PLn4wp9+f26g97PfJY1tqvW/s6yfRjX2MpkVZVIL9IkevngzsQKAEAKEDpHDdr+zyWkrnOYe+QZNqW35NfuzG1e5vRsQsIlAAAFCBPjm/olWRaoUfmjpcTaZX71n+BTFfx0Y5jNtFUWmnbfqwbWe7zPPY1Ql6Posn8EqKXBFJU+OMEAKAA+XLcsDKxklJDaP2axpFoQo1lXoV9D75Gd6VfsVQ6553YaVsajybVXbl+bWRXpV8j0fVrNhvLvJrI4xxKKffPB3cgUAIAUIC8luTL4S3dt7CqhjKvgg91KfsWEpqKpfR6V6X2lHm1t9KvV1vKdW0ypnxucbx0b0VH60M6UhdUfdCrv9Zx/7zLt6dj68Z1lPvVt5DI+ev6PPc3/aB4ECgBAChAlmWpuezJh7FMxlKaiCZ1sObBzTO2pP9wZ0G2Lf3mgRr99a5KvTMTW3esT3XAo9891qDOiuy7s9+fW9VPRpb1SktYv/V8jZrKfPr+nYV1u8dbwz4FvZY+mIvn/Nmay3wcGVRkODYIAIAC1RL2aXQ5+cSbcsx4VJ9pLdeNhzqHC4m0fnA3++011QGvYsn0E6eqr03FdG0qlvXnT+0p08V7K0rm2Pn0WFJrHkcMwR0IlAAAFKjmsO+JYVKS7iwkVBuMqdLv0WKOm272VfnVO7GieD5z4I/wWNLkSlKX7608efAn0rZy6rzCXfgTBQCgQDWHc39NX5nM3kXcyH8fzf0KxmzSttQ7kXuYzMjnc8EdWEMJAECBqguu32xTDIJeS7VB4kex4U8UAIACZVmWjtaHVCyR0pL0Yn2IDTlFiEAJAEABO9YQUrFcUmhLerEh5HQZ2AEESgAAClht0KvuSr/ru5SWpL2VftUGvU6Xgh1AoAQAoMCdaHR/l9KWdKKxzOkysEMIlAAAFLh9VQHVBDyu7VJakmoCHj1TxfmTxYpACQBAgfNYlr7QVenaLqUt6fWuSnnYjFO0CJQAALhAR4VfJxvdt+PbknSqMaT2Ta54hPsRKAEAcIlPt5arykVT35akqoBHr7aWO10KdhiBEgAAl/B7LL3uoqnvzFS33+OWCIynRaAEAMBFOir8eq3dHR2/19rL1cFUd0kgUAIA4DInG8v0SkvY6TI29UpLWCc5JqhkcDs7AAAu1NN0P6z9YizqcCWPe7UlrHNNhMlSYtm27ZalGAAA4BFXJlf01vCyLMnRtZWZ7/9aezmdyRJEoAQAwOWGlhL60cCiFlbTjoTKzG7u17sqWTNZogiUAAAUgUTa1s9Gl3VlMrZr3crM9znVGNKrreXs5i5hBEoAAIrI0FJCbw4sam41vWPBMvN1awIefYGuJESgBACg6KRtW3cXEro6uaK+xcS2BcvM19lb6deJxjI9U+XnOkVIIlACAFDUZuMp3ZiK6cZ0TPHU/Ve+x5LSObz9Hx4X9Fp6sT6kFxtCqg16d7BiuBGBEgCAEmDbtmbjaY1HkxpfSWp0OaHxlaSS6cfH+jxSc5lPreV+NZf51Bz2qTbokUU3ElkQKAEAKFG2bSttS0nbVioteT2Sz7LksUR4RF4IlAAAANgSrl4EAADAlhAoAQAAsCUESgAAAGwJgRIAAABbQqAEAADAlhAoAQAAsCUESgAAAGwJgRIAAABbQqAEAADAlhAoAQAAsCUESgAAAGwJgRIAAABbQqAEAADAlhAoAQAAsCUESgAAAGwJgRIAAABbQqAEAADAlhAoAQAAsCUESgAAAGwJgRIAAABbQqAEAADAlhAoAQAAsCX/P3KMcLK37WTtAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApQAAAHzCAYAAACe1o1DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABkcklEQVR4nO3dd3RU1f4F8H1n0kOoCb0XRSQFkkAoofcmafQA0jtIR1BRFEFp0gSVmoQuoICggIQOyUxIUX9PfYD00EnPZMr9/YH4ACkTUs7cmf1Z6623/L3JzM77PcfN99xzjiTLsgwiIiIiolekEh2AiIiIiJSNhZKIiIiI8oSFkoiIiIjyhIWSiIiIiPKEhZKIiIiI8oSFkoiIiIjyhIWSiIiIiPKEhZKIiIiI8oSFkoiIiIjyhIWSiIiIiPKEhZKIiIiI8oSFkoiIiIjyhIWSiIiIiPKEhZKIiIiI8oSFkoiIiIjyhIWSiIiIiPKEhZKIiIiI8oSFkoiIiIjyhIWSiIiIiPKEhZKIiIiI8oSFkoiIiIjyhIWSiIiIiPLETnQAIqLCJssyjDJgkGWYTIBKBdhJEtQSIEmS6HhERIrDQklEVk2WZdzTGZGcaUBypgE3Mg1IzjLAYPr3a+1UQFlnO5RzsUPZv/9V0lHNkklE9BKSLMuy6BBERPntvs6Ic3eykXA3Gzrjw685FYBn9Mh/efx1jmoJ3qWcUM/dCSUc1QWUlohI2VgoichqmGQZ51NzoL2djb/S9JAA5McX3KP3qepmD18PJ9Qo6gAVp5ZERP9goSQiq3AlXY99l9LwIMeUb0XyaY/et7iDCp2ruKFSEfsC+BQiIuVhoSQiRdObZBy9ngHN7ewCK5JPe/Q5fh5OaF7eFfYqTiuJyLaxUBKRYl1J12PvpTSk5pgKpUg+TQJQ1EGFLpxWEpGNY6EkIkXS3M7CoasZhTaVfJ5Hn9+moiv8PJwFJiEiEoeFkogURZZlnLqZheM3MkVH+ZfAci5oXMaZxwwRkc3hTTlEpCiWWiYB4PiNTJy6mSU6BhFRoWOhJCLF0Nyy3DL5yPEbmdDcZqkkItvCQklEinAlXY9D1zJExzDLoasZuJKuFx2DiKjQsFASkcXTm2TsvZQGpTyZKAHYeykNehMfUSci28BCSUQW7+j1DGFHA70KGUBqjgnHritjokpElFcslERk0a6k66G5na2YMvmIDCD2djaXvonIJrBQEpHFMsky9iloqftpEoB9l9Jg4ulsRGTlWCiJyGKdT83BAwUtdT9NBvAgx4QLqZxSEpF1Y6EkIoul/ft+biWTAGh5jBARWTkWSiKySPd1RvyVplfsdPIRGcDFND3u64yioxARFRgWSiKySOfuKH86+YgEIP5OtugYREQFhoWSiCyOLMtIuKu8nd3PIwOIv5sNmZtziMhKsVASkcW5pzNCZ7Su8qUzyrivM4mOQURUIFgoicjiJGcazHqdk1rC2LolUcyh8L/KulV1Q4PSzrn6GXN/LyIipbETHYCI6GnJmQaoALxsnte4rAv+TMlBSs7/XtmmgisqFrGHu5Mad7ONWPf7g1x/vruTGoHlXFDW2Q7FHNU4dDUdmttPPgN5KjkTfWsVQ8KdbOjMuGJRJQHJWQbUgWOu8xARWTpOKInI4tzINLy0TNpJgFcpRyTe/fdml8S72fjPA90rf76dSsIDnRHR1zOQrn92kjvZRjzQGfFmSfMKokkGrmfwPEoisk6cUBKRRZFlGclZL18arlHMAUYTcP2pZeRD1x7en+1i5wIPp1fLkJxp+Gd5ukX5508f/5uagzdKOCLOzB3cyVkGyLIMSbKW/etERA9xQklEFsUoAwYz9q5UcrU3q3gWpOsZBpRzsYPazH5oMD2cVBIRWRsWSiKyKAYzj9Yp6qB67nJ0YUnXm2CnkuBqZ/5Xqbm/HxGRkrBQEpFFMZnZEe1UEgyCx32PyqG9yvwlbCNPDiIiK8RCSUQWRWXmt1KWwQQnc9eaC4iT+mHYTHPW6P+m5rcuEVkhfrURkUWxM3PDys0sI9ydxO4r9HBSIzXHiKxcHMJu7u9HRKQkLJREZFHUEmDOI4kXU3Pg7qyG41NTyuIOKpR2VsPVXoKdCijtrEZpZzVysSoNlfTYz6kAN/uH71n8qQPUKxWxx8U0848CslMhVzmIiJSCxwYRkUWRJAllne1wNePFO7hvZxtxM9OAN4o7Iv6xsyg7VXZDZTf7f/56UO0SAIAvf733zwHo0+u5Y9+lNCTde/ZZlW72qn9+DgAalnFBwzIuuJymx6b/pgB4WHxrFXPAtvOpZv9uZZ3teGQQEVklFkoisjjlXOxwPePlh5ufTM5Ey/KuTxTKR4XveYo5qGCUZVx9wSHjKTkmzDt354Xv41XKCTcyDf86B/N5VBJQ3tX+5S8kIlIgFkoisjhlXexeWiYB4HyqHiUcs+Fmr0KamUcI1SjqgPg72bivy9t2a6Ms4+DVDLNfb5IfTiiJiKwRv92IyOKUdTH/q+npO7ZfxtxbbV4m8W7ur3bMze9FRKQk3JRDRBanpOO/N9sonaNaQglHfuUSkXXitxsRWRxJkuBdygnWUiklAD6lnLghh4isFgslEVmkeu5OsJZLCmUAPu5OomMQERUYFkoiskglHNWo6mav+CmlBKCamz1KOKpFRyEiKjAslERksXw9lD+llAH4ejiLjkFEVKBYKInIYtUo6oDiDirFTiklPLy5p3pRnj9JRNaNhZKILJZKktC5iptip5QygC5V3KDiZhwisnIslERk0SoVsYefh/I2tJhMRlyM3gPj3euioxARFTgWSiKyeCXvXEDqzeswGY2io5hFAuAMIw6tnAdvb29s2rRJdCQiogLFQklEFm3Lli1o2jgAsWs/g0qtjK8sGUDo6x6I08Sga9eu6Nu3L/r06YMHDx6IjkZEVCCU8e1MRDbHYDBgypQp6N27N4KDg/Hd+q/QpmIR0bHM0qaiKyoVsUexYsUQERGBzZs344cffoCXlxeio6NFxyMiyncslERkce7evYuOHTti8eLFWLx4MSIiIuDi4gI/D2cElnMRHe+FAss9zPm4Xr16ITExETVq1ECrVq0wbdo05OTkCEpIRJT/JFmWlbqBkoisUHx8PIKCgpCeno5t27ahZcuWT/znsizj1M0sHL+RKSjh8zUr54JGZZyfe8Wi0WjEokWLMHPmTLz55puIiopCnTp1CjklEVH+44SSiCzGpk2b0LhxY5QsWRIajeZfZRJ4eM93k7IuaFPR9eFfF3bIp/P8/e9tKrqicVmXF97XrVarMWXKFMTExECn08HX1xfLly8H/1xPRErHQklEwhkMBkyaNAl9+/ZFSEgITpw4gSpVqrzwZ/w8nNG3VjEUFXjwuQSgqIMKfWsV+9cy94v4+PhAq9Vi6NChGDt2LDp16oTk5OSCC0pEVMC45E1EQt25cwc9e/bE0aNHsWjRIowdO/aFU76n6U0yjl7PgOZ2NiSgUA5Bf/Q5/h5OaFbeFfaqV6+0+/fvx6BBg2AwGPDNN9/grbfeyrecRESFhYWSiISJi4tDcHAwMjMzsW3bNrRo0eKV3+tKuh77LqXhQY6pwIrlo/ct7qBC5ypuqFQkf65UvH37NoYOHYrvvvsOQ4YMweLFi1GkiDJ2tBMRASyURCRIVFQUhgwZgjfffBM7d+5E5cqV8/yeJlnGhVQ9tLezcDFNn2/F8tH7VHOzh6+HM6oXtc/36xRlWcbatWsxfvx4lCtXDlFRUWjQoEG+fgYRUUFhoSSiQvXofMklS5agf//+WLVqFZydzX/+0Fz3dUbE38lG/N1s6IwPv+ZUEmAy4xvv8dc5qiX4lHKCj7sTSjiq8z3n0/7880/069cPWq0WH3zwAWbMmAE7O7sC/1wiorxgoSSiQnP79m306NEDJ06cwOLFizF69OhcPS/5KmRZxn2dCcmZBiRnGXA9Q4/kLAMMpn+/1k4FlHW2Q3lXe5R1tkNZFzuUcFQVeMan6fV6fPzxx/j444/RsGFDREZGonr16oWagYgoN1goiahQxMXFISgoCFlZWdixYweaNWsmLIssyzDJgEGWYTQBahVgJ0lQSSj08vgip0+fRr9+/XDr1i0sW7YMAwYMsKh8RESP8NggIipwERERaNKkCcqUKQOtViu0TAIPS6NaJcFRrYKLvQqOahXUKsniylqjRo0QHx+PsLAwvP322wgLC8Pdu3dFxyIi+hcWSiIqMHq9HuPHj0f//v3Ru3dvHDt2DJUqVRIdS1Hc3Nywdu1a7NixA0eOHIGXlxcOHjwoOhYR0RNYKImoQNy6dQtt27bFypUrsWLFCqxZswZOTk6iYylWSEgIEhMT8eabb6Jdu3Z45513kJ2dLToWEREAPkNJRAVAo9EgKCgIOTk52LFjBwIDA0VHshomkwnLli3DtGnTUKtWLURFRcHLy0t0LCKycZxQElG+2rBhA5o2bYry5ctDq9WyTOYzlUqF8ePHIzY2FpIkwd/fH4sWLYLJ9Ixt60REhYSFkojyhV6vx9ixYzFw4ED07dsXR48eRcWKFUXHslqenp6IiYnB2LFjMWnSJLRr1w5Xr14VHYuIbBSXvIkoz27evImwsDCcOXMGS5cuxfDhwy1ux7Q1O3z4MAYMGIDMzEysXr0aYWFhoiMRkY3hhJKI8iQ2NhZ+fn74448/cOTIEYwYMYJlspC1bt0aiYmJaNOmDXr06IGBAwciNTVVdCwisiEslET0ytatW4fAwEBUrFgRWq0WTZo0ER3JZpUsWRJbt27Fhg0bsHPnTnh7e+PkyZOiYxGRjWChJKJcy8nJwejRozFo0CD0798f0dHRqFChguhYNk+SJPTv3x8JCQmoUKECmjVrhvfeew96vV50NCKycnyGkohyJTk5GWFhYTh79iyWL1+OYcOGiY5Ez2AwGDB//nzMnj0b9erVQ2RkJF577TXRsYjISnFCSURmO3v2LHx9ffHf//4X0dHRLJMWzM7ODjNnzsSpU6eQkpKCevXq4auvvgJnCERUEFgoicgsa9asQbNmzVClShVotVo0btxYdCQyg7+/P+Li4hAeHo7hw4fjrbfewq1bt0THIiIrw0JJRC+Uk5ODkSNHYsiQIXj77bdx5MgRlC9fXnQsygVXV1esWrUK33//Pc6cOQNPT0/88MMPomMRkRVhoSSi57px4wZatmyJtWvX4quvvsKqVavg6OgoOha9oq5duyIpKQl+fn7o3LkzRo8ejczMTNGxiMgKcFMOET3TmTNnEBISAlmWsXPnTgQEBIiORPlElmV8+eWXmDRpEqpWrYqoqCjUr19fdCwiUjBOKInoX77++ms0a9YM1apVg1arZZm0MpIkYdSoUYiLi4OLiwsaNmyIefPmwWg0io5GRArFQklE/9DpdBg+fDiGDRuGIUOG4Oeff0a5cuVEx6IC8sYbb+D06dOYMmUK3n33XbRq1QqXLl0SHYuIFIhL3kQEALh+/TpCQ0Oh1WqxcuVKDB48WHQkKkTHjh1DeHg4Hjx4gJUrV6Jv376iIxGRgnBCSUQ4deoUfH19cfnyZRw7doxl0gY1a9YMiYmJ6NatG/r164c+ffrgwYMHomMRkUKwUBLZuNWrV6NFixaoWbMmNBoNGjZsKDoSCVKsWDFERERg8+bN+OGHH+Dl5YXo6GjRsYhIAVgoiWyUTqfDsGHDMGLECAwbNgyHDx9G2bJlRcciC9CrVy8kJiaiRo0aaNWqFaZOnQqdTic6FhFZMD5DSWSDrl27hpCQEMTHx+PLL7/E22+/LToSWSCTyYSFCxdi5syZePPNNxEVFYU6deqIjkVEFogTSiIbc/LkSfj5+eHq1as4fvw4yyQ9l0qlwpQpUxATEwOdTgdfX18sX76c94ET0b+wUBLZiEeHWbdo0QKvvfYatFot/P39RcciBfDx8YFWq8XQoUMxduxYdOrUCTdu3BAdi4gsCAslkQ3Izs7GkCFDMGrUKIwcORKHDh1CmTJlRMciBXF2dsbSpUuxf/9+xMfHw8vLC999953oWERkIVgoiazc1atX0bx5c0RFRWH9+vVYunQp7O3tRcciherQoQMSExPRpEkTdO/eHUOHDkV6erroWEQkGDflEFmx48ePIzQ0FI6Ojti5cyf8/PxERyIrIcsy1q5di/Hjx6NcuXKIjIzkkVNENowTSiIrJMsyVqxYgVatWuGNN96ARqNhmaR8JUkSBg8ejHPnzqFkyZJo0qQJPvroIxgMBtHRiEgAFkoiK5OdnY3BgwdjzJgxGD16NA4ePIjSpUuLjkVWqlatWjhx4gRmzZqFDz/8EM2aNcP58+dFxyKiQsYlbyIrcuXKFQQHB+OXX37BV199hfDwcNGRyIacPn0a/fr1w61bt7B06VIMHDgQkiSJjkVEhYATSiIrcezYMfj5+eHWrVs4efIkyyQVukaNGiE+Ph5hYWEYNGgQwsLCcPfuXdGxiKgQsFASKZwsy1i2bBlat26NN998ExqNBvXr1xcdi2yUm5sb1q5dix07duDIkSPw9PTEwYMHRcciogLGQkmkYFlZWRg4cCDGjRuHsWPH4qeffoKHh4foWEQICQlBUlIS6tati3bt2uGdd95Bdna26FhEVED4DCWRQl2+fBnBwcH49ddf8c0336Bv376iIxH9i8lkwrJlyzBt2jTUqlULUVFR8PLyEh2LiPIZJ5REChQdHQ0/Pz/cuXMHp06dYpkki6VSqTB+/HhoNBqoVCr4+/tj0aJFMJlMoqMRUT5ioSRSEFmW8cUXX6BNmzbw8vKCRqNBvXr1RMcieqm6desiJiYGY8eOxaRJk9C2bVtcvXpVdCwiyicslEQKkZWVhQEDBmDChAmYMGECDhw4AHd3d9GxiMzm6OiIBQsW4NChQ/j999/h5eWF7du3i45FRPmAhZJIAS5duoQmTZpgx44d2LRpExYsWAA7OzvRsYheSevWrZGYmIg2bdqgR48eGDBgAFJTU0XHIqI84KYcIgt35MgR9OjRA0WKFMHu3bvh7e0tOhJRvpBlGRERERgzZgxKlSqFiIgING3aVHQsInoFnFASWShZlrF48WK0bdsWPj4+0Gg0LJNkVSRJQv/+/ZGQkIAKFSqgefPmmDVrFvR6vehoRJRLLJREFigzMxPh4eGYOHEiJk6ciP3796NUqVKiYxEViGrVquHo0aOYM2cO5s+fj8aNG+OPP/4QHYuIcoFL3kQW5q+//kJQUBD++OMPrF27Fj179hQdiajQxMbGol+/frh69SoWL16MoUOH8j5wIgXghJLIghw+fBh+fn5ISUnBqVOnWCbJ5vj7+yMuLg79+/fH8OHD8dZbb+HWrVuiYxHRS7BQElkAWZaxcOFCtGvXDr6+vnxekmyaq6srvvzyS3z//fc4c+YMPD09sW/fPtGxiOgFWCiJBMvMzETfvn0xefJkTJkyBT/88ANKliwpOhaRcF27dkVSUhL8/PzQpUsXjBo1CpmZmaJjEdEz8BlKIoEuXryIoKAg/Pnnn1i3bh169OghOhKRxZFlGatWrcKkSZNQpUoVREVFoX79+qJjEdFjOKEkEuTgwYPw8/NDeno6zpw5wzJJ9BySJGHkyJGIi4uDi4sLGjZsiHnz5sFoNIqORkR/Y6EkKmSyLOPzzz9Hhw4d4O/vj9jYWHh6eoqORWTxateujdOnT2PKlCl499130bJlS1y6dEl0LCICCyVRocrIyEDv3r0xdepUTJs2Dfv27UOJEiVExyJSDAcHB8ydOxdHjx7F5cuX4eXlhaioKNGxiGwen6EkKiQXLlxA9+7dceHCBaxfvx6hoaGiIxEpWkpKCsaMGYPIyEj07t0bK1as4B/QiAThhJKoEPz000/w8/NDVlYWzp49yzJJlA+KFSuGiIgIbN68Gfv374e3tzeio6NFxyKySSyURAVIlmXMnz8fHTt2REBAAGJiYvDmm2+KjkVkVXr16oXExETUqFEDrVq1wtSpU6HT6UTHIrIpLJREBSQ9PR09e/bE9OnTMWPGDOzZs4fLcUQFpFKlSjh8+DDmz5+PJUuWICAgAL/99pvoWEQ2g4WSqACcP38ejRo1wv79+/Htt9/i448/hlqtFh2LyKqpVCpMmTIFMTExyMnJga+vL5YtWwZuFSAqeCyURPnswIED8PPzg06nw9mzZxEcHCw6EpFN8fHxgUajwdChQzFu3Dh06tQJN27cEB2LyKqxUBLlE1mW8emnn6JTp05o0qQJYmJiUKdOHdGxiGySs7Mzli5div379yM+Ph6enp7YvXu36FhEVouFkigfpKenIywsDO+++y5mzZqF77//HsWLFxcdi8jmdejQAYmJiQgMDERQUBCGDh2K9PR00bGIrA7PoSTKoz///BNBQUG4fPkyNm7ciO7du4uORERPkWUZa9euxfjx41G2bFlERUWhYcOGomMRWQ1OKInyYP/+/fD394der8fZs2dZJokslCRJGDx4MOLj4+Hu7o4mTZrgo48+gsFgEB2NyCqwUBK9AlmW8cknn6Bz585o1qwZYmJi8MYbb4iORUQvUbNmTRw/fhyzZs3Chx9+iMDAQJw/f150LCLFY6EkyqW0tDSEhoZi1qxZ+OCDD7B7924UK1ZMdCwiMpO9vT1mz56NEydO4NatW/Dx8cG6det4vBBRHvAZSqJc+OOPP9C9e3dcvXoVkZGR6Natm+hIRJQHaWlpmDBhAtauXYvg4GB89dVXKFWqlOhYRIrDCSWRmfbt24cGDRpAlmXExMSwTBJZATc3N6xZswbffvstoqOj4enpiZ9++kl0LCLFYaEkegmTyYQ5c+aga9euaN68Oc6ePYvatWuLjkVE+Sg4OBhJSUmoW7cu2rdvjwkTJiA7O1t0LCLF4JI30QukpqZiwIAB2L17Nz788EPMmjULKhX/HEZkrUwmE5YtW4Zp06ahZs2aiIqKgre3t+hYRBaP/2Qkeo7ff/8dDRs2xM8//4w9e/bg/fffZ5kksnIqlQrjx4+HRqOBWq1GgwYNsHDhQphMJtHRiCwa/+lI9Ax79uxBgwYNIEkSYmNj0aVLF9GRiKgQ1a1bFzExMRg7diwmT56Mtm3b4urVq6JjEVksFkqix5hMJnz44Yfo1q0bWrVqhTNnzuC1114THYuIBHB0dMSCBQtw6NAh/P777/D09MS2bdtExyKySCyURH9LSUlBUFAQPvzwQ3z88cf49ttvUbRoUdGxiEiw1q1bIzExEe3atUPPnj3Rv39/pKamio5FZFG4KYcIwH/+8x90794dycnJiIqKQufOnUVHIiILI8syIiMjMXr0aJQqVQoRERFo2rSp6FhEFoETSrJ53333HRo0aAC1Wo3Y2FiWSSJ6JkmSEB4ejsTERFSsWBHNmzfHrFmzoNfrRUcjEo6FkmyWyWTCBx98gO7du6Nt27Y4c+YMatWqJToWEVm4qlWrIjo6GnPmzMH8+fPRuHFj/P7776JjEQnFQkk2KSUlBW+99RbmzJmDTz75BDt27ICbm5voWESkEGq1Gu+++y5OnTqF1NRU1K9fH6tXr+Z94GSz+Awl2ZzffvsNQUFBuHXrFjZt2oSOHTuKjkRECpaRkYHJkydj1apV6NKlC9asWYPSpUuLjkVUqDihJJuye/duNGzYEPb29oiNjWWZJKI8c3V1xZdffonvv/8eZ8+ehaenJ/bt2yc6FlGhYqEkm2AymfDee+8hKCgIHTp0wJkzZ1CzZk3RsYjIinTt2hVJSUnw9/dHly5dMGrUKGRmZoqORVQouORNVu/Bgwfo27cv9u/fj08//RRTp06FJEmiYxGRlZJlGatWrcKkSZNQuXJlREVFwdfXV3QsogLFCSVZtV9//RX+/v44deoU9u/fj2nTprFMElGBkiQJI0eORFxcHFxdXREQEIBPP/0URqNRdDSiAsNCSVZr586dCAgIgLOzMzQaDdq3by86EhHZkNq1a+P06dOYMmUKZs6ciZYtW+Kvv/4SHYuoQLBQktUxGo2YOXMmQkJC0KlTJ5w+fRo1atQQHYuIbJCDgwPmzp2Lo0eP4vLly/D29kZkZCSPFyKrw0JJVuX+/fvo2rUr5s2bh/nz52PLli1wdXUVHYuIbFxgYCASEhLQrVs3hIeHo0+fPrh//77oWET5hptyyGr88ssv6N69O+7du4ctW7agXbt2oiMREf3Lli1bMHLkSBQpUgQbN25Ey5YtRUciyjNOKMkq7NixAwEBAXB1dYVGo2GZJCKL1atXLyQmJqJmzZpo3bo1pk6dCp1OJzoWUZ6wUJKiGY1GzJgxA2FhYejatStOnTqF6tWri45FRPRClSpVwuHDh/HZZ59hyZIlaNiwIX799VfRsYheGQslKda9e/fQuXNnfPbZZ1iwYAE2bdrE5yWJSDFUKhUmT56MmJgY6PV6+Pn5YdmyZdywQ4rEZyhJkZKSktC9e3c8ePAAW7duRZs2bURHIiJ6ZVlZWZg2bRqWLVuG9u3bY926dShXrpzoWERm44SSFGfbtm0ICAhA0aJFodFoWCaJSPGcnZ2xdOlS7N+/HwkJCfD09MSuXbtExyIyGwslKYbRaMS0adPQs2dPdO/eHSdPnkS1atVExyIiyjcdOnRAUlISAgMDERwcjCFDhiA9PV10LKKX4pI3KcK9e/fQu3dvHDp0CJ9//jneeecdXqFIRFZLlmWsXbsW48ePR9myZREZGYmAgADRsYieixNKsngJCQnw8/ODVqvFwYMHMXHiRJZJIrJqkiRh8ODBiI+Ph7u7O5o2bYoPP/wQBoNBdDSiZ2KhJIu2ZcsWNGrUCMWLF4dWq0WrVq1ERyIiKjQ1a9bE8ePHMWvWLHz00UcIDAzE+fPnRcci+hcWSrJIBoMBU6ZMQe/evREcHIwTJ06gSpUqomMRERU6e3t7zJ49GydOnMCtW7fg4+ODtWvX8nghsigslGRx7t69i44dO2Lx4sVYsmQJIiIi4OLiIjoWEZFQjRo1Qnx8PHr06IHBgwcjNDQUd+/eFR2LCAA35ZCFiY+PR1BQENLT07Ft2zbecUtE9Aw7d+7E0KFD4ejoiPXr1/O6WRKOE0qyGJs2bULjxo1RsmRJaLValkkioucIDg5GUlIS6tati/bt22PChAnIysoSHYtsGAslCWcwGDBp0iT07dsXYWFhOHHiBCpXriw6FhGRRStfvjwOHDiAL774AqtWrYK/vz8SEhJExyIbxUJJQt25cwft27fHF198gS+++ALr16+Hs7Oz6FhERIqgUqkwbtw4aDQaqNVqNGjQAAsXLoTJZBIdjWwMn6EkYeLi4hAcHIzMzExs374dzZs3Fx2JiEixdDodZs2ahQULFqBly5bYsGEDKlWqJDoW2QhOKEmIqKgoNGnSBB4eHtBqtSyTRER55OjoiM8//xyHDx/GH3/8AS8vL2zbtk10LLIRLJRUqAwGA9555x3069cPvXr1wvHjx/knaCKifNSqVSskJiaiXbt26NmzJ/r374+UlBTRscjKccmbCs3t27fRo0cPnDhxAkuWLMGoUaN4hSIRUQGRZRmRkZEYPXo0SpYsicjISDRt2lR0LLJSnFBSodBqtfD19cVvv/2Gw4cPY/To0SyTREQFSJIkhIeHIzExEZUqVULz5s0xc+ZM5OTkiI5GVoiFkgpcREQEmjZtirJly0Kr1aJZs2aiIxER2YyqVasiOjoac+bMwWeffYbGjRvj999/Fx2LrAwLJRUYvV6P8ePHo3///ujduzeOHTuGihUrio5FRGRz1Go13n33XZw+fRppaWmoV68eVq1axfvAKd+wUFKBuHXrFtq2bYuVK1dixYoVWLNmDZycnETHIiKyaX5+foiLi8OAAQMwcuRIdOvWDbdu3RIdi6wAN+VQvtNoNAgKCoJer8eOHTv4EDgRkQXas2cPBg8eDEmSsGbNGnTp0kV0JFIwTigpX23YsAFNmzZFhQoVoNVqWSaJiCxU165dkZSUBH9/f3Tt2hWjRo1CZmam6FikUCyUlC/0ej3Gjh2LgQMHIjw8HEePHkWFChVExyIiohcoU6YM9uzZg5UrV2L9+vWoX78+tFqt6FikQCyUlGc3b95E69atsXr1aqxatQpfffUVHB0dRcciIiIzSJKEkSNHIi4uDq6urggICMCnn34Ko9EoOhopCJ+hpDyJiYlBcHAwjEYjvv32WzRu3Fh0JCIiekU5OTmYPXs25s2bhyZNmiAiIgJVq1YVHYsUgBNKemXr1q1Ds2bNUKlSJWi1WpZJIiKFc3BwwNy5c3H06FFcuXIF3t7eiIyM5PFC9FIslJRrOTk5GD16NAYNGoQBAwYgOjoa5cuXFx2LiIjySWBgIBISEtCtWzeEh4ejd+/euH//vuhYZMG45E25kpycjLCwMJw9exbLly/HsGHDREciIqICtGXLFowcORJFihTBxo0b0bJlS9GRyAJxQklmO3v2LHx9fXH+/HkcPXqUZZKIyAb06tULiYmJqFWrFlq3bo0pU6ZAp9OJjkUWhoWSzLJmzRo0a9YMVatWhVarRaNGjURHIiKiQlKpUiUcOnQIn332Gb744gs0bNgQv/76q+hYZEFYKOmFcnJyMHLkSAwZMgSDBg3CkSNHUK5cOdGxiIiokKlUKkyePBkxMTHQ6/Xw9fXF0qVLYTKZREcjC8BnKOm5bty4gdDQUGg0GqxYsQJDhgwRHYmIiCxAVlYWpk+fjqVLl6J9+/ZYt24dhw02joWSnun06dMICQmBJEnYuXMnGjZsKDoSERFZmB9//BEDBw6EXq/H119/jaCgINGRSBAuedO/fP3112jevDmqV68OrVbLMklERM/Uvn17JCUlITAwEMHBwRg8eDDS09NFxyIBWCjpHzqdDsOHD8ewYcMwdOhQ/PzzzyhbtqzoWEREZMHc3d2xc+dOfPPNN9i6dSt8fHxw5swZ0bGokLFQEgDg+vXraNmyJdavX481a9ZgxYoVcHBwEB2LiIgUQJIkDB48GPHx8XB3d0fTpk3x4YcfwmAwiI5GhYTPUBJOnTqFkJAQqNVq7Ny5Ew0aNBAdiYiIFMpgMODjjz/Gxx9/DD8/P0RGRqJmzZqiY1EB44TSxq1evRotWrRArVq1oNVqWSaJiChP7OzsMHv2bBw/fhy3b9+Gj48P1q5dy/vArRwLpY3S6XQYNmwYRowYgeHDh+Pw4cMoU6aM6FhERGQlGjVqhPj4ePTs2RODBw9GaGgo7ty5IzoWFRAueduga9euISQkBPHx8Vi1ahUGDhwoOhIREVmxnTt3YujQoXB0dMT69evRrl070ZEon3FCaWNOnjwJPz8/XLt2DSdOnGCZJCKiAhccHIykpCR4enqiffv2GD9+PLKyskTHonzEQmkjZFnGl19+iRYtWuC1116DVquFn5+f6FhERGQjypcvj/379+OLL77A6tWr4e/vj4SEBNGxKJ+wUNqA7OxsDBkyBKNGjcKoUaNw6NAhlC5dWnQsIiKyMSqVCuPGjYNGo4FarUaDBg2wYMEC3gduBfgMpZW7evUqQkJCkJiYiNWrV6N///6iIxEREUGn02HWrFlYsGABWrZsiQ0bNqBSpUqiY9ErYqG0YsePH0doaCgcHR2xa9cu+Pr6io5ERET0hJ9//hn9+/dHRkYGVq1ahZ49e4qORK+AS95WSJZlrFixAq1atUKdOnWg1WpZJomIyCK1atUKiYmJaNeuHXr16oX+/fsjJSVFdCzKJRZKK5OdnY3BgwdjzJgxGDNmDA4ePAgPDw/RsYiIiJ6rZMmS2LJlCzZu3Ijdu3fD29sbx48fFx2LcoGF0opcuXIFgYGB2Lx5MyIiIrB48WLY2dmJjkVERPRSkiQhPDwciYmJqFSpElq0aIGZM2ciJydHdDQyA5+htBLHjh1DWFgYnJ2dsXPnTtSvX190JCIioldiNBoxf/58fPDBB/D29kZkZCRq164tOha9ACeUCifLMpYtW4bWrVujbt260Gg0LJNERKRoarUa7777Lk6fPo20tDTUr18fq1atspj7wGVZhsEkI9toQqbehGyjCQaTbDH5ROCEUsGysrIwYsQIbNy4ERMnTsT8+fO5xE1ERFYlIyMDkydPxqpVq9ClSxesWbOmUM9SlmUZ93RGJGcakJxpwI1MA5KzDDA84+hMOxVQ1tkO5VzsUPbvf5V0VEOSpELLKwoLpUJdvnwZwcHB+O233/DNN9+gT58+oiMREREVmL1792LQoEGQJAlr1qxBly5dCvTz7uuMOHcnGwl3s6EzPqxKKgDmHMH++Osc1RK8SzmhnrsTSjiqCyiteCyUChQdHY2wsDC4urpi9+7d8PHxER2JiIiowN28eRODBw/Gvn37MGLECCxcuBAuLi759v4mWcb51Bxob2fjrzQ9JAD5UZIevU9VN3v4ejihRlEHqKxsaslCqSCyLGPp0qWYNGkSWrRogS1btsDd3V10LCIiokIjyzJWr16NiRMnonLlyoiKisqXs5avpOux71IaHuSY8q1IPu3R+xZ3UKFzFTdUKmJfAJ8iBjflKERWVhYGDBiACRMmYOLEiThw4ADLJBER2RxJkjBixAjExcXB1dUVAQEB+PTTT2E0Gl/p/fQmGYeupiPqzxSk5DxcqC6oSduj903JMSHqzxQcupoOvck65nqcUCrApUuXEBQUhP/85z9Yu3YtevXqJToSERGRcDk5OZg9ezbmzZuHJk2aICIiAlWrVjX756+k67H3UhpSc0wFViJfRAJQ1EGFLlYwrWShtHBHjhxBjx494Obmhl27dsHb21t0JCIiIoty/PhxhIeH4969e1ixYgX69ev30p3VmttZOHQ1o8CWt8316PPbVHSFn4ezwCR5wyVvCyXLMhYvXoy2bduiXr16iI2NZZkkIiJ6hsDAQCQkJOCtt95C//790atXL9y/f/+Zr5VlGSeTM3HoasbDvy7MoM/K8/e/H7qagZPJmYo9y5KF0gJlZmYiPDwcEydOxKRJk/DDDz+gVKlSomMRERFZrGLFiiEiIgKbN2/GTz/9BC8vL/z888//et2pm1k4fiNTQMKXO34jE6duZomO8UpYKC3MX3/9hSZNmmDXrl3YunUrDysnIiLKhV69eiExMRG1atVCmzZtMGXKFOh0OgCA5pbllslHjt/IhOa28koln6G0IIcOHUKvXr1QrFgx7Nq1C15eXqIjERERKZLJZMKiRYvw7rvv4o033sCyyO04ZSgpOpbZ+tYqpqiNOjY9obSUuzhlWcbChQvRvn17+Pn5ITY2lmWSiIgoD1QqFSZPnoyYmBjIKjX2XU4HZHPuuRFPArD3UpqijhSymQmlpd7FmZmZiSFDhmDz5s2YMWMG5syZA7Xaeq9mIiIiKmwH/nqAc/dyIEnKmaNJAPw8nNC6YhHRUcxi9Q/nvcpdnAYTcDXDgOsZhgK9i/PixYsICgrCf//7X2zfvh2hoaH58r5ERET00JV0PeLvGxRVJoGHu79jb2fjteKOilj6tsoJpRLu4jx48CB69eqFEiVKYPfu3ahbt24+JCQiIqJHTLKMr367jxRBB5fnlQSgmIMKw+qUsPi7v61uQvn0XZxA/p0x9eh9LqXp8Vea/pXu4pRlGQsWLMD06dPRrl07bNq0CSVKlMinhERERPTI+dQcPMhRxnOTzyIDeJBjwoVUPWoWcxAd54WUNf99ASXcxZmRkYHevXtj6tSpmD59Ovbu3csySUREVEC0t7Nh2XO9l5MAaBVwjJBVTCgfv4sTKLxT7x99jvZ2Nv5MyXnhXZwXLlxA9+7dceHCBezYsQMhISGFlJKIiMj23NcZ8VeaXnSMPJMBXEzT477OmG97OAqC4ieUmttZiPozRdjF7sDD/2en/j2tfNZhpD/++CP8/PyQlZWFs2fPskwSEREVsHN3lD+dfEQCEH8nW3SMF1JsoVTCXZyyLGP+/Pno1KkTGjVqhNjYWLz55ptCcxIREVk7WZaRcDdbeDfILzKA+LvZFn3Pt2ILpaXfxRl9JQU9e/bE9OnTMXPmTOzZswfFixcXHY2IiMjq3dMZ/zkq0FrojDLu6yx3g5EiC6US7uI8e9eA286lsXPnTnz00UdQqRT5XzUREZHiJGcazH6tk1rC2LolUcyh8P85Hf5aMbyei93bufm9CpviNuVcSdfj0LUM0THM0n7CB/CrVVx0DCIiIpuSnGl46SUmjzQu64I/U3L+OSEGAIraq9CuUhFUcbNHjlHGL/eyEX09M1dL6JVc7dCwjAvKuKjhZq/GtxdS8WdKzhOvOZWcidYViuD3p/7vz6KSgOQsA+rAMRcpCo+ixmZ6k4y9l9IU85CtBElxd3ESEREp3Y1Mg1ll0k4CvEo5IvHu/za8SABCaxSFWgIi/niAfZfT4FnSCYHlXHKVwV4t4WaWAQevPH8IdiFVDwe1hBpFX36etUkGrmdY7q51RRXKo9czhO7mzq1Hu7+PXVfGRJWIiEjpZFlGcpZ5S8M1ijnAaAKuP7aUXK2oPdyd1NhzKQ23soy4kKrHsRuZqO/hBFUuJloXUvU4fiMTf7xg+igDuJCagzdKmDd1TM4yWOzGHMUUyivpemhuK2/H1qO7OK+kW+6fKoiIiKyFUQYMZu5dqeRq/6/yWcHFHrezjMg0/K9xXEzLgZNaBQ+n/D8H8nqGAZVczbtxz2B6OKm0RIoolCZZxj4FLXU/TQKw71IaTBb6pwoiIiJrYcjFP2uLOqiQrn+yfbraq5DxVCPN+Ps1rvb5X5vS9Sa45WJDUG5+v8KkiEL56C5Oy/yv8OUev4uTiIiICo4pFyfr2KkkGASP/AyyDJUkwc7MqZnRQk8OUkSh5F2cREREZI7cnNKXZTDBSf1kw8jQm+Bq9+SbPJpMZujzv805qSXkGGUYzOy1agttbhYa638e3cWp1OnkI4/fxUlEREQFw04yfwR1M8sId6cnT1C8lqmHh7MaLo+NDKu62SPbaMKd7Pz/Z7iHsx1umrmJCMjd71eYLL5Q8i5OIiIiMpdaAuzMbDcXU3Pg7qyG42NTyoupetzJNqJLFTeUdlajmps9mpVzRdztbOTm8h17FVDaWY3Szg838hR3UKG0sxpFn3oOs5KrPS6mvvwcSuDh75WbneaFyaILJe/iJCIiotyQJAllnc27t+V2thE3Mw14o/j/ju2RAew4nwpZBsJfK46uVdzwy73sJ27oK+agwvR67qhc5Pm7s8u52GNQ7RIYVLsEAKB1xSIYVLvEE+dZFrFXoYKrHZLu6czKW9bZDpKFTigt+qYca76Ls2QBHD1AREREQDkXO1zPMO9w85PJmWhZ3hXxjx1unqo3YfuF1Of+TDEHNbINphcuVV9O12PeuTsv/Gw/Dyck3dMhzYxnM1USUN7M44VEsOgJpbl3VirpHk7Asu/iJCIiUrqyLnZmlUkAOJ+qR/zdbLjl4kigGkXtcepmVp6HXpkGGcdumHf5iUmG2ZNXESw3Gcy/i/NZ93C2qeCKikUennZ/N9uIdb8/eKUMrxd3QLNyLijmoMY9nRHR1zOeOP4nN/dwApZ/FycREZHSlXXJXb3R3M7d/oYj1zNf/iIzxNzK3ekvuf29CpNFTyjNuYvzWfdwPpJ4Nxv/eWDecwnPUsHVDm9VdUPCXR3W/ecB/kzJQUi1onB/bLk6N/dwApZ/FycREZHSlXR8cqONNXBUSyjhaLm1zWKTmXsX57Pu4QSAQ9cyEHcnGw90r35mlJ+HMy6k6hFzKwt3dUYcv5GJ5CwDfD2c/pcTubuHE7DsuziJiIiUTpIkeJdysqpTYnxKOVnshhzAgguluXdxPusezvxS3tUOf6U9uZR9MVWPCk89FJubezgBy76Lk4iIyBrUc3eyqlNifNydXvo6kSy2UJp7V+Wz7uHML0XsnnGfp+HfJ+jn9h5OwHLv4iQiIrIGJRzVqOpmr/gppQSgmps9Sjha9ukwFlsozb2LU4n3cAKWexcnERGRtfD1UP6UUgbg6+EsOsZLWWyhNPcuzmfdw5lf0p8xjXR9xtQyt/dwApZ7FycREZG1qFHUAcUdVIqdUkp4eMNOdTM3/opksbXG3Lsqn3UPZ365nmFAVbcnz5is6maPa0/t0s7tPZyA5d7FSUREZC1UkoTOVdwUO6WUAXSp4gaVAjqDxRZKc+/ifNY9nMD/7sx0tZdg99h9mrm5A1NzOwvVitqjQWlnlHRUo2lZF5RzsYP2qfOqcnMPJ2DZd3ESERFZk0pF7OHnobwd3xIAfw8nVHzB9Y6WxGILpbl3cT7rHk4A6FTZDYNql0A9d2eUcrL75z7Nx0/Cn17PHZ4ln3/cz7UMA77/Kw3epRwxqHZxvF7cAd9eTMWdbOM/r8ntPZyAZd/FSUREZG2al3eFWp8Fk1EZN9VJeLjpuFl5V9FRzGa5R67D/Ls4n3UP56b/przwZ4o5qGCUZVx9ySHjvz/Iwe8Pnj99zM09nIDl38VJRERkTYxGI96fNQubDxzB8DV7RMcxy6OlbnsFLWda7IQSMP8uzle7h9MB8XeycT8PB58DubuHE7D8uziJiIisxd27d9GxY0d89tlnGN0nBG0rKmPi16aiKyopZKn7EYtuNrm5szK393DG3cnd658nt/dwApZ9FycREZE1OHfuHIKDg5GWloaffvoJrVu3BgDoTMDxG/lzF3dBCCznAj8FHBP0NIueUPIuTiIiIsqtyMhING7cGCVLloRWq/2nTAJA4zLOCCznIjDd8zUr54LGZZRXJgELL5S8i5OIiIjMpdfrMW7cOISHh6Nnz544ceIEqlSp8sRrJElCk7IuaPP38rfofyI/+vw2FV3RuKyLYjuCxa+91nN3eqVlZUukhLs4iYiIlCg5ORk9evTA6dOnsWLFCowcOfKF5czPwxllnO2w91IaUnNMQs6qfLSbu0sVN8U9M/k0iy+Uj+7ivJSmV+zBpMDD/9FUVcBdnEREREpz+vRphIaGwmQyITo6Gk2aNDHr5yoVsceQN0rg6PUMaG5nQwIKpWs8+hw/Dyc0K++qqN3cz2PRS96P8C5OIiIieposy1i9ejWaN2+OqlWrIi4uzuwy+Yi9SkKbikXQt1YxFHN4WIsKqt49et9iDir0rVUMrSsWsYoyCQCSLMsW39VMsoyvfruPFEEj6byS8PB/PMPqlFDE9UlERESWLjs7G6NHj8batWsxevRoLFq0CA4ODi//wRcwyTIupOqhvZ2Fi2n6fJtYPnqfam728PVwRvWi9lbXBxRRKAHgSroeUX+++LByS9avVjHFXJ9ERERkyS5fvoyQkBAkJSVh9erVGDBgQL5/xn2dEfF3shF/Nxs648OqpJIenif9Mo+/zlEtwaeUE3zcnaz6sTfFFEoAOHQ1Hdrb2YqaUsomE2o7GxBUp7zoKERERIp35MgR9OjRAy4uLti5cyd8fX0L9PNkWcZ9nQnJmQYkZxlwPUOP5CwDDM+4F8VO9fDykvKu9ijrbIeyLnYo4ahS7M7t3LD4TTmPa17eFX+m5AjbjZVrsoy0WzcwZEA7ZC1ZjD59+ohOREREpEiyLGPx4sWYOnUqWrRogS1btsDd3b3AP1eSJJR0UqOkkxp14PhPFpMMGGQZRhOgVgF2kgSVBJsoj8+iiE05j9irJHSp4qaMMgkAkoT+9SujY7u26Nu3L/r164eUFOUu2xMREYmQkZGBPn36YNKkSZg0aRIOHDhQKGXyeSRJglolwVGtgou9Co5qFdQqyWbLJKCwJe9HNLezcOiq+fdni9Kmous/1ydFRUVh1KhRKFGiBCIjI9G0aVPB6YiIiCzf+fPnERQUhAsXLmDdunUICwsTHYmeQVETykf8PCz32qRHnr6Ls2/fvkhISEClSpXQvHlzvP/++9Dr9QITEhERWbYffvgBfn5+yMrKwpkzZ1gmLZgiCyWgzLs4q1atiujoaHz00UeYO3cuAgMD8d///ldAQiIiIstlMpkwZ84cdOnSBU2bNkVsbCzq1q0rOha9gGILpVLv4lSr1Zg5cyZOnjyJO3fuwMfHB+vWrYMCnzwgIiLKdykpKQgKCsL777+PDz74AN999x2KFy8uOha9hCKfoXzalXS9Iu/iTEtLw4QJE7B27VqEhYVh1apVKFmyZMEFJSIismC//fYbgoKCcPPmTURGRqJLly6iI5GZrKJQAoDeJAu7i9M/j3dx7tixA8OGDYOrqys2btyIli1b5mtOIiIiS7djxw4MHDgQVatWxa5du1CrVi3RkSgXFLvk/TQl38UZGhqKxMRE1KpVC61bt8b06dORk5OTP2GJiIgsmNFoxPTp0xEWFobOnTvjzJkzLJMKZDUTyscp9S5Ok8mEhQsXYubMmfD09ERUVBRq166db+9PRERkSe7cuYPevXvj559/xvz58zFp0iSbPstRyayyUD5OiXdxxsXFoU+fPrh8+TIWL16MYcOG8W8wIiKyKnFxcQgODkZGRga2bt2KVq1aiY5EeWD1hfIRpd3FmZmZiUmTJmHVqlXo1q0bvvnmG3h4eBTa5xMRERWUjRs3Yvjw4XjzzTexc+dOVK5cWXQkyiObKZTPooS7OL///nsMHjwYdnZ22LBhA9q1ayc6EhER0SvJycnBpEmTsHz5crz99ttYuXIlnJycRMeifGA1m3JehRLu4uzWrRsSExPh7e2N9u3b45133kF2drboWERERLmSnJyM1q1bY/Xq1Vi5ciXWrFnDMmlFbHpCqSQmkwnLly/H1KlT8dprr2HTpk28NYCIiBTh9OnTCAkJAfDweKDGjRsLTkT5zaYnlEqiUqkwbtw4xMbGQpZl+Pn5YdmyZbxhh4iILJYsy/jyyy/RvHlzVK9eHVqtlmXSSrFQKoynpydiYmIwfPhwjBs3Dp06dUJycrLoWERERE/Izs7G4MGDMWrUKAwfPhw///wzypUrJzoWFRAueSvY/v378fbbb8NkMmHt2rW8ooqIiCzC5cuXERwcjF9//RWrVq3CgAEDREeiAsYJpYJ17NgRiYmJCAgIQNeuXTF69GhkZmaKjkVERDbs559/hq+vL+7cuYOTJ0+yTNoIFkqFK126NL777jt8+eWXWLduHfz8/BAfHy86FhER2RhZlrFgwQK0bdsWPj4+0Gg0qF+/vuhYVEhYKK2AJEkYMWIEtFotHB0d0aBBAyxYsAAm0zNObSciIspnGRkZ6N27N6ZMmYIpU6bgwIEDcHd3Fx2LChGfobQyOp0O7733Hj7//HO0bt0aGzZsQIUKFUTHIiIiK/Xf//4XQUFBuHjxItavX4/Q0FDRkUgATiitjKOjIz777DMcOnQI//d//wcvLy/s3LlTdCwiIrJC+/btg5+fH3Q6HWJiYlgmbRgLpZVq3bo1EhMT0bJlS4SEhGDIkCFIT08XHYuIiKyAyWTCRx99hK5du6J58+aIjY1FnTp1RMcigbjkbeVkWca6deswbtw4lCtXDps2bYK/v7/oWEREpFApKSkIDw/H3r178eGHH2LmzJlQqTifsnX8X4CVkyQJgwYNwrlz51CiRAk0btwYc+fOhdFoFB2NiIgU5tdff4W/vz+OHTuGvXv34r333mOZJAAslDajVq1aOHnyJKZNm4ZZs2ahZcuWuHTpkuhYRESkENu3b0fDhg3h6OgIjUaDTp06iY5EFoSF0obY29vj448/RnR0NC5dugRvb29s2bJFdCwiIrJgBoMB06ZNQ48ePdClSxecOXMGNWvWFB2LLAwLpQ1q1qwZEhIS0KlTJ/Tu3Rv9+/dHamqq6FhERGRh7ty5gw4dOmDhwoVYuHAhNm/eDFdXV9GxyAJxU46Ni4qKwsiRI+Hu7o7IyEg0btxYdCQiIrIAcXFxCA4ORkZGBrZt24aWLVuKjkQWjBNKG9e3b18kJCSgXLlyCAwMxAcffACDwSA6FhERCbRhwwY0adIEHh4e0Gq1LJP0UiyUhGrVquHo0aOYPXs2PvnkEwQGBuLChQuiYxERUSHLycnBmDFjMHDgQPTp0wfHjx9H5cqVRcciBeCSNz3hzJkz6Nu3L27duoUVK1YgPDwckiSJjkVERAXsxo0bCAsLQ0xMDJYtW4Zhw4bx+5/MxgklPSEgIADx8fEICQnBgAED0Lt3b9y/f190LCIiKkCnTp2Cr68vLl68iKNHj2L48OEsk5QrLJT0L25ubli/fj22bt2KH3/8Ed7e3oiOjhYdi4iI8pksy1i5ciVatGiBmjVrQqvVolGjRqJjkQKxUNJz9ejRA4mJiahevTpatWqFGTNmICcnR3QsIiLKB1lZWRg0aBBGjx6NESNG4PDhwyhbtqzoWKRQfIaSXspoNGLBggWYNWsWvL29ERUVhddff110LCIiekWXLl1CSEgIfv31V3z11VcIDw8XHYkUjhNKeim1Wo1p06bhzJkzSEtLQ/369fH111+DfxYhIlKew4cPw9fXF3fv3sWpU6dYJilfsFCS2Xx9fREXF4d+/fph2LBhCA4Oxp07d0THIiIiM8iyjM8//xzt2rVD/fr1odFoUK9ePdGxyEpwyZteye7duzFkyBA4ODhgw4YNaNu2rehIRET0HOnp6Rg0aBC2b9+O6dOn4+OPP4ZarRYdi6wIJ5T0Srp3747ExETUrVsX7dq1w6RJk6DT6UTHIiKip/z5558ICAjA/v37sWPHDnz66acsk5TvWCjplZUvXx4HDhzAokWLsHz5cjRo0AC//vqr6FhERPS3vXv3wt/fH3q9HmfPnkVISIjoSGSlWCgpT1QqFd555x3ExMTAYDDAz88PK1as4IYdIiKBTCYTZs+eja5du6J58+aIiYlBnTp1RMciK8ZCSfnC29sbGo0GQ4YMwZgxY9ClSxfcvHlTdCwiIpvz4MEDvPXWW/joo48wZ84c7Nq1C8WKFRMdi6wcN+VQvvvhhx/w9ttvQ5ZlrFu3Dp07dxYdiYjIJvzyyy8ICgrCnTt3sGnTJnTs2FF0JLIRnFBSvuvUqROSkpLQoEEDdOnSBWPGjEFWVpboWEREVm3btm0ICAiAs7MzNBoNyyQVKhZKKhClS5fGnj17sGLFCqxZswZ+fn5ISEgQHYuIyOoYDAZMmTIFPXv2RLdu3XD69GnUqFFDdCyyMSyUVGAkScKoUaOg1Wphb2+PBg0aYNGiRTCZTKKjERFZhdu3b6N9+/ZYvHgxFi1ahKioKLi6uoqORTaIz1BSodDpdJg5cyYWLlyINm3aYMOGDShfvrzoWEREiqXVahEcHIysrCxs3boVLVu2FB2JbBgnlFQoHB0dsWDBAvz000/49ddf4enpiV27domORUSkSOvXr0eTJk1QpkwZaLValkkSjoWSClXbtm2RlJSE5s2bIzg4GMOGDUNGRoboWEREipCTk4PRo0fj7bffRr9+/XDs2DFUqlRJdCwiLnmTGLIsY82aNRg/fjwqVqyIqKgo+Pn5iY5FRGSxrl+/jrCwMMTGxmL58uUYNmyY6EhE/+CEkoSQJAlDhgzBuXPn4ObmhkaNGmHevHkwGo2ioxERWZwTJ07A19cXf/31F44dO8YySRaHhZKEeu2113Dq1ClMmTIF7777Llq3bo3Lly+LjkVEZBFkWcaKFSvQsmVL1KpVC3FxcQgICBAdi+hfWChJOAcHB8ydOxdHjhzBhQsX4OXlha1bt4qORUQkVFZWFt5++22MGTMGo0ePxuHDh1GmTBnRsYieiYWSLEbz5s2RkJCADh06oFevXhgwYABSU1NFxyIiKnSXLl1C06ZNsW3bNkRERGDJkiWwt7cXHYvoubgphyyOLMuIjIzE6NGj4eHhgcjISDRq1Eh0LCKiQnHo0CH06tULbm5u2LVrF3x8fERHInopTijJ4kiShPDwcMTHx6NMmTIIDAzERx99BIPBIDoaEVGBkWUZn332Gdq3bw9fX19oNBqWSVIMFkqyWNWrV8exY8cwa9YsfPjhh2jevDkuXLggOhYRUb5LT09Hz549MW3aNEybNg0//PADSpUqJToWkdm45E2KcOrUKfTr1w937tzBihUr0K9fP0iSJDoWEVGe/fHHHwgKCsLly5exYcMGBAcHi45ElGucUJIiNG7cGPHx8QgKCkL//v3Rp08fPHjwQHQsIqI82bNnD/z9/WE0GhETE8MySYrFQkmKUbRoUWzYsAGbN2/G/v374e3tjWPHjomORUSUayaTCR988AG6deuGli1bIiYmBm+88YboWESvjIWSFKdXr15ITExE1apV0aJFC8ycORN6vV50LCIiszx48ABdu3bFnDlz8PHHH2Pnzp0oWrSo6FhEecJnKEmxjEYjPvvsM7z//vuoV68eoqKiUKtWLdGxiIieKykpCUFBQbh37x42bdqEDh06iI5ElC84oSTFUqvVmDFjBk6dOoUHDx7Ax8cHa9asAf+MRESWaOvWrQgICICrqys0Gg3LJFkVFkpSPH9/f8TFxaFPnz4YMmQIQkNDcffuXdGxiIgAAAaDAZMnT0avXr3QvXt3nDp1CtWrVxcdiyhfccmbrMrOnTsxdOhQODk5YePGjWjdurXoSERkw27fvo2ePXvi2LFjWLBgAcaPH88jz8gqcUJJViU4OBiJiYl444030KZNG0yZMgU6nU50LCKyQRqNBr6+vvjll19w6NAhTJgwgWWSrBYLJVmdChUq4KeffsKCBQvwxRdfICAgAP/3f/8nOhYR2ZC1a9eiadOmKFeuHOLi4tCiRQvRkYgKFAslWSWVSoVJkyYhJiYGOp0O9evXx8qVK7lhh4gKVE5ODkaOHInBgwcjPDwcx44dQ8WKFUXHIipwfIaSrF5mZiamTp2KFStWoHPnzli7di1Kly4tOhYRWZnr168jNDQUWq0Wy5cvx9ChQ0VHIio0LJRkM/bu3YtBgwZBkiSsX78eHTt2FB2JiKzEiRMnEBoaCjs7O3z77bdo2LCh6EhEhYpL3mQzunTpgqSkJPj6+qJTp04YN24csrKyRMciIgWTZRnLly9Hy5Yt8frrr0Or1bJMkk1ioSSbUqZMGezbtw/Lli3DV199BX9/fyQmJoqORUQKlJWVhQEDBmDs2LEYM2YMDh06hDJlyoiORSQECyXZHEmSMGbMGGg0GqjVavj7+2PJkiUwmUyioxGRQvz1119o0qQJduzYgcjISCxevBj29vaiYxEJw0JJNqtu3bo4e/YsRo8ejXfeeQcdO3bEjRs3RMciIgt38OBB+Pr64sGDBzh9+jT69u0rOhKRcCyUZNOcnJywaNEi/Pjjj0hMTISnpye+++470bGIyALJsoz58+ejQ4cO8Pf3h0ajgbe3t+hYRBaBhZIIQLt27ZCUlISmTZuie/fuGDFiBDIyMkTHIiILkZaWhrCwMEyfPh0zZszAvn37ULJkSdGxiCwGjw0ieowsy/j6668xYcIEVK5cGVFRUfD19RUdi4gE+uOPPxAUFIQrV65gw4YNCAoKEh2JyOJwQkn0GEmSMGzYMMTFxcHV1RUBAQGYP38+jEaj6GhEJMD3338Pf39/mEwmxMTEsEwSPQcLJdEz1K5dG6dPn8akSZMwY8YMtGnTBleuXBEdi4gKiclkwvvvv4+33noLrVu3xtmzZ1G7dm3RsYgsFpe8iV4iOjoa4eHhyMjIwOrVqxEWFiY6EhEVoPv376Nfv37Yv38/PvnkE0ybNg0qFecvRC/Cv0OIXqJFixZITExEmzZt0KNHDwwaNAhpaWmiYxFRAUhKSoK/vz9Onz6N/fv3Y8aMGSyTRGbg3yVEZihRogS2bt2KdevWYfv27ahXrx7OnDkjOhYR5aMtW7YgICAARYoUgUajQfv27UVHIlIMFkoiM0mShIEDB+LcuXNwd3dH06ZNMWfOHBgMBtHRiCgPDAYDJk2ahN69eyMoKAinTp1C9erVRcciUhQ+Q0n0CvR6PebMmYNPPvkEjRo1QmRkJKpWrSo6FhHl0q1bt9CzZ08cP34cixYtwtixYyFJkuhYRIrDQkmUBydPnkS/fv1w7949rFy5klewESlIbGwsgoODkZOTg+3bt6NZs2aiIxEpFpe8ifKgSZMmiI+PR7du3dCvXz/07dsXKSkpomMR0UusXbsWgYGBqFChArRaLcskUR6xUBLlUbFixRAREYGoqCjs3bsX3t7eOH78uOhYRPQMOp0OI0aMwODBgzFgwAAcPXoUFStWFB2LSPFYKInySZ8+fZCQkIBKlSqhRYsWeO+996DX60XHIqK/Xbt2DS1atMC6devw9ddfY/Xq1XB0dBQdi8gq8BlKonxmNBoxb948fPDBB/D19UVUVBRq1qwpOhaRTTt+/DjCwsJgb2+Pb7/9Fg0aNBAdiciqcEJJlM/UajVmzpyJU6dO4e7du/Dx8cG6devAP7sRFT5ZlrF06VK0atUKtWvXhlarZZkkKgAslEQFpEGDBoiPj0fPnj0xaNAg9OjRA/fu3RMdi8hmZGZmYsCAARg/fjzGjh2LgwcPonTp0qJjEVklLnkTFYIdO3Zg2LBhcHFxwcaNG9GqVSvRkYis2sWLFxEcHIzff/8d33zzDfr06SM6EpFV44SSqBCEhoYiMTERr732Gtq0aYOpU6ciJydHdCwiq/TTTz/Bz88PqampOHPmDMskUSFgoSQqJBUrVsShQ4cwf/58LFmyBAEBAfjPf/4jOhaR1ZBlGZ9++ik6dOiABg0aIDY2Fl5eXqJjEdkEFkqiQqRSqTBlyhScPXsWWVlZqF+/PlatWsUNO0R5lJaWhtDQULz77ruYOXMm9u7di5IlS4qORWQz+AwlkSCZmZmYPHkyvvzyS3Tt2hVr1qyBh4eH6FhEivP777+je/fuuHbtGjZu3Iju3buLjkRkczihJBLExcUFK1euxPfff4/Tp0/Dy8sLBw4cEB2LSFG+++47+Pv7Q5IkxMbGskwSCcJCSSRY165dkZSUBG9vb3Ts2BETJkxAdna26FhEFs1oNOK9995D9+7d0bZtW5w9exavv/666FhENotL3kQWwmQyYfny5Zg6dSpq1aqFTZs2wdPTU3QsIotz//599OnTBz/++CPmzp2LadOmQZIk0bGIbBonlEQWQqVSYdy4cYiNjQUA+Pv7Y+nSpdywQ/SYxMRE+Pn5ISYmBgcOHMD06dNZJoksAAslkYXx9PREbGwsRowYgfHjx6NTp05ITk4WHYtIuM2bNyMgIABFixaFRqNBu3btREcior+xUBJZICcnJyxZsgT79+/HuXPn4OnpiT179oiORSSEXq/HxIkT0adPH4SEhODkyZOoVq2a6FhE9BgWSiIL1qFDByQlJaFRo0bo1q0bRo4ciczMTNGxiArNrVu30LZtWyxbtgxLly7Fxo0b4eLiIjoWET2Fm3KIFECWZaxevRoTJ05ElSpVsGnTJtSrV090LKICFRMTg5CQEOj1emzbtg3NmjUTHYmInoMTSiIFkCQJI0aMQFxcHJydndGwYUMsWLAAJpNJdDSiAvHNN98gMDAQFStWhFarZZkksnAslEQKUrt2bZw5cwbvvPMOpk6dirZt2+Lq1auiYxHlG51Oh+HDh2Po0KEYNGgQoqOjUaFCBdGxiOgluORNpFA///wz+vfvj8zMTHz99dcICQkRHYkoT65evYrQ0FCcO3cOX375JQYNGiQ6EhGZiRNKIoVq1aoVEhIS0KpVK4SGhmLw4MFIT08XHYvolRw7dgy+vr64du0aTpw4wTJJpDAslEQKVqpUKWzfvh1r1qzB1q1bUa9ePcTExIiORWQ2WZaxdOlStG7dGnXq1IFWq4W/v7/oWESUSyyURAonSRIGDRqE+Ph4lCxZEo0bN8Ynn3wCo9EoOhrRC2VmZiI8PBzjx4/HuHHjcPDgQZQuXVp0LCJ6BXyGksiK6PV6fPTRR5g7dy6aNGmCiIgIVKlSRXQson+5cOECgoOD8eeff2LNmjXo1auX6EhElAecUBJZEXt7e8yZMwfR0dG4dOkSvLy8sHnzZtGxiJ7w448/ws/PD2lpaTh9+jTLJJEVYKEkskKBgYFISEhA586d0adPH4SHhyMlJUV0LLJxsixj7ty56NixIwICAqDRaODl5SU6FhHlAy55E1m5qKgojBo1CiVLlkRkZCSaNGkiOhLZoNTUVAwcOBC7du3Ce++9h9mzZ0Ol4kyDyFrw72YiK9e3b1/Ex8ejQoUKaNasGT744AMYDAbRsciG/Oc//0HDhg1x+PBhfPfdd/joo49YJomsDP+OJrIB1apVQ3R0NGbPno1PPvkETZs2xfnz50XHIhuwe/duNGjQAJIkISYmBt26dRMdiYgKAAslkY2ws7PDe++9hxMnTuD27dvw8fHB+vXrwadeqCAYjUbMnDkTQUFBaNeuHc6ePYvXX39ddCwiKiAslEQ2JiAgAPHx8QgNDcXbb7+Nnj174v79+6JjkRW5d+8eunTpgnnz5mHevHnYvn073NzcRMciogLETTlENmz79u0YNmwYihQpgoiICLRo0UJ0JFK4hIQEBAUFISUlBVu2bEHbtm1FRyKiQsAJJZENCwsLQ2JiImrWrIlWrVph+vTpyMnJER2LFGrTpk1o1KgRihcvDq1WyzJJZENYKIlsXKVKlXDo0CHMmzcPCxcuRKNGjfD777+LjkUKotfrMWHCBPTt2xehoaE4efIkqlatKjoWERUiFkoiglqtxtSpU3HmzBmkp6ejXr16+Oqrr7hhh17q5s2baNu2LVasWIFly5Zhw4YNcHZ2Fh2LiAoZn6EkoidkZGRg0qRJWL16Nd566y188803cHd3Fx2LLNDZs2cREhICg8GA7du3IzAwUHQkIhKEE0oieoKrqytWrVqF3bt348SJE/D09MRPP/0kOhZZmK+//hrNmjVD5cqVERcXxzJJZONYKInomd566y0kJibCy8sL7du3x8SJE5GdnS06Fgmm0+kwdOhQDBs2DIMGDUJ0dDTKly8vOhYRCcYlbyJ6IZPJhKVLl2LatGmoXbs2Nm3ahDfffFN0LBLg6tWrCAkJQUJCAlauXIlBgwaJjkREFoITSiJ6IZVKhQkTJiA2NhZGoxG+vr5YtmwZN+zYmKNHj8LX1xc3btzAiRMnWCaJ6AkslERkFi8vL8TGxmLYsGEYN24cOnfujJs3b4qORQVMlmUsWbIErVu3Rt26daHVauHn5yc6FhFZGBZKIjKbs7Mzli5din379kGr1cLT0xP79u0THYsKSGZmJvr164d33nkH77zzDn788Ud4eHiIjkVEFoiFkohyrVOnTkhKSkKDBg3QpUsXjBkzBllZWaJjUT66cOECGjVqhN27d2PLli34/PPPYWdnJzoWEVkoFkoieiWlS5fGnj17sHLlSqxZswa+vr6Ij48XHYvywYEDB+Dn54eMjAycOXMGPXv2FB2JiCwcCyURvTJJkjBy5EhotVo4ODigQYMGWLhwIUwmk+ho9ApMJhM++eQTdOrUCY0aNYJGo4Gnp6foWESkACyURJRnderUwdmzZzFu3DhMnjwZ7dq1w7Vr10THolxITU1FSEgIZs2ahffffx979uxB8eLFRcciIoXgOZRElK8OHTqE/v37Q6fT4ZtvvkFQUJDoSPQS//d//4egoCDcuHEDkZGR6Nq1q+hIRKQwnFASUb5q06YNkpKS0Lx5cwQHB2Po0KFIT08XHYueY9euXWjQoAHUajViY2NZJonolbBQElG+K1WqFL799lt888032LRpE+rXr4/Y2FjRsegxRqMRM2fORHBwMDp06ICzZ8/itddeEx2LiBSKhZKICoQkSRg8eDDOnTuHYsWKoXHjxvj0009hNBpFR7N59+7dQ+fOnTFv3jx89tln2LZtG4oUKSI6FhEpGJ+hJKICp9frMXv2bHz66acIDAxEREQEKleuLDqWTYqPj0dwcDBSU1OxZcsWtGnTRnQkIrICnFASUYGzt7fHJ598giNHjuDixYvw8vLC1q1bRceyOVFRUWjcuDFKlCgBjUbDMklE+YaFkogKTfPmzZGQkIAOHTqgV69eGDBgAFJTU0XHsnp6vR4TJkxAv3790KNHD5w4cQJVq1YVHYuIrAiXvImo0MmyjMjISIwePRru7u6IjIxE48aNRceySjdv3kSPHj1w6tQpLFmyBKNGjYIkSaJjEZGV4YSSiAqdJEkIDw9HfHw8ypYti8DAQMyePRsGg0F0NKty5swZ1K9fH3/88Qeio6MxevRolkkiKhAslEQkTPXq1XHs2DG8//77mDNnDpo1a4YLFy6IjmUVvvrqKzRr1gxVq1aFVqtFkyZNREciIivGQklEQtnZ2eGDDz7A8ePHkZycDB8fH2zcuBF8GufVZGdnY+jQoRg+fDiGDh2KI0eOoHz58qJjEZGVY6EkIovQuHFjxMfHIygoCAMGDEDv3r1x//590bEU5cqVK2jevDkiIiKwbt06rFixAg4ODqJjEZEN4KYcIrI4W7duxfDhw1G0aFFERESgefPmoiNZvOjoaPTo0QPOzs7YuXMnfH19RUciIhvCCSURWZyePXsiMTER1apVQ8uWLfHuu+8iJydHdKx/yLIMg0lGttGETL0J2UYTDCZZyDK9LMtYvHgx2rRpA09PT2g0GpZJIip0nFASkcUyGo34/PPP8d5778HHxwdRUVGFft+0LMu4pzMiOdOA5EwDbmQakJxlgMH079faqYCyznYo52KHsn//q6SjusB2VmdkZGDo0KHYvHkzpkyZgrlz58LOzq5APouI6EVYKInI4mk0GvTp0wfXrl3DF198gcGDBxf48Tf3dUacu5ONhLvZ0Bkffk2qADyjR/7L469zVEvwLuWEeu5OKOGozrd858+fR3BwMM6fP4+1a9eiR48e+fbeRES5xUJJRIqQnp6OiRMn4uuvv0ZQUBC+/vprlCpVKl8/wyTLOJ+aA+3tbPyVpocEID++IB+9T1U3e/h6OKFGUQeo8lCI9+/fjz59+sDd3R27du1C3bp18yElEdGrY6EkIkXZtWsXhgwZAicnJ2zYsCHf7qO+kq7HvktpeJBjyrci+bRH71vcQYXOVdxQqYh9rn7eZDJh7ty5eP/999G5c2dERESgePHiBZCUiCh3uCmHiBQlKCgISUlJqFOnDtq2bYtJkyZBp9O98vvpTTIOXU1H1J8pSMl5uFBdUH/KfvS+KTkmRP2ZgkNX06E3mfdpKSkpCA4OxnvvvYf3338f3333HcskEVkMTiiJSJFMJhOWLFmCGTNm4I033sCmTZtQp06dXL3HlXQ99l5KQ2qOqcBK5ItIAIo6qNDlJdPK3377DUFBQbh58yYiIyPRpUuXwgtJRGQGTiiJSJFUKhUmTpyIs2fPIicnB76+vli5cqXZR/dobmch6s8UYWUSeDixTP17Wqm5nfXM13z77bdo2LAh7O3tERsbyzJJRBaJhZKIFM3HxwcajQaDBw/G6NGj0bVrV9y6deu5r5dlGSeTM3HoasbDvy6soM/L8/e/H7qagZPJmf8UYqPRiBkzZiA0NBSdOnXCmTNnUKtWLXFBiYhegEveRGQ19u3bh0GDBgEA1q1bh06dOv3rNSeTM3H8RmZhRzNbYDkX1LbPQu/evXH48GHMnz8fkyZNKvBjkoiI8oITSiKyGp07d0ZiYiJ8fX3RuXNnjB07FllZ/1tK1tzKsugyCQDHb2RiwPufIS4uDj/99BMmT57MMklEFo8TSiKyOrIsY8WKFZg8eTJq1KiBTZs2oWSNOoj6M0V0NLPIsoy2RbPhV7OS6ChERGbhhJKIrI4kSRgzZgy0Wi3s7OzQJLAZohKvQSlzPpUkIVbnavaRQkREonFCSURWLTs7G3N3/gyn13yhUuff1YcFTQLg5+GE1hWLiI5CRPRSnFASkVW7bVDD5Y0GiiqTwMPd37G3s3ElXS86ChHRS7FQEpHVMsky9l1KU8xS99MkAPsupcHEhSQisnAslERktc6n5uCBwIPL80oG8CDHhAupnFISkWVjoSQiq6W9na3Y6eQjEgDtc27RISKyFCyURGSV7uuM+CtNr9jp5CMygItpetzXGUVHISJ6LhZKIrJK5+4ofzr5iAQg/k626BhERM/FQklEVkeWZSTczVb8dPIRGUD83WzwlDcislQslERkde7pjNAZrat86Ywy7utMomMQET0TCyURWZ3kTINZr3NSSxhbtySKORTuV6FKAkbWKYGyzna5+jlzfy8iosKWu28zIiIFSM40QAXgZfO8xmVd8GdKDlJy/vfKovYqtKtUBFXc7JFjlPHLvWxEX8/M9fJ5fXcnNCztDFd7FW5lGXDwagZu/F0ITTJw9lYWWlRwwZb/ppr1fioJSM4yoA4cc5mEiKjgcUJJRFbnRqbhpWXSTgK8Sjki8e7/NrtIAEJrFIVaAiL+eIB9l9PgWdIJgeVccvX5tYs7oFUFV5xIzsS63x/gVpYRPWsUhYvd/7YJ/Xpfh4qu9nB3Mu8GH5MMXM/geZREZJlYKInIqsiyjOSsly8N1yjmAKMJuP7YMnK1og8L3p5LabiVZcSFVD2O3chEfQ8nqHKxZbxBaWck3M1G0j0d7mYbceBKOvQmGV6lnP55jc4o41qGHm+UMH/imJxl4MYcIrJILJREZFWMMmAwY+9KJVf7fxXPCi72uJ1lRKbhf6XtYloOnNQqeJg5SVRJQFkXO/yV9uQ08a80PSq4PPmU0fVMAyq52pv1vsDD38vEPklEFoiFkoisisHMCV5RBxXS9U82T1d7FTKeaqMZf7/G1d68r0sXtQoqSfrn5/55H4PpX++RrjehaC43BJn7+xERFSYWSiKyKiYzT9axU0kwCB73GUwy7HOzlg7AyJODiMgCsVASkVVRmfmtlmUwwUn9ZJnL0JvgavfkGzyaKj49cXyeTKMJJln+1zTS1U71r/dwUquQac76/GPU/NYmIgvEryYisip2knkTv5tZRrg7PflM47VMPTyc1U/sxq7qZo9sowl3ss27S9skPzy2qKrbk89GVnGzx7WnzpH0cFbjphkbiB5n7u9HRFSYWCiJyKqoJcDOjG+2i6k5cHdWw/GxKeXFVD3uZBvRpYobSjurUc3NHs3KuSLudjZyc/FOzK0seJdyQt2SjijlqEb7Sq5wUElPHFEEPNwYdDHV/KOA7FTI1W5zIqLCwkJJRFZFkiSzbqC5nW3EzUwD3ij+v2N7ZAA7zqdCloHw14qjaxU3/HIvG8dvZP7zmmIOKkyv547KRZ6/O/s/D3Lw87UMBJZzwdu1i6OMsx22nk99Yvd4eRc7OKol/P5AZ/bvVtbZDhInlERkgXhTDhFZnXIudrie8fLDzU8mZ6JleVfEPzY5TNWbsP3C82+vKeagRrbB9NKl6rg72Yi7k/3c/9y/tDPO3sqCwczJp0oCyufiiCEiosLEQklEVqesi91LyyQAnE/Vo4RjNtzsVUgzc9NNjaL2OHUzC7rcrIE/RSUBt7MMiL2VZfbPmGTk+u5vIqLCwm8nIrI6ZV3M/2rT3H7+FPFZjlzPfPmLXsIkA6duml8mH8nN70VEVJj4DCURWZ2Sjk9utrEGjmoJJRz5lU1ElonfTkRkdSRJgncpJ1hLpZQA+JRy4oYcIrJYLJREZJXquTvBWi4plAH4uDuJjkFE9FwslERklUo4qlHVzV7xU0oJQDU3e5RwVIuOQkT0XCyURGS1fD2UP6WUAfh6OIuOQUT0QiyURGS1ahR1QHEHlWKnlBKA4g4qVC/K8yeJyLKxUBKR1VJJEjpXcVPslFIG0KWKG1TcjENEFo6FkoisWqUi9vDzUN6ObwmAv4cTKr7gikciIkvBQklEVq95eVcUVdDStwSgqIMKzcq7io5CRGQWFkoisnr2KgldFLT0/Wip216llApMRLaOhZKIbEKlIvZoU1EZE782FV1RiUvdRKQgLJREZDP8PJwRWM5FdIwXCiznAj8eE0RECmMnOgARUWFqXOZhWTt+I1Nwkn9rVs4FjcqwTBKR8kiyLCvlsSIionyjuZ2FQ1czIAFCn6189PltKrpyMklEisVCSUQ260q6HnsvpSE1xySkVD7azd2lihufmSQiRWOhJCKbpjfJOHo9A5rb2YU2rXz0Of4eTmhW3pW7uYlI8VgoiYjwcFq571IaHuSYCqxYPnrf4g4qdOZUkoisCAslEdHfTLKMC6l6aG9n4WKaPt+K5aP3qeZmD18PZ1Qvas/rFInIqrBQEhE9w32dEfF3shF/Nxs648OvSZUEmMz4xnz8dY5qCT6lnODj7oQSjuoCTExEJA4LJRHRC8iyjPs6E5IzDUjOMuB6hh7JWQYYTP9+rZ0KKOtsh/Ku9ijrbIeyLnYo4aiCxGkkEVk5FkoiolySZRkmGTDIMowmQK0C7CQJKgksj0Rkk1goiYiIiChPePUiEREREeUJCyURERER5QkLJRERERHlCQslEREREeUJCyURERER5QkLJRERERHlCQslEREREeUJCyURERER5QkLJRERERHlCQslEREREeUJCyURERER5QkLJRERERHlCQslEREREeUJCyURERER5QkLJRERERHlCQslEREREeUJCyURERER5QkLJRERERHlCQslEREREeUJCyURERER5QkLJRERERHlCQslEREREeXJ/wP3Nj1YQ+GDuAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G_vis = nx.grid_graph(dim=lattice_size)\n",
    "G= nx.grid_graph(dim=lattice_size, periodic=True)\n",
    "\n",
    "# Draw the graph\n",
    "pos = nx.spring_layout(G_vis, seed=42)  # positions for all nodes - seed for reproducibility\n",
    "nx.draw(G_vis, pos, with_labels=True, node_color=\"skyblue\", node_size=1500, font_size=10, font_color=\"white\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "nx.draw(G, with_labels=True, node_color=\"skyblue\", node_size=1500, font_size=10, font_color=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b629387",
   "metadata": {},
   "source": [
    "## Hamiltonian creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80b0f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a graph representing the lattice\n",
    "G = nx.grid_graph(dim=lattice_size, periodic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d16e91",
   "metadata": {},
   "source": [
    "## In the following we want to compute the Hamiltonian and find the GS if it's a small one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3908f16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_time 0.6212878227233887\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sonnet as snt\n",
    "from graph_nets import modules\n",
    "from graph_nets import blocks\n",
    "from compgraph.gnn_src_code import GNN_double_output\n",
    "gnn=GNN_double_output()\n",
    "start_time=time.time()\n",
    "for i in range(35):\n",
    "    a=gnn(graph_tuples[i])[0]\n",
    "    #print(a)\n",
    "print(\"final_time\", time.time()-start_time)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0542d0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn_double_output: GNN_double_output\n",
      "  graph_network: Encoder\n",
      "    edge_block: EdgeBlock\n",
      "      mlp_model_enc: MLPModel_enc\n",
      "        layer1: Linear\n",
      "        layer2: Linear\n",
      "        layer3: Linear\n",
      "        layer4: Linear\n",
      "    node_block: NodeBlock\n",
      "      mlp_model_enc: MLPModel_enc\n",
      "        layer1: Linear\n",
      "        layer2: Linear\n",
      "        layer3: Linear\n",
      "        layer4: Linear\n",
      "      received_edges_to_nodes_aggregator: ReceivedEdgesToNodesAggregator\n",
      "    global_block: GlobalBlock\n",
      "      mlp_model_glob: MLPModel_glob\n",
      "        layer1: Linear\n",
      "        layer2: Linear\n",
      "      edges_to_globals_aggregator: EdgesToGlobalsAggregator\n",
      "      nodes_to_globals_aggregator: NodesToGlobalsAggregator\n",
      "  processor_1: Processor\n",
      "  graph_network: Decoder\n",
      "    edge_block: EdgeBlock\n",
      "      mlp_model_dec: MLPModel_dec\n",
      "        layer1: Linear\n",
      "        layer2: Linear\n",
      "        layer3: Linear\n",
      "        layer4: Linear\n",
      "    node_block: NodeBlock\n",
      "      mlp_model_dec: MLPModel_dec\n",
      "        layer1: Linear\n",
      "        layer2: Linear\n",
      "        layer3: Linear\n",
      "        layer4: Linear\n",
      "      received_edges_to_nodes_aggregator: ReceivedEdgesToNodesAggregator\n",
      "    global_block: GlobalBlock\n",
      "      mlp_model_glob: MLPModel_glob\n",
      "        layer1: Linear\n",
      "        layer2: Linear\n",
      "      edges_to_globals_aggregator: EdgesToGlobalsAggregator\n",
      "      nodes_to_globals_aggregator: NodesToGlobalsAggregator\n",
      "  pooling_layer_double: PoolingLayer_double\n",
      "    linear_pool: Linear\n",
      "    global_transform: Linear\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sonnet as snt\n",
    "\n",
    "def list_layers(module, prefix=''):\n",
    "    \"\"\"\n",
    "    Recursively list the layers and sub-layers of a TensorFlow/Sonnet module.\n",
    "    \n",
    "    Args:\n",
    "    - module: The module from which to list layers.\n",
    "    - prefix: A prefix for nested layer names to indicate their hierarchy.\n",
    "    \"\"\"\n",
    "    # Check if the module is an instance of the layers we're interested in.\n",
    "    # Depending on your TensorFlow/Sonnet version, you might need to adjust these checks.\n",
    "    if isinstance(module, (tf.Module, tf.keras.layers.Layer, snt.Module)):\n",
    "        print(f\"{prefix}{module.name}: {type(module).__name__}\")\n",
    "        \n",
    "        # Iterate through all attributes of the module.\n",
    "        for name, attr in module.__dict__.items():\n",
    "            # Recursively list layers.\n",
    "            list_layers(attr, prefix=prefix + '  ')\n",
    "\n",
    "# Instantiate your model\n",
    "module = GNN_double_output()\n",
    "\n",
    "# List layers\n",
    "list_layers(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b658434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 12)\t1\n",
      "Graph indices   (0, 12)\t1 graph\n",
      "Corresponding graph tuple GraphsTuple(nodes=<tf.Tensor: shape=(4, 3), dtype=float64, numpy=\n",
      "array([[ 1.,  1.,  0.],\n",
      "       [ 1.,  0., -1.],\n",
      "       [-1.,  1.,  0.],\n",
      "       [-1.,  0., -1.]])>, edges=<tf.Tensor: shape=(8, 1), dtype=float64, numpy=\n",
      "array([[0.05],\n",
      "       [0.05],\n",
      "       [0.05],\n",
      "       [0.05],\n",
      "       [0.05],\n",
      "       [0.05],\n",
      "       [0.05],\n",
      "       [0.05]])>, receivers=<tf.Tensor: shape=(8,), dtype=int32, numpy=array([2, 1, 3, 3, 0, 0, 1, 2], dtype=int32)>, senders=<tf.Tensor: shape=(8,), dtype=int32, numpy=array([0, 0, 1, 2, 2, 1, 3, 3], dtype=int32)>, globals=<tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[0.5]])>, n_node=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([4], dtype=int32)>, n_edge=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([8], dtype=int32)>)\n",
      "index 0 amplitude tf.Tensor(-0.041391842, shape=(), dtype=float32)   (0, 12)\t1\n",
      "index 1 amplitude tf.Tensor(0.1613889, shape=(), dtype=float32)   (0, 0)\t1\n",
      "index 2 amplitude tf.Tensor(-0.07960918, shape=(), dtype=float32)   (0, 6)\t1\n",
      "index 3 amplitude tf.Tensor(-0.07960918, shape=(), dtype=float32)   (0, 9)\t1\n",
      "Energy of the system   (0, 0)\t(0.5361479548220022+0j)\n"
     ]
    }
   ],
   "source": [
    "num_config= 4\n",
    "training_samples=1 #Just for debugging\n",
    "for i in range(training_samples):\n",
    "    start=(i*num_config)%19200\n",
    "    end=(start +num_config)%19200\n",
    "    graph_tuples_batch_indices= configurations[start:end]\n",
    "    print(configurations[0])\n",
    "    graph_tuples_batch= graph_tuples[start:end]\n",
    "    print(\"Graph indices\", graph_tuples_batch_indices[0], \"graph\")\n",
    "    print(\"Corresponding graph tuple\", graph_tuples_batch[0])\n",
    "\n",
    "    #print(graph_tuples_batch)\n",
    "    res=gnn(graph_tuples_batch[0])\n",
    "    energy=StochasticEnergy(graph_tuples_batch_indices, graph_tuples_batch, gnn , Hamiltonian)\n",
    "    print(\"Energy of the system\", energy)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01dd9785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations used in compute wave_fucntion   (0, 12)\t1  \n",
      "\n",
      "here is my little wave   (12, 0)\t(-0.041391842+0.21869823j)\n",
      "Hamiltonian is good, what about the wave   (12, 0)\t(-0.041391842+0.21869823j)\n",
      "not yet to be checked   (0, 0)\t(0.05158395986158364+0j)\n",
      "Time elapsed 0.021310806274414062\n",
      "index 0 amplitude tf.Tensor(-0.041391842, shape=(), dtype=float32)   (0, 12)\t1\n",
      "index 0 amplitude tf.Tensor(-0.041391842, shape=(), dtype=float32)   (0, 12)\t1\n",
      "  (0, 0)\t(0.05158395781472935-1.6940658945086007e-21j)\n",
      "0.03712964057922363\n",
      "Percentage difference 0.4260432920447176\n"
     ]
    }
   ],
   "source": [
    "start= time.time()\n",
    "start_idx=0\n",
    "end_idx=1\n",
    "graph_tuples_batch = graph_tuples[start_idx:end_idx]\n",
    "configurations_new = configurations[start_idx:end_idx]\n",
    "print(\"Configurations used in compute wave_fucntion\", configurations_new[0], \" \\n\")\n",
    "wave_function = compute_wave_function_csr(graph_tuples_batch, gnn, configurations_new)\n",
    "print(\"here is my little wave\", wave_function)\n",
    "beta=0.005\n",
    "#print(\"Hamiltonian\", Hamiltonian, \"Good Check it is alive\")\n",
    "\n",
    "ite= wave_function-beta* Hamiltonian.dot(wave_function)\n",
    "print(\"Hamiltonian is good, what about the wave\", wave_function)\n",
    "new_norm= ite.conj().transpose().dot(ite)\n",
    "\n",
    "print(\"not yet to be checked\", new_norm)\n",
    "t1= time.time()-start\n",
    "print(\"Time elapsed\", t1)\n",
    "###This is to show that computing the wave_function and then the norm using the WF is much quicker then computing the energy several times\n",
    "start=time.time()\n",
    "elem1=StochasticEnergy(configurations_new, graph_tuples_batch, gnn , -2*beta*Hamiltonian)\n",
    "\n",
    "elem0=wave_function.conj().transpose().dot(wave_function)\n",
    "elem2= StochasticEnergy(configurations_new, graph_tuples_batch, gnn , (beta**2)*Hamiltonian*Hamiltonian) \n",
    "print(elem2+elem1 + elem0)\n",
    "\n",
    "t2=time.time()-start\n",
    "print(t2)\n",
    "print(\"Percentage difference\", np.abs(t1-t2)/(t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa7f3c",
   "metadata": {},
   "source": [
    "#### Now let's dive into the markov chain update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b65c55d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01597285270690918\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "checker= 3\n",
    "#print(graph_tuples[checker].nodes)\n",
    "\n",
    "# Create a new graph tuple with the proposed nodes\n",
    "for i, graph_tuple in enumerate(graph_tuples[:20000]):\n",
    "    #print(i)\n",
    "    proposed_nodes = graph_tuple.nodes.numpy().copy()  # Convert to numpy array for mutability\n",
    "    j = np.random.randint(len(proposed_nodes))  # Choose a random node\n",
    "    proposed_nodes[j, 0] *= -1  # Flip the spin at this node\n",
    "    proposed_graph_tuple = graph_tuple.replace(nodes=tf.constant(proposed_nodes))\n",
    "    graph_tuple= proposed_graph_tuple\n",
    "    \n",
    "# print(graph_tuples[checker].nodes)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5394781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn=GNN_double_output()\n",
    "start_time=time.time()\n",
    "for i in range(1):\n",
    "    a=gnn(graph_tuples[i])[0]\n",
    "# Define the optimizer with the given hyperparameters\n",
    "\n",
    "initial_learning_rate = 7e-3\n",
    "decay_steps = 8 * 1e5\n",
    "decay_rate = 0.1\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps, decay_rate, staircase=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.99, clipnorm=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25bd7aee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_sparse_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17427/3452811157.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_sparse_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsi_csr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_csr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_sparse_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 32  # Set your batch size\n",
    "start = 0  # Initialize the start index for batching\n",
    "N_sweeps = 5  # Number of Monte Carlo sweeps\n",
    "\n",
    "for step in range(30):  # IT-SWO steps\n",
    "    # Compute phi once at the beginning of each outer step, this is the ITO of psi\n",
    "    graph_tuples_batch=graph_tuples[start:start + batch_size]\n",
    "    graph_tuples_batch_indices= configurations[start:start + batch_size]\n",
    "    psi_csr = compute_wave_function_csr(graph_tuples_batch, gnn, graph_tuples_batch_indices)\n",
    "    beta = 0.05\n",
    "    phi_csr = psi_csr - beta * Hamiltonian.dot(psi_csr)\n",
    "    phi_sparse_coo = phi_csr.tocoo()\n",
    "    indices = np.column_stack((phi_sparse_coo.row, phi_sparse_coo.col))\n",
    "    phi_sparse_tf = tf.cast(tf.sparse.SparseTensor(indices, phi_sparse_coo.data, phi_sparse_coo.shape), dtype=tf.complex64)\n",
    "    \n",
    "    for _ in range(3):  # Inner loop iterations: here we let psi approximate its ITO phi\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(gnn.trainable_variables)\n",
    "            \n",
    "            loss = loss_sparse_vectors(psi_csr, phi_csr)\n",
    "            print(loss)\n",
    "        \n",
    "        \n",
    "        gradients = tape.gradient(loss, gnn.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, gnn.trainable_variables))\n",
    "        time_s = time.time()\n",
    "        # Update graph_tuples and configurations using Monte Carlo updates\n",
    "        for i in range(start, start + batch_size):\n",
    "            updated_graph_tuple, updated_configuration = monte_carlo_update(graph_tuples[i], gnn, N_sweeps)\n",
    "            graph_tuples[i] = updated_graph_tuple\n",
    "            configurations[i] = updated_configuration\n",
    "        print(time.time() - time_s, \"Monte Carlo update with N_sweeps\", N_sweeps)\n",
    "    \n",
    "    print(gradients[0][0], \"step\", step)\n",
    "    \n",
    "    \n",
    "    # Update the start index for the next batch\n",
    "    start += batch_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13b5ea2",
   "metadata": {},
   "source": [
    "# From now on is all trial to compute proximity of wave function to real eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a60e6ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16ded7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.linalg.sparse import sparse_csr_matrix_ops\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90093317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'graph_nets.graphs.GraphsTuple'>\n",
      "norms: tf.Tensor((1.7510287+0j), shape=(), dtype=complex64) tf.Tensor((1.5934507+0j), shape=(), dtype=complex64)\n",
      "tf.Tensor((2.7901778+0j), shape=(), dtype=complex64) DENOMINATOR\n",
      "numerator SparseTensor(indices=tf.Tensor(\n",
      "[[ 0  0]\n",
      " [ 0  3]\n",
      " [ 0  5]\n",
      " [ 0  6]\n",
      " [ 0  9]\n",
      " [ 0 10]\n",
      " [ 0 12]\n",
      " [ 6  0]\n",
      " [ 6  3]\n",
      " [ 6  5]\n",
      " [ 6  6]\n",
      " [ 6  9]\n",
      " [ 6 10]\n",
      " [ 6 12]\n",
      " [ 9  0]\n",
      " [ 9  3]\n",
      " [ 9  5]\n",
      " [ 9  6]\n",
      " [ 9  9]\n",
      " [ 9 10]\n",
      " [ 9 12]\n",
      " [12  0]\n",
      " [12  3]\n",
      " [12  5]\n",
      " [12  6]\n",
      " [12  9]\n",
      " [12 10]\n",
      " [12 12]], shape=(28, 2), dtype=int64), values=tf.Tensor(\n",
      "[ 0.59657955-9.1890097e-03j -0.03639577-3.2595173e-04j\n",
      " -0.18082526-3.2595545e-04j  0.60067433+5.5412352e-03j\n",
      "  0.60067433+5.5412352e-03j -0.18082526-3.2595545e-04j\n",
      "  0.8301812 -3.2597780e-04j  0.6572834 +0.0000000e+00j\n",
      " -0.0400841 -9.7652897e-04j -0.199172  -3.4269318e-03j\n",
      "  0.66154385+1.6294718e-02j  0.66154385+1.6294718e-02j\n",
      " -0.199172  -3.4269318e-03j  0.91444325+1.3725907e-02j\n",
      "  0.6012616 -1.4647931e-02j -0.0366894 +1.8626451e-09j\n",
      " -0.18227248+1.3038144e-03j  0.60552204+1.6298890e-04j\n",
      "  0.60552204+1.6298890e-04j -0.18227248+1.3038144e-03j\n",
      "  0.83680904-7.8228712e-03j  0.6012616 -1.4647931e-02j\n",
      " -0.0366894 +1.8626451e-09j -0.18227248+1.3038144e-03j\n",
      "  0.60552204+1.6298890e-04j  0.60552204+1.6298890e-04j\n",
      " -0.18227248+1.3038144e-03j  0.83680904-7.8228712e-03j], shape=(28,), dtype=complex64), dense_shape=tf.Tensor([16 16], shape=(2,), dtype=int64)) Norm \n",
      " tf.Tensor(2.7901778, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y: Tensor conversion requested dtype complex64 for Tensor with dtype float32: <tf.Tensor: shape=(), dtype=float32, numpy=2.7901778>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17427/3267682188.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mpsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_wave_function_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_tuples_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_tuples_batch_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msystem_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss_tensor_updated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_sparse_tf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_17427/3267682188.py\u001b[0m in \u001b[0;36mcompute_loss_tensor_updated\u001b[0;34m(psi_sparse, phi_sparse)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;31m#print(psi_sparse, phi_sparse)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"numerator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Norm\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenominator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerator\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdenominator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/GraphNet2/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/GraphNet2/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1599\u001b[0m               \u001b[0;34mf\"Tensor conversion requested dtype {dtype.name} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m               \u001b[0;34mf\"for Tensor with dtype {value.dtype.name}: {value!r}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m               name=name))\n\u001b[0m\u001b[1;32m   1602\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y: Tensor conversion requested dtype complex64 for Tensor with dtype float32: <tf.Tensor: shape=(), dtype=float32, numpy=2.7901778>"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from compgraph.sparse_ham import compute_wave_function_csr\n",
    "from compgraph.tensor_wave_functions import compute_wave_function_sparse_tensor\n",
    "\n",
    "batch_size = 4  # Set your batch size\n",
    "start = 0  # Initialize the start index for batching\n",
    "N_sweeps = 5  # Number of Monte Carlo sweeps\n",
    "def compute_sparse_tensor_norm(sparse_tensor):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "    - sparse_tensor: A tf.SparseTensor.\n",
    "\n",
    "    Returns:\n",
    "    - The L2 or Euclidean norm of a sparse tensor.\n",
    "    \"\"\"\n",
    "    # Compute the square of the values (i.e., v_i^2 for each non-zero v_i)\n",
    "    norm = tf.norm(sparse_tensor.values)\n",
    "\n",
    "\n",
    "    return norm\n",
    "\n",
    "def tf_multiply(a: tf.SparseTensor, b: tf.SparseTensor):\n",
    "    a_sm = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(\n",
    "        a.indices, a.values, a.dense_shape)\n",
    "    #print(a.dense_shape,'shape of the dense shape of a', a_sm)\n",
    "    b_sm = sparse_csr_matrix_ops.sparse_tensor_to_csr_sparse_matrix(\n",
    "        b.indices, b.values, b.dense_shape\n",
    "    )\n",
    "\n",
    "    c_sm = sparse_csr_matrix_ops.sparse_matrix_sparse_mat_mul(\n",
    "        a=a_sm, b=b_sm, transpose_b=True, type=tf.complex64\n",
    "    )\n",
    "\n",
    "    c = sparse_csr_matrix_ops.csr_sparse_matrix_to_sparse_tensor(\n",
    "        c_sm, tf.complex64\n",
    "    )\n",
    "\n",
    "    return tf.SparseTensor(\n",
    "        c.indices, c.values, dense_shape=c.dense_shape\n",
    "    )\n",
    "def compute_loss_tensor_updated(psi_sparse, phi_sparse):\n",
    "    # Compute the conjugate of the sparse tensor values\n",
    "    psi_sparse_conj = tf.SparseTensor(\n",
    "        indices=psi_sparse.indices,\n",
    "        values=tf.math.conj(psi_sparse.values),\n",
    "        dense_shape=psi_sparse.dense_shape\n",
    "    )\n",
    "    \n",
    "    phi_sparse_conj = tf.SparseTensor(\n",
    "        indices=phi_sparse.indices,\n",
    "        values=tf.math.conj(phi_sparse.values),\n",
    "        dense_shape=phi_sparse.dense_shape\n",
    "    )\n",
    "    \n",
    "    # Reorder the indices of the conjugate sparse tensor\n",
    "    psi_sparse_conj = tf.sparse.reorder(psi_sparse_conj)\n",
    "    phi_sparse_conj = tf.sparse.reorder(phi_sparse_conj)\n",
    "\n",
    "    \n",
    "    # Compute the norms using sparse-dense matrix multiplication\n",
    "    psi_norm=compute_sparse_tensor_norm(psi_sparse)\n",
    "    phi_norm =compute_sparse_tensor_norm(phi_sparse)\n",
    "    print(\"norms:\", psi_norm, phi_norm)\n",
    "    denominator = psi_norm * phi_norm\n",
    "    print(denominator,'DENOMINATOR')\n",
    "    denominator = tf.cast(denominator, tf.float32)\n",
    "\n",
    "    # Compute the numerator using dense-sparse matrix multiplication\n",
    "    numerator = tf_multiply(psi_sparse, phi_sparse_conj)\n",
    "    #print(psi_sparse, phi_sparse)\n",
    "    print(\"numerator\", numerator, \"Norm\" ,\"\\n\", denominator)\n",
    "    loss = 1.-numerator/denominator\n",
    "    \n",
    "    return loss\n",
    "\n",
    "for step in range(30):  # IT-SWO steps\n",
    "    # Compute phi once at the beginning of each outer step, this is the ITO of psi\n",
    "    graph_tuples_batch=graph_tuples[start:start + batch_size]\n",
    "    graph_tuples_batch_indices= configurations[start:start + batch_size]\n",
    "    psi_csr = compute_wave_function_csr(graph_tuples_batch, gnn, graph_tuples_batch_indices)\n",
    "    beta = 0.05\n",
    "    phi_csr = psi_csr - beta * Hamiltonian.dot(psi_csr)\n",
    "    phi_sparse_coo = phi_csr.tocoo()\n",
    "    indices = np.column_stack((phi_sparse_coo.row, phi_sparse_coo.col))\n",
    "    phi_sparse_tf = tf.cast(tf.sparse.SparseTensor(indices, phi_sparse_coo.data, phi_sparse_coo.shape), dtype=tf.complex64)\n",
    "\n",
    "    for _ in range(5):  # Inner loop iterations: here we let psi approximate its ITO phi\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(gnn.trainable_variables)\n",
    "            psi = compute_wave_function_sparse_tensor(graph_tuples_batch, gnn, graph_tuples_batch_indices, system_dim=2**4)\n",
    "            loss = compute_loss_tensor_updated(psi, phi_sparse_tf)\n",
    "            print(loss)\n",
    "        \n",
    "        time_s = time.time()\n",
    "        gradients = tape.gradient(loss, gnn.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, gnn.trainable_variables))\n",
    "\n",
    "        # Update graph_tuples and configurations using Sequential Monte Carlo updates\n",
    "        updated_tuples_and_configs = sequential_monte_carlo_update(\n",
    "            graph_tuples[start:start + batch_size], gnn, N_sweeps\n",
    "        )\n",
    "        for i, (updated_graph_tuple, updated_configuration) in enumerate(updated_tuples_and_configs):\n",
    "            graph_tuples[start + i] = updated_graph_tuple\n",
    "            configurations[start + i] = updated_configuration\n",
    "\n",
    "        print(time.time() - time_s, \"Monte Carlo update with N_sweeps\", N_sweeps)\n",
    "    \n",
    "    print(gradients[0][0], \"step\", step)\n",
    "    \n",
    "    # Update the start index for the next batch\n",
    "    start += batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d2c4167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d290caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'graph_nets.graphs.GraphsTuple'>\n",
      "Gradient for gnn_double_output/graph_network/edge_block/mlp_model_enc/layer1/b:0: tf.Tensor(\n",
      "[ 0.         -0.36966752  0.28359411 -0.15598896 -0.24703589  0.47167627\n",
      "  0.50503715  0.07714894  0.19251668  0.05756854 -0.54210466 -0.03360454\n",
      "  0.13480605 -0.11786553 -0.3771505   0.21527855 -0.04141254  0.29126534\n",
      " -0.30643947 -0.17212504  0.02085138 -0.18820141  0.10160268 -0.0452376\n",
      " -0.06314923 -0.39562747 -0.03983399  0.29386004 -0.00885216  0.18171405\n",
      " -0.50897699 -0.14505066], shape=(32,), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/edge_block/mlp_model_enc/layer1/w:0: tf.Tensor(\n",
      "[[ 0.00000000e+00 -1.84833759e-02  1.41797057e-02 -7.79944792e-03\n",
      "  -1.23517946e-02  2.35838133e-02  2.52518573e-02  3.85744685e-03\n",
      "   9.62583413e-03  2.87842722e-03 -2.71052332e-02 -1.68022686e-03\n",
      "   6.74030238e-03 -5.89327672e-03 -1.88575250e-02  1.07639276e-02\n",
      "  -2.07062692e-03  1.45632672e-02 -1.53219737e-02 -8.60625199e-03\n",
      "   1.04256897e-03 -9.41007066e-03  5.08013391e-03 -2.26187986e-03\n",
      "  -3.15746157e-03 -1.97813736e-02 -1.99169951e-03  1.46930021e-02\n",
      "  -4.42607951e-04  9.08570235e-03 -2.54488497e-02 -7.25253291e-03]\n",
      " [ 0.00000000e+00 -3.69667517e-01  2.68196692e-01 -1.69845077e-02\n",
      "  -1.18222524e-01  3.67110076e-01  9.57670810e-02  1.08416195e-01\n",
      "   1.22501451e-01  5.75685443e-02 -3.44445681e-01 -2.25831758e-02\n",
      "  -1.65415044e-01 -1.17865534e-01 -2.83936399e-01  1.96363038e-01\n",
      "   4.14125384e-02  1.99286397e-01 -1.70373872e-01 -1.34619080e-01\n",
      "  -2.08513795e-02 -1.75241515e-01  1.01602678e-01 -7.53004253e-02\n",
      "   1.76359964e-01 -5.11440641e-01  3.98339902e-02  2.93860041e-01\n",
      "  -8.85215902e-03 -2.04039927e-02 -1.29287023e-01  4.32984183e-02]\n",
      " [ 0.00000000e+00 -1.42556870e-01  1.07578979e-01 -6.79598871e-02\n",
      "  -3.09294299e-02  1.90908836e-01  1.96514295e-01  2.81116630e-02\n",
      "   9.29246954e-02  0.00000000e+00 -3.28026587e-01 -1.11518284e-02\n",
      "   1.15056793e-01 -6.15277190e-02 -3.53999930e-02  1.00089975e-01\n",
      "   1.57554672e-02  6.52057893e-02  0.00000000e+00 -1.23570256e-01\n",
      "   5.45710599e-03 -2.17016906e-01  6.86897097e-02 -6.31558452e-02\n",
      "  -8.08940460e-02 -2.20865359e-01 -2.27998463e-02  1.92226856e-01\n",
      "   0.00000000e+00  1.24412578e-01 -3.38606394e-01 -8.01458487e-03]\n",
      " [ 0.00000000e+00  2.27110648e-01 -1.76015135e-01  8.80290713e-02\n",
      "   2.16106463e-01 -2.80767430e-01 -3.08522852e-01 -4.90372739e-02\n",
      "  -9.95919872e-02 -5.75685443e-02  2.14078077e-01  2.24527087e-02\n",
      "  -1.97492551e-02  5.63378154e-02  3.41750507e-01 -1.15188577e-01\n",
      "   5.71680056e-02 -2.26059555e-01  3.06439473e-01  4.85547834e-02\n",
      "  -1.53942735e-02 -2.88154926e-02 -3.29129685e-02 -1.79182481e-02\n",
      "  -1.77448147e-02  1.74762113e-01  1.70341439e-02 -1.01633185e-01\n",
      "   8.85215902e-03 -5.73014687e-02  1.70370600e-01  1.37036073e-01]\n",
      " [ 0.00000000e+00  8.37407798e-02 -2.83594114e-01 -4.88979956e-02\n",
      "  -5.20651058e-02 -1.69499970e-01  4.02787137e-01 -7.92088222e-02\n",
      "   6.02279773e-02 -5.75685443e-02 -1.79260035e-01  3.36045371e-02\n",
      "   1.49430324e-01  3.27961453e-02 -1.10191478e-01  5.07244499e-04\n",
      "  -6.94797022e-02  1.28086882e-01 -1.17065730e-01  4.78999593e-02\n",
      "   1.31850328e-02  1.56428905e-01  3.95473200e-02  4.52375972e-02\n",
      "  -7.19426808e-02 -8.76774926e-02 -3.98339902e-02 -3.42351405e-02\n",
      "   8.85215902e-03  6.62547480e-02 -2.59846345e-01 -1.45050658e-01]\n",
      " [ 0.00000000e+00 -1.28147734e-01  1.31278252e-01 -1.55988958e-01\n",
      "  -1.34255476e-01  1.91193768e-01  1.75527487e-01  5.17570409e-02\n",
      "   1.05359268e-01  0.00000000e+00 -4.47755636e-01 -5.08728578e-02\n",
      "   1.37693896e-01 -1.17865534e-01 -1.94262016e-01  2.15278551e-01\n",
      "  -1.64201151e-02  5.04659987e-03 -5.49372127e-02 -1.39037922e-01\n",
      "  -3.75597928e-02 -2.05280212e-01  0.00000000e+00 -2.21642855e-02\n",
      "  -4.15142502e-02 -2.90115315e-01 -3.98339902e-02  1.35043876e-01\n",
      "   0.00000000e+00  1.76426963e-01 -2.87398193e-01  7.37660087e-03]\n",
      " [ 0.00000000e+00  2.41519783e-01 -1.52315862e-01  0.00000000e+00\n",
      "   1.12780417e-01 -2.80482497e-01 -3.29509660e-01 -2.53918961e-02\n",
      "  -8.71574142e-02 -5.75685443e-02  9.43490280e-02 -1.72683207e-02\n",
      "   2.88784844e-03  0.00000000e+00  1.82888484e-01  0.00000000e+00\n",
      "   2.49924233e-02 -2.86218744e-01  2.51502261e-01  3.30871177e-02\n",
      "  -5.84111723e-02 -1.70787988e-02 -1.01602678e-01  2.30733117e-02\n",
      "   2.16349811e-02  1.05512157e-01  0.00000000e+00 -1.58816166e-01\n",
      "   8.85215902e-03 -5.28708356e-03  2.21578802e-01  1.52427259e-01]\n",
      " [ 0.00000000e+00 -1.84833759e-01  1.41797057e-01 -7.79944792e-02\n",
      "  -1.23517946e-01  2.35838133e-01  2.52518573e-01  3.85744685e-02\n",
      "   9.62583413e-02  2.87842722e-02 -2.71052332e-01 -1.68022686e-02\n",
      "   6.74030238e-02 -5.89327672e-02 -1.88575250e-01  1.07639276e-01\n",
      "  -2.07062692e-02  1.45632672e-01 -1.53219737e-01 -8.60625199e-02\n",
      "   1.04256897e-02 -9.41007066e-02  5.08013391e-02 -2.26187986e-02\n",
      "  -3.15746157e-02 -1.97813736e-01 -1.99169951e-02  1.46930021e-01\n",
      "  -4.42607951e-03  9.08570235e-02 -2.54488497e-01 -7.25253291e-02]], shape=(8, 32), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/edge_block/mlp_model_enc/layer2/b:0: tf.Tensor(\n",
      "[ 0.10018193 -0.43496887 -0.00165831 -0.18845029 -0.13667439 -0.90492843\n",
      "  0.64253076 -0.60654223 -0.13724514  0.99773705 -0.00404151  0.36083815\n",
      "  0.         -0.04428852  0.          0.22579361  0.         -0.96602661\n",
      "  0.36829061  0.          0.          0.         -0.0753752   0.31739918\n",
      "  0.79826313 -0.11970103 -0.09626071  0.         -0.57230117 -0.68252319\n",
      "  1.07875714  0.13648287], shape=(32,), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/edge_block/mlp_model_enc/layer2/w:0: tf.Tensor(\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 8.12568238e-02 -1.29764629e-01  0.00000000e+00 ... -3.43375612e-01\n",
      "   5.18704737e-01  0.00000000e+00]\n",
      " [ 2.14122436e-03 -1.50103225e-02 -4.44580497e-04 ... -9.94545809e-02\n",
      "   2.17744646e-01  7.90531336e-03]\n",
      " ...\n",
      " [ 2.46821774e-02 -1.95297746e-01 -1.09997274e-04 ... -3.68381003e-01\n",
      "   3.31345096e-01  4.29778924e-02]\n",
      " [ 4.71437933e-02 -2.01200609e-01 -1.26199538e-05 ... -3.32512752e-01\n",
      "   3.05425735e-01  4.95060160e-02]\n",
      " [ 1.02707942e-02 -9.50581896e-02  0.00000000e+00 ... -1.47301407e-01\n",
      "   1.01336485e-01  2.65740848e-02]], shape=(32, 32), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/edge_block/mlp_model_enc/layer3/b:0: tf.Tensor(\n",
      "[ 0.          0.          0.3510147  -2.99669681 -0.40374349  0.02392152\n",
      "  0.          1.20805982  0.43778789  0.89713834  2.41622129  1.21317023\n",
      " -0.00443484  0.         -1.19373576  0.73110083  0.         -0.48091074\n",
      "  0.05781518 -0.2781302  -1.09990278  0.13202101  0.12297968 -0.1395438\n",
      " -0.13245083  0.48946236  0.33555174  0.          0.13862978  0.26450163\n",
      "  1.17845434 -0.1662869 ], shape=(32,), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/edge_block/mlp_model_enc/layer3/w:0: tf.Tensor(\n",
      "[[ 0.00000000e+00  0.00000000e+00  4.34247245e-04 ...  8.79895056e-02\n",
      "   5.47178174e-02  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  3.81382406e-02 ...  1.33738666e-01\n",
      "   2.33805295e-01 -4.89917752e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.69465843e-03 ...  2.22474820e-03\n",
      "   1.37866443e-02  0.00000000e+00]\n",
      " ...\n",
      " [ 0.00000000e+00  0.00000000e+00  1.23766105e-01 ...  1.58358917e-01\n",
      "   4.43367886e-01 -1.48383713e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.80191523e-01 ...  3.24484512e-02\n",
      "   5.52546216e-01 -1.38144333e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00 -6.15941831e-03 ...  6.19786236e-03\n",
      "   8.12711630e-02  0.00000000e+00]], shape=(32, 32), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/edge_block/mlp_model_enc/layer4/b:0: tf.Tensor(\n",
      "[ 0.06819027  0.17818351  0.07880916  1.53057863 -6.43897352  3.39672601\n",
      "  0.84906437 -0.68683224 -3.28259954  0.          5.37015183 -4.23583181\n",
      " -0.15542218 -1.93618331  0.1132347  -3.00784293], shape=(16,), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/edge_block/mlp_model_enc/layer4/w:0: tf.Tensor(\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 9.84103201e-03  1.30202572e-02  0.00000000e+00  6.66699115e-02\n",
      "  -1.46105356e-01  6.16793013e-02  0.00000000e+00 -2.45137216e-02\n",
      "  -4.72810450e-02  0.00000000e+00  1.37711091e-01 -3.39895478e-02\n",
      "  -5.21900997e-04 -3.16893014e-02  1.38063109e-02 -2.36151095e-02]\n",
      " [ 0.00000000e+00  2.05909227e-02  4.10695261e-03  5.26765722e-01\n",
      "  -2.35644442e+00  1.21878614e+00  3.52956170e-01 -5.85230348e-02\n",
      "  -1.10890266e+00  0.00000000e+00  1.79545653e+00 -1.82052920e+00\n",
      "  -8.34819528e-02 -7.28982681e-01  2.97123833e-02 -1.29536427e+00]\n",
      " [ 2.03955450e-03  3.52472806e-03  5.56766819e-03  7.77779126e-02\n",
      "  -3.33244919e-01  1.99835577e-01  6.14634435e-02 -3.09722330e-02\n",
      "  -2.03435992e-01  0.00000000e+00  3.63462997e-01 -3.00705135e-01\n",
      "  -1.39248550e-02 -1.24802040e-01  2.46433039e-03 -1.62300242e-01]\n",
      " [ 5.75141434e-03  7.60945539e-03  0.00000000e+00  1.11797475e-02\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.43266041e-02\n",
      "  -1.42678013e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.18041801e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  9.53737012e-03  1.27078791e-04  3.95280465e-02\n",
      "  -1.35268116e-01  1.36994945e-01  5.40657462e-02 -1.93713688e-02\n",
      "  -1.33094550e-01  0.00000000e+00  2.11049531e-01 -1.59077699e-01\n",
      "  -1.24416768e-02 -8.10005998e-02 -4.79920787e-03 -3.94555242e-02]\n",
      " [ 5.09349196e-03  6.73898585e-03  1.38691354e-02  2.56261485e-01\n",
      "  -6.91826262e-01  3.72261524e-01  3.64111774e-02 -7.31234106e-02\n",
      "  -2.52360268e-01  0.00000000e+00  8.05686170e-01 -3.52109705e-01\n",
      "  -1.29976650e-02 -2.07072773e-01  3.73978104e-02 -1.53761108e-01]\n",
      " [ 7.41836959e-03  3.01797647e-02  3.39147779e-03  4.31914465e-01\n",
      "  -1.35255529e+00  7.30645956e-01  2.42391116e-01 -7.34381581e-02\n",
      "  -7.03955017e-01  0.00000000e+00  1.01143164e+00 -1.18899910e+00\n",
      "  -4.13568988e-02 -4.32068819e-01  2.35285381e-02 -8.97938617e-01]\n",
      " [ 1.36328037e-03  1.80369915e-03  3.22172482e-03  4.02560787e-01\n",
      "  -1.08702060e+00  5.65681665e-01  1.33125815e-01 -1.74347696e-02\n",
      "  -4.52222117e-01  0.00000000e+00  1.00614698e+00 -9.15654587e-01\n",
      "  -3.41078478e-02 -3.34907898e-01  4.46966737e-02 -6.28406814e-01]\n",
      " [ 2.07686898e-02  3.99903524e-02  2.07375159e-02  2.97916147e-01\n",
      "  -1.16751446e+00  6.24556152e-01  8.69070184e-02 -1.66786301e-01\n",
      "  -5.71461019e-01  0.00000000e+00  1.12034188e+00 -5.29578842e-01\n",
      "  -2.08136449e-02 -3.44932279e-01  3.32452767e-02 -3.00433334e-01]\n",
      " [ 0.00000000e+00  1.10374488e-03  0.00000000e+00  1.11928839e-01\n",
      "  -6.15189091e-01  3.49583499e-01  6.92123312e-02 -2.17773302e-03\n",
      "  -2.82957216e-01  0.00000000e+00  5.79834284e-01 -3.45822333e-01\n",
      "  -2.92059871e-02 -2.12267810e-01  6.92676368e-03 -1.22894831e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.55581249e-03  7.25166287e-03  5.31238756e-03  3.13491759e-02\n",
      "  -1.41507921e-01  5.93560516e-02  4.31937152e-03 -3.72710187e-02\n",
      "  -3.91654680e-02  0.00000000e+00  1.16022126e-01 -3.54544939e-03\n",
      "   2.99149121e-03 -2.36666481e-02  8.98085208e-03 -2.41189186e-02]\n",
      " [ 1.12410998e-02  1.57211465e-02  2.22511650e-03  2.18507395e-02\n",
      "  -8.67783654e-02  3.89889640e-02  5.08246176e-03 -3.93715018e-02\n",
      "  -6.80265194e-02  0.00000000e+00  6.65226134e-02 -1.82420568e-02\n",
      "   1.58274601e-03 -2.11160145e-02  0.00000000e+00 -2.24883720e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 5.97911345e-03  7.91071455e-03  1.39991032e-02  3.79464589e-02\n",
      "  -1.90165735e-01  8.05439772e-02  0.00000000e+00 -7.58958112e-02\n",
      "  -8.54935448e-02  0.00000000e+00  1.80885134e-01 -2.00965791e-02\n",
      "   6.66764098e-03 -3.61852124e-02  7.25404459e-03 -2.21653555e-02]\n",
      " [ 4.84265814e-04  6.40711813e-04  0.00000000e+00  1.38263255e-01\n",
      "  -4.61851607e-01  2.31693288e-01  5.50285328e-02 -1.20629191e-03\n",
      "  -2.11708160e-01  0.00000000e+00  4.10052020e-01 -4.08316285e-01\n",
      "  -1.39068468e-02 -1.36197423e-01  1.94682892e-02 -3.54951280e-01]\n",
      " [ 1.82278946e-04  2.41165638e-04  7.05577693e-03  3.54318515e-04\n",
      "  -9.22260077e-02  4.62842290e-02  0.00000000e+00 -3.12000646e-02\n",
      "  -5.25161496e-02  0.00000000e+00  1.02170451e-01  0.00000000e+00\n",
      "   2.04367127e-03 -2.27414527e-02  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  9.59960140e-03  0.00000000e+00  1.20870466e-02\n",
      "  -4.28850196e-01  2.13167526e-01  7.47234319e-02 -1.89403994e-02\n",
      "  -2.02432030e-01  0.00000000e+00  2.59238251e-01 -2.44422599e-01\n",
      "  -1.86354735e-02 -1.27567759e-01 -1.49919157e-03 -1.51416169e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -1.44361658e-01  8.18858300e-02  0.00000000e+00  0.00000000e+00\n",
      "  -8.55103071e-02  0.00000000e+00  4.10166737e-02  0.00000000e+00\n",
      "  -4.66807353e-03 -4.98168594e-02  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -1.50884502e-01  7.11889930e-02  1.76173819e-02  0.00000000e+00\n",
      "  -6.64057472e-02  0.00000000e+00  7.91871212e-02 -7.34287472e-02\n",
      "  -5.17265817e-03 -4.29897262e-02  0.00000000e+00 -7.72304488e-02]\n",
      " [ 2.12866406e-02  4.06062026e-02  8.53267657e-03  9.52113511e-02\n",
      "  -5.44325711e-01  3.32184839e-01  6.82067678e-02 -1.14756123e-01\n",
      "  -3.83324477e-01  0.00000000e+00  4.40287802e-01 -2.48764453e-01\n",
      "  -1.25241959e-02 -1.87734352e-01 -7.31489134e-03 -1.44504732e-01]\n",
      " [ 2.61659816e-03  3.46191142e-03  0.00000000e+00  1.91952714e-01\n",
      "  -5.31209986e-01  2.16288483e-01  5.76987218e-02 -6.51786915e-03\n",
      "  -1.92754032e-01  0.00000000e+00  2.67994780e-01 -4.05682879e-01\n",
      "  -6.28834339e-03 -1.26107873e-01  2.50988791e-02 -4.15347425e-01]\n",
      " [ 0.00000000e+00  6.91394893e-03  5.50179598e-03  1.54896778e-01\n",
      "  -1.01186638e+00  5.44734820e-01  1.56345066e-01 -3.76159378e-02\n",
      "  -5.02115280e-01  0.00000000e+00  8.43314678e-01 -7.04628677e-01\n",
      "  -4.24965181e-02 -3.34161532e-01  1.48188601e-03 -3.87334194e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  2.36936071e-02\n",
      "  -3.56248811e-01  2.15492020e-01  4.62808008e-02  0.00000000e+00\n",
      "  -2.07682824e-01  0.00000000e+00  2.98306970e-01 -1.80467153e-01\n",
      "  -1.84320141e-02 -1.35322338e-01 -3.09945168e-03 -8.28871763e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 5.29658944e-03  9.60434730e-03  1.31593551e-03  1.02956471e-02\n",
      "  -2.23778844e-01  1.01726318e-01  1.38302607e-02 -2.40512225e-02\n",
      "  -1.15503147e-01  0.00000000e+00  1.07363411e-01 -4.86425020e-02\n",
      "  -3.65746400e-03 -5.81439951e-02  0.00000000e+00 -6.12653051e-02]\n",
      " [ 7.64828804e-03  1.19485451e-02  1.06962909e-02  2.46728723e-01\n",
      "  -8.87221586e-01  4.06275443e-01  2.87491436e-02 -6.92709638e-02\n",
      "  -3.17334553e-01  0.00000000e+00  8.01295226e-01 -4.18824492e-01\n",
      "  -1.25468885e-02 -2.22845406e-01  4.50344013e-02 -3.23343465e-01]\n",
      " [ 1.03433325e-02  1.36848299e-02  6.89330157e-03  1.77691794e-01\n",
      "  -4.49335753e-01  3.06204529e-01  5.68523295e-02 -5.58029533e-02\n",
      "  -2.69422047e-01  0.00000000e+00  6.08541117e-01 -3.28207014e-01\n",
      "  -1.76308093e-02 -1.82377802e-01  1.36974509e-02 -1.14522690e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  2.52369638e-02\n",
      "  -1.44444267e-01  6.14629320e-02  3.44871212e-02  0.00000000e+00\n",
      "  -5.96844868e-02  0.00000000e+00  7.31867230e-02 -1.31284220e-01\n",
      "  -6.68930763e-03 -4.16681623e-02  0.00000000e+00 -7.08011739e-02]], shape=(32, 16), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/global_block/mlp_model_glob/layer1/b:0: tf.Tensor(\n",
      "[ 0.00086944 -0.00434284 -0.00228053 -0.         -0.01312887  0.\n",
      "  0.          0.01216927 -0.         -0.00363023 -0.0070853  -0.01376552\n",
      "  0.00838213  0.00279923 -0.          0.          0.01121381 -0.01123865\n",
      "  0.         -0.          0.0268172   0.          0.02145591 -0.\n",
      " -0.          0.          0.         -0.01979441  0.02370049  0.00801879\n",
      "  0.00599552 -0.        ], shape=(32,), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/global_block/mlp_model_glob/layer1/w:0: tf.Tensor(\n",
      "[[ 0.00000000e+00 -8.69318921e-08 -1.93714435e-07 ...  0.00000000e+00\n",
      "   2.44380192e-07  0.00000000e+00]\n",
      " [ 0.00000000e+00 -3.94981674e-05 -1.78771206e-05 ...  0.00000000e+00\n",
      "   5.07325197e-05  0.00000000e+00]\n",
      " [ 0.00000000e+00 -6.87480826e-05  8.66936859e-06 ...  0.00000000e+00\n",
      "   5.40955149e-05  0.00000000e+00]\n",
      " ...\n",
      " [ 0.00000000e+00 -9.99796941e-05 -3.24246475e-07 ...  0.00000000e+00\n",
      "   8.97892632e-05  0.00000000e+00]\n",
      " [ 1.11142539e-04 -6.44971092e-04 -3.14177036e-04 ...  1.02505592e-03\n",
      "   8.66307532e-04  0.00000000e+00]\n",
      " [ 4.34722055e-04 -2.17141816e-03 -1.14026618e-03 ...  4.00939569e-03\n",
      "   2.99776015e-03  0.00000000e+00]], shape=(33, 32), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/global_block/mlp_model_glob/layer2/b:0: tf.Tensor(\n",
      "[ 0.         -0.          0.03789878 -0.          0.03213768 -0.03851742\n",
      " -0.01727653  0.01246578 -0.          0.0269959  -0.00530554 -0.\n",
      " -0.         -0.04105748 -0.00315291  0.01233833  0.          0.\n",
      "  0.          0.          0.         -0.         -0.          0.04008692\n",
      "  0.03915734 -0.00094258  0.          0.01910256  0.          0.00832515\n",
      " -0.         -0.03595104], shape=(32,), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/global_block/mlp_model_glob/layer2/w:0: tf.Tensor(\n",
      "[[ 0.          0.          0.00020605 ...  0.          0.\n",
      "  -0.00019546]\n",
      " [ 0.          0.          0.00554094 ...  0.00034091  0.\n",
      "  -0.00525618]\n",
      " [ 0.          0.          0.00116965 ...  0.00023422  0.\n",
      "  -0.00110954]\n",
      " ...\n",
      " [ 0.          0.          0.0015383  ...  0.          0.\n",
      "  -0.00145924]\n",
      " [ 0.          0.          0.01169214 ...  0.00320131  0.\n",
      "  -0.01109125]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]], shape=(32, 32), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/node_block/mlp_model_enc/layer1/b:0: tf.Tensor(\n",
      "[ 0.15529091 -0.13056875 -0.07055314  0.15327418  0.         -0.02399535\n",
      " -0.01076772 -0.0357456  -0.06470705 -0.06027705  0.         -0.07079099\n",
      "  0.02318536 -0.12964115  0.          0.01628855  0.          0.\n",
      "  0.11428826  0.          0.07739749  0.16128892 -0.01132324  0.01979699\n",
      "  0.16525525  0.44046801  0.          0.01807096 -0.00543056 -0.30937605\n",
      "  0.06558663 -0.1165478 ], shape=(32,), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/node_block/mlp_model_enc/layer1/w:0: tf.Tensor(\n",
      "[[ 0.00000000e+00  3.58712823e-06 -1.46374069e-07  5.86357027e-07\n",
      "   0.00000000e+00 -2.53747949e-06  0.00000000e+00  9.09565687e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.12769962e-06\n",
      "   0.00000000e+00 -1.69802327e-06  0.00000000e+00  3.79749755e-07\n",
      "   0.00000000e+00  0.00000000e+00 -6.69097194e-08  0.00000000e+00\n",
      "   2.79243465e-06  0.00000000e+00  0.00000000e+00  9.71541771e-07\n",
      "   0.00000000e+00 -6.93389618e-07  0.00000000e+00  0.00000000e+00\n",
      "   1.70447903e-07 -3.79436817e-08  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  9.24649912e-04  2.96909937e-07  9.68431445e-05\n",
      "   0.00000000e+00 -5.86433006e-04  0.00000000e+00 -3.29282700e-05\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.72924221e-04\n",
      "   0.00000000e+00 -4.02410391e-04  0.00000000e+00  6.21804875e-05\n",
      "   0.00000000e+00  0.00000000e+00  5.13997168e-05  0.00000000e+00\n",
      "   7.44351029e-04  0.00000000e+00  0.00000000e+00  2.53908828e-04\n",
      "   0.00000000e+00 -1.92597851e-04  0.00000000e+00  0.00000000e+00\n",
      "  -2.86877426e-06  8.49026416e-06  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  1.20937916e-03  3.84099910e-05  7.23712818e-05\n",
      "   0.00000000e+00 -6.99374854e-04  0.00000000e+00 -9.94331820e-05\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.39207465e-04\n",
      "   0.00000000e+00 -4.91043797e-04  0.00000000e+00  4.56262464e-05\n",
      "   0.00000000e+00  0.00000000e+00  1.35863581e-04  0.00000000e+00\n",
      "   9.98105022e-04  0.00000000e+00  0.00000000e+00  3.35570548e-04\n",
      "   0.00000000e+00 -2.65766326e-04  0.00000000e+00  0.00000000e+00\n",
      "  -5.05497941e-05  2.93728008e-05  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00274039e-02 -8.72718229e-03 -1.02411409e-02  3.54311589e-02\n",
      "   0.00000000e+00 -3.50890486e-04 -1.16255111e-03  1.25777547e-05\n",
      "  -5.09520609e-03 -7.57778569e-04  0.00000000e+00 -1.01110606e-02\n",
      "   2.28668632e-03 -4.29877650e-03  0.00000000e+00  5.96803006e-03\n",
      "   0.00000000e+00  0.00000000e+00  3.98078269e-03  0.00000000e+00\n",
      "   1.28796415e-02  1.11044377e-02 -3.96775780e-03  1.34347791e-04\n",
      "   8.39865981e-03  3.20195202e-02  0.00000000e+00 -4.41612687e-03\n",
      "  -9.59199383e-04 -3.67438407e-02  6.80286180e-03 -7.21054952e-04]\n",
      " [ 2.26579187e-02 -2.67847382e-02 -4.35816873e-03  7.00712273e-03\n",
      "   0.00000000e+00 -1.44736399e-03 -3.12525789e-03 -2.59400391e-03\n",
      "  -1.12157268e-02 -9.07434394e-03  0.00000000e+00 -2.86692254e-03\n",
      "   5.43680023e-03 -1.10274345e-02  0.00000000e+00 -3.40312395e-04\n",
      "   0.00000000e+00  0.00000000e+00  7.15063996e-03  0.00000000e+00\n",
      "   3.16879259e-03  2.22752266e-02 -4.29358405e-04  1.32829047e-03\n",
      "   2.22897059e-02  5.02560899e-02  0.00000000e+00  4.65685276e-03\n",
      "  -4.68107388e-04 -3.15742551e-02  1.55520686e-02 -2.33332213e-02]\n",
      " [ 4.06337746e-02 -5.44623625e-02 -1.52450006e-02  3.49339032e-02\n",
      "   0.00000000e+00  2.45942914e-03 -3.14046475e-03 -6.77805393e-03\n",
      "  -1.75790318e-02 -1.92412712e-02  0.00000000e+00 -1.64172860e-02\n",
      "   6.57678621e-03 -2.49527542e-02  0.00000000e+00  8.96240121e-03\n",
      "   0.00000000e+00  0.00000000e+00  2.66427773e-02  0.00000000e+00\n",
      "   1.21587099e-02  4.27876811e-02 -1.44893664e-03  7.11786816e-04\n",
      "   4.15273379e-02  1.20521928e-01  0.00000000e+00  5.68157638e-03\n",
      "  -5.61291721e-04 -7.92490409e-02  1.87596068e-02 -3.32958807e-02]\n",
      " [ 4.65677460e-03 -6.01034618e-03 -1.94773173e-04  7.93109146e-04\n",
      "   0.00000000e+00 -1.30733517e-04 -2.90575774e-04 -4.49337642e-05\n",
      "  -2.14401658e-03 -2.88804922e-03  0.00000000e+00 -4.58202690e-04\n",
      "   6.66295213e-04 -1.01556195e-03  0.00000000e+00  4.30459214e-04\n",
      "   0.00000000e+00  0.00000000e+00  2.34557507e-03  0.00000000e+00\n",
      "   7.78022821e-04  5.68809222e-03  0.00000000e+00  7.70747202e-05\n",
      "   3.71073376e-03  1.14401953e-02  0.00000000e+00  1.43339536e-03\n",
      "  -4.94189155e-05 -6.93432583e-03  1.81152294e-03 -5.09767477e-03]\n",
      " [ 0.00000000e+00  4.90842064e-03  1.61295965e-04  2.86011391e-04\n",
      "   0.00000000e+00 -2.82888894e-03  0.00000000e+00 -4.11573630e-04\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.37419297e-03\n",
      "   0.00000000e+00 -1.98794969e-03  0.00000000e+00  1.80105652e-04\n",
      "   0.00000000e+00  0.00000000e+00  5.61175182e-04  0.00000000e+00\n",
      "   4.05442599e-03  0.00000000e+00  0.00000000e+00  1.36245009e-03\n",
      "   0.00000000e+00 -1.08061692e-03  0.00000000e+00  0.00000000e+00\n",
      "  -2.11814260e-04  1.21809763e-04  0.00000000e+00  0.00000000e+00]\n",
      " [ 3.05747779e-02 -3.36257130e-02 -9.69618477e-03  1.51844168e-02\n",
      "   0.00000000e+00 -1.78409466e-03 -2.07947299e-03 -6.24958256e-03\n",
      "  -1.28503497e-02 -1.48720924e-02  0.00000000e+00 -8.31651292e-03\n",
      "   4.55790804e-03 -2.11655180e-02  0.00000000e+00  2.07674893e-03\n",
      "   0.00000000e+00  0.00000000e+00  2.18563041e-02  0.00000000e+00\n",
      "   7.51364468e-03  3.22639662e-02 -6.07744774e-05  2.43933110e-03\n",
      "   3.18332550e-02  8.36790771e-02  0.00000000e+00  6.42019284e-03\n",
      "  -7.29691990e-04 -5.11964555e-02  1.27384373e-02 -2.78295095e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.88926413e-02 -1.76956666e-02 -8.00300064e-03  2.17396448e-02\n",
      "   0.00000000e+00 -1.84657385e-03 -1.90555300e-03 -2.31967170e-03\n",
      "  -8.80919530e-03 -5.73549855e-03  0.00000000e+00 -6.99644561e-03\n",
      "   3.70551679e-03 -1.05890434e-02  0.00000000e+00  1.16417826e-03\n",
      "   0.00000000e+00  0.00000000e+00  8.64608883e-03  0.00000000e+00\n",
      "   7.95126827e-03  1.98849546e-02 -2.62864167e-03  1.41120027e-03\n",
      "   1.82065156e-02  4.84543189e-02  0.00000000e+00  1.23176751e-03\n",
      "  -7.17513215e-04 -3.84607358e-02  1.05915614e-02 -1.39006968e-02]\n",
      " [ 1.02625399e-02 -1.51944750e-02 -2.34107466e-03  1.07032224e-02\n",
      "   0.00000000e+00  0.00000000e+00 -6.45079730e-05  0.00000000e+00\n",
      "  -4.39888997e-03 -7.97121138e-03  0.00000000e+00 -6.29243913e-03\n",
      "   1.02112760e-03 -2.51900444e-03  0.00000000e+00  6.47367995e-03\n",
      "   0.00000000e+00  0.00000000e+00  8.08726687e-03  0.00000000e+00\n",
      "   7.91779376e-03  1.36521558e-02 -4.74692268e-05  0.00000000e+00\n",
      "   7.71742811e-03  3.50897319e-02  0.00000000e+00  1.68873157e-03\n",
      "  -6.77899286e-05 -2.36033208e-02  2.81311174e-03 -8.38026532e-03]\n",
      " [ 3.95115326e-02 -3.12833878e-02 -2.50777346e-02  4.33238719e-02\n",
      "   0.00000000e+00 -3.49230880e-03 -3.21696658e-03 -1.28355858e-02\n",
      "  -1.56610941e-02 -8.47942531e-03  0.00000000e+00 -1.49437168e-02\n",
      "   6.30053262e-03 -4.12929859e-02  0.00000000e+00 -3.95440686e-03\n",
      "   0.00000000e+00  0.00000000e+00  2.96934040e-02  0.00000000e+00\n",
      "   8.32632163e-03  3.62787750e-02 -4.31202517e-03  4.66365272e-03\n",
      "   4.83557277e-02  1.10534955e-01  0.00000000e+00  2.72261092e-03\n",
      "  -1.14910749e-03 -7.87952372e-02  1.79438626e-02 -2.56484809e-02]\n",
      " [ 2.96105614e-02 -3.14008019e-02 -1.23599227e-02  3.45291613e-02\n",
      "   0.00000000e+00 -1.65757245e-03 -2.35303432e-03 -2.85906190e-03\n",
      "  -1.35378521e-02 -1.15585888e-02  0.00000000e+00 -1.14287934e-02\n",
      "   5.18784230e-03 -1.40473106e-02  0.00000000e+00  4.76747764e-03\n",
      "   0.00000000e+00  0.00000000e+00  1.59255851e-02  0.00000000e+00\n",
      "   1.34475873e-02  3.29222439e-02 -3.38159334e-03  1.46679118e-03\n",
      "   2.72728985e-02  8.06709470e-02  0.00000000e+00  2.07799807e-03\n",
      "  -1.10690415e-03 -6.24719368e-02  1.47361338e-02 -2.17847779e-02]\n",
      " [ 7.43664647e-03 -5.51123188e-03 -5.72231955e-03  1.85315779e-02\n",
      "   0.00000000e+00  0.00000000e+00 -7.80841739e-04  0.00000000e+00\n",
      "  -3.70694434e-03  1.25829890e-04  0.00000000e+00 -3.08946553e-03\n",
      "   1.56848283e-03 -1.89931624e-03  0.00000000e+00 -2.68609203e-04\n",
      "   0.00000000e+00  0.00000000e+00  1.84610970e-03  0.00000000e+00\n",
      "   3.59707258e-03  8.40830245e-03 -2.98668382e-03  0.00000000e+00\n",
      "   6.16676270e-03  1.82599215e-02  0.00000000e+00 -1.64120612e-03\n",
      "  -6.21981712e-04 -2.14490513e-02  4.50465648e-03 -2.33596080e-03]\n",
      " [ 5.56248998e-03 -5.91742014e-03 -2.30422279e-03  1.08049318e-02\n",
      "   0.00000000e+00 -1.00028593e-03 -1.31160164e-03 -3.43803282e-04\n",
      "  -3.19952791e-03 -1.68303583e-03  0.00000000e+00 -5.42314259e-03\n",
      "   1.77524012e-03 -3.97315361e-03  0.00000000e+00  3.81511956e-03\n",
      "   0.00000000e+00  0.00000000e+00  7.08989842e-04  0.00000000e+00\n",
      "   7.46584699e-03  4.86956721e-03 -8.55187864e-04  5.89724504e-04\n",
      "   5.19234657e-03  1.46892386e-02  0.00000000e+00 -6.67688676e-04\n",
      "  -3.26058476e-04 -1.35118717e-02  5.30854153e-03 -4.14637036e-03]\n",
      " [ 1.16789573e-01 -2.25232544e-01  1.72018726e-03  1.12302168e-01\n",
      "   0.00000000e+00  2.39953485e-02 -1.07677205e-02  3.57456022e-02\n",
      "  -6.47070543e-02 -8.02125591e-02  0.00000000e+00 -3.07679031e-02\n",
      "   2.31853613e-02  5.83030688e-02  0.00000000e+00  6.16703691e-02\n",
      "   0.00000000e+00  0.00000000e+00  1.00251612e-02  0.00000000e+00\n",
      "   4.63954650e-02  1.61288924e-01 -1.13232391e-02 -1.97969851e-02\n",
      "   5.50082471e-02  3.04863820e-01  0.00000000e+00  1.80709596e-02\n",
      "   5.33813410e-04 -2.42844237e-01  6.55866270e-02 -1.16547804e-01]\n",
      " [ 1.55290910e-01 -2.08722686e-01 -3.84026605e-02  1.62164600e-02\n",
      "   0.00000000e+00  1.72642722e-02 -1.07677205e-02 -2.98795415e-02\n",
      "  -6.47070543e-02 -6.87342620e-02  0.00000000e+00  0.00000000e+00\n",
      "   2.31853613e-02 -8.74276755e-02  0.00000000e+00 -2.53826288e-02\n",
      "   0.00000000e+00  0.00000000e+00  9.61449664e-02  0.00000000e+00\n",
      "  -4.33821937e-02  1.61288924e-01  0.00000000e+00  0.00000000e+00\n",
      "   1.65255255e-01  3.96591059e-01  0.00000000e+00  4.45487109e-02\n",
      "   0.00000000e+00 -2.15956713e-01  6.38201760e-02 -1.54474738e-01]\n",
      " [ 0.00000000e+00 -7.81539377e-02  3.21504782e-02 -1.37057716e-01\n",
      "   0.00000000e+00  4.12596207e-02  0.00000000e+00  5.86606074e-03\n",
      "   0.00000000e+00 -8.45721133e-03  0.00000000e+00  7.07909931e-02\n",
      "   0.00000000e+00  4.22134707e-02  0.00000000e+00 -4.16711813e-02\n",
      "   0.00000000e+00  0.00000000e+00 -1.81432911e-02  0.00000000e+00\n",
      "  -1.20779686e-01  0.00000000e+00  1.13232391e-02 -1.97969851e-02\n",
      "   0.00000000e+00 -4.38769500e-02  0.00000000e+00  2.64777513e-02\n",
      "   5.43055698e-03  9.34193417e-02 -1.76645092e-03 -3.79269341e-02]\n",
      " [ 7.76454552e-02 -6.52843740e-02 -3.52765694e-02  7.66370878e-02\n",
      "   0.00000000e+00 -1.19976743e-02 -5.38386027e-03 -1.78728011e-02\n",
      "  -3.23535271e-02 -3.01385253e-02  0.00000000e+00 -3.53954965e-02\n",
      "   1.15926806e-02 -6.48205731e-02  0.00000000e+00  8.14427624e-03\n",
      "   0.00000000e+00  0.00000000e+00  5.71441287e-02  0.00000000e+00\n",
      "   3.86987463e-02  8.06444619e-02 -5.66161956e-03  9.89849254e-03\n",
      "   8.26276274e-02  2.20234004e-01  0.00000000e+00  9.03547979e-03\n",
      "  -2.71527849e-03 -1.54688027e-01  3.27933135e-02 -5.82739018e-02]], shape=(20, 32), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/node_block/mlp_model_enc/layer2/b:0: tf.Tensor(\n",
      "[ 0.01390865 -0.0774872   0.05736495 -0.05184494 -0.17931865 -0.15901598\n",
      "  0.0638523  -0.31725776  0.         -0.38183263  0.25112191 -0.24621007\n",
      "  0.46039297  0.10999691  0.10877054 -0.14385109  0.10993764 -0.13213289\n",
      "  0.          0.         -0.00286867  0.15688934 -0.01886557 -0.02780021\n",
      " -0.02137895  0.29008935 -0.27977159  0.30963658  0.10258796 -0.05249104\n",
      " -0.13454577  0.21463782], shape=(32,), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/node_block/mlp_model_enc/layer2/w:0: tf.Tensor(\n",
      "[[ 0.         -0.01064656  0.00303387 ...  0.0017538  -0.01331732\n",
      "   0.01578405]\n",
      " [ 0.00478214 -0.00312531  0.00872225 ... -0.00744314 -0.0061779\n",
      "   0.01364182]\n",
      " [ 0.00032732 -0.00062474  0.02285319 ...  0.01156833  0.0153485\n",
      "  -0.00024825]\n",
      " ...\n",
      " [ 0.00311092 -0.02279635  0.01185945 ... -0.01227154 -0.0429898\n",
      "   0.06008619]\n",
      " [ 0.         -0.00875415  0.         ... -0.01122759 -0.01498378\n",
      "   0.02174568]\n",
      " [ 0.00272071 -0.00270609  0.         ... -0.00694768 -0.01275315\n",
      "   0.01635508]], shape=(32, 32), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/node_block/mlp_model_enc/layer3/b:0: tf.Tensor(\n",
      "[ 0.         -0.12212679  0.44046377  0.68885049 -0.01573918  0.04424478\n",
      "  0.06128963 -0.08768595 -0.30401326  0.         -0.12593628  0.45730567\n",
      "  0.14806602  0.22790411  0.25919898  0.4565188   0.07055529  0.67898924\n",
      " -0.28551347  0.         -0.0471476   0.77096799 -0.39864148  0.34625976\n",
      "  0.07418892  0.02932464 -0.17177443 -0.50727063 -0.23444128  0.\n",
      " -0.64183248  0.        ], shape=(32,), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/node_block/mlp_model_enc/layer3/w:0: tf.Tensor(\n",
      "[[ 0.00000000e+00  1.60058702e-04  0.00000000e+00 ...  0.00000000e+00\n",
      "  -8.01592082e-04  0.00000000e+00]\n",
      " [ 0.00000000e+00 -4.09637419e-02  1.03955719e-01 ...  0.00000000e+00\n",
      "  -6.17517456e-02  0.00000000e+00]\n",
      " [ 0.00000000e+00 -9.93995065e-03  3.82665951e-02 ...  0.00000000e+00\n",
      "  -8.63439140e-03  0.00000000e+00]\n",
      " ...\n",
      " [ 0.00000000e+00 -5.71371920e-02  1.61946756e-01 ...  0.00000000e+00\n",
      "  -1.30488359e-01  0.00000000e+00]\n",
      " [ 0.00000000e+00  2.30133376e-03  6.96928908e-02 ...  0.00000000e+00\n",
      "  -6.28334692e-02  0.00000000e+00]\n",
      " [ 0.00000000e+00 -3.10568917e-02  7.90110619e-03 ...  0.00000000e+00\n",
      "  -6.12055389e-02  0.00000000e+00]], shape=(32, 32), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/node_block/mlp_model_enc/layer4/b:0: tf.Tensor(\n",
      "[ 0.22981385 -0.48781665  0.         -1.45397559  1.38816722 -0.15440255\n",
      " -0.24350079 -0.40184258 -0.41525843  2.39815972 -0.68439747  0.\n",
      "  0.          0.01336277  0.04224724  0.36991178], shape=(16,), dtype=float64)\n",
      "Gradient for gnn_double_output/graph_network/node_block/mlp_model_enc/layer4/w:0: tf.Tensor(\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.91846564e-02 -6.52224968e-02  0.00000000e+00 -1.32169587e-01\n",
      "   7.66318914e-02 -1.39058253e-02 -2.57620077e-02 -2.41379662e-02\n",
      "  -3.73448307e-02  2.15675105e-01 -4.59614102e-02  0.00000000e+00\n",
      "   0.00000000e+00  1.27533844e-03  1.46780246e-03  4.61463758e-02]\n",
      " [ 2.53915372e-03  0.00000000e+00  0.00000000e+00 -2.05737697e-02\n",
      "   3.26100451e-02 -2.20465491e-03 -1.84752873e-03 -1.11019129e-02\n",
      "  -5.97782167e-03  3.45640805e-02 -1.51058956e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.67649779e-03  1.95663399e-03]\n",
      " [ 3.42213239e-02 -4.46950639e-02  0.00000000e+00 -2.44363137e-01\n",
      "   2.82037077e-01 -3.06772194e-02 -3.13116482e-02 -1.35996946e-01\n",
      "  -8.25333308e-02  4.77575405e-01 -2.07496404e-01  0.00000000e+00\n",
      "   0.00000000e+00  2.17564650e-03  1.36708331e-02  7.21164014e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.47542727e-02\n",
      "   5.50272609e-02 -5.19262239e-03  0.00000000e+00 -4.01493295e-02\n",
      "  -1.39767370e-02  8.10827644e-02 -5.47060205e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  4.93097330e-03  1.03578356e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.08578787e-03\n",
      "   1.71941104e-03 -9.24341545e-05  0.00000000e+00 -7.43038918e-04\n",
      "  -2.56436374e-04  1.48651174e-03 -1.00160951e-03  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.56753372e-04  0.00000000e+00]\n",
      " [ 8.51692556e-03 -3.11544878e-02  0.00000000e+00 -1.46013557e-01\n",
      "   1.65788255e-01 -1.78622887e-02 -1.37545738e-02 -9.36133885e-02\n",
      "  -4.81121118e-02  2.78507030e-01 -1.31416780e-01  0.00000000e+00\n",
      "   0.00000000e+00  3.82511838e-04  1.14729421e-02  4.17441932e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.90178841e-04\n",
      "   1.09684816e-03 -6.21647932e-05 -1.39945426e-04  0.00000000e+00\n",
      "  -1.66554043e-04  9.52929036e-04  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 6.16461929e-03  0.00000000e+00  0.00000000e+00 -1.47872313e-02\n",
      "   2.34539655e-02 -1.30360928e-03 -3.12232288e-03  0.00000000e+00\n",
      "  -3.52195830e-03  2.02972799e-02 -2.84385426e-03  0.00000000e+00\n",
      "   0.00000000e+00  2.77251576e-04  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 2.74684614e-02 -2.21171493e-02  0.00000000e+00 -1.19058592e-01\n",
      "   1.30574623e-01 -1.25422832e-02 -2.01582025e-02 -3.21613824e-02\n",
      "  -3.37381677e-02  1.95037044e-01 -6.07525900e-02  0.00000000e+00\n",
      "   0.00000000e+00  1.65652627e-03  3.42904007e-03  2.53508188e-02]\n",
      " [ 0.00000000e+00 -4.36931824e-02  0.00000000e+00 -5.04291280e-02\n",
      "   0.00000000e+00 -7.35396907e-03 -1.06151840e-02 -2.24259027e-02\n",
      "  -1.98233086e-02  1.14507089e-01 -3.05433096e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  3.53161160e-02]\n",
      " [ 1.62304557e-03 -1.38615166e-01  0.00000000e+00 -1.83226839e-01\n",
      "   2.91902463e-02 -1.91549646e-02 -3.84780613e-02 -2.25509674e-02\n",
      "  -5.15307477e-02  2.97080328e-01 -3.07134327e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  8.39015080e-02]\n",
      " [ 1.44462908e-03 -1.74180827e-02  0.00000000e+00 -2.32287328e-02\n",
      "   6.14493103e-03 -5.55632009e-03 -4.88016383e-03 -2.70129671e-02\n",
      "  -1.49428094e-02  8.64552831e-02 -3.75630621e-02  0.00000000e+00\n",
      "   0.00000000e+00  7.26887900e-05  0.00000000e+00  2.49890551e-02]\n",
      " [ 0.00000000e+00 -2.03472573e-02  0.00000000e+00 -2.24856130e-02\n",
      "   0.00000000e+00 -1.98980125e-03 -4.72526204e-03  0.00000000e+00\n",
      "  -5.36197649e-03  3.08776831e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  9.54600438e-03]\n",
      " [ 5.32145859e-03 -2.38257325e-02  0.00000000e+00 -7.30592221e-02\n",
      "   6.36574358e-02 -1.05645790e-02 -8.44890593e-03 -5.44428185e-02\n",
      "  -2.83771254e-02  1.64365521e-01 -8.04976471e-02  0.00000000e+00\n",
      "   0.00000000e+00  6.18181176e-04  4.72259449e-03  3.37521592e-02]\n",
      " [ 0.00000000e+00 -2.96519699e-03  0.00000000e+00 -9.67996710e-03\n",
      "   9.30058478e-03 -2.02683222e-03 -8.07650343e-04 -1.31020571e-02\n",
      "  -5.47131018e-03  3.17049846e-02 -1.78591992e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  8.32418976e-04  7.29229341e-03]\n",
      " [ 1.29557172e-03 -5.28027590e-02  0.00000000e+00 -1.08056420e-01\n",
      "   7.21184851e-02 -1.42712390e-02 -1.59926380e-02 -5.81762186e-02\n",
      "  -3.84524674e-02  2.22241192e-01 -7.92072284e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  4.51012784e-03  4.93130037e-02]\n",
      " [ 7.95544031e-03 -3.85450697e-02  0.00000000e+00 -1.16217177e-01\n",
      "   1.14160981e-01 -1.37666545e-02 -1.31383287e-02 -6.39253580e-02\n",
      "  -3.70937264e-02  2.14599300e-01 -9.19886046e-02  0.00000000e+00\n",
      "   0.00000000e+00  4.83622121e-04  7.65241865e-03  3.58106387e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 3.76472643e-03 -1.57254256e-02  0.00000000e+00 -2.21195850e-02\n",
      "   7.72914641e-03 -1.95435069e-03 -4.68326752e-03  0.00000000e+00\n",
      "  -5.25741454e-03  3.03241709e-02 -2.86389646e-03  0.00000000e+00\n",
      "   0.00000000e+00  2.79205519e-04  0.00000000e+00  7.31986444e-03]\n",
      " [ 1.62771650e-03 -8.19797526e-02  0.00000000e+00 -1.47565724e-01\n",
      "   7.25869019e-02 -2.03360058e-02 -2.24932073e-02 -8.42944709e-02\n",
      "  -5.47327231e-02  3.16546767e-01 -1.16020752e-01  0.00000000e+00\n",
      "   0.00000000e+00  1.19174307e-04  5.80623286e-03  7.82956676e-02]\n",
      " [ 9.60591677e-03  0.00000000e+00  0.00000000e+00 -2.50228540e-02\n",
      "   3.96466582e-02 -2.21089375e-03 -3.68598947e-03 -5.21995052e-03\n",
      "  -5.90623864e-03  3.41765276e-02 -1.46199893e-02  0.00000000e+00\n",
      "   0.00000000e+00  7.31598334e-04  1.09729478e-03  0.00000000e+00]\n",
      " [ 6.41384261e-03  0.00000000e+00  0.00000000e+00 -2.74918220e-02\n",
      "   4.35470842e-02 -2.40304034e-03 -2.41914256e-03 -1.09558131e-02\n",
      "  -6.48454493e-03  3.75575451e-02 -1.91906484e-02  0.00000000e+00\n",
      "   0.00000000e+00  4.19516950e-04  2.30537612e-03  0.00000000e+00]\n",
      " [ 0.00000000e+00 -2.35403521e-02  0.00000000e+00 -2.96616263e-02\n",
      "   0.00000000e+00 -2.62372455e-03 -6.25936270e-03  0.00000000e+00\n",
      "  -7.05926861e-03  4.06897500e-02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.25710832e-02]\n",
      " [ 0.00000000e+00 -1.11876398e-02  0.00000000e+00 -6.95827761e-02\n",
      "   9.00605231e-02 -1.11968806e-02 -2.67188668e-03 -7.81664228e-02\n",
      "  -3.02167250e-02  1.75158304e-01 -1.06398114e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  8.08925936e-03  3.00195662e-02]\n",
      " [ 0.00000000e+00 -4.48294552e-02  0.00000000e+00 -1.04296335e-01\n",
      "   7.99048851e-02 -1.65066447e-02 -1.13425134e-02 -9.10309773e-02\n",
      "  -4.44913965e-02  2.57595675e-01 -1.23947911e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  7.17255509e-03  5.81441565e-02]\n",
      " [ 3.05865856e-03  0.00000000e+00  0.00000000e+00 -4.87836852e-02\n",
      "   7.28852302e-02 -8.59993415e-03 -4.13802852e-03 -5.28225836e-02\n",
      "  -2.31498100e-02  1.34042550e-01 -7.29724855e-02  0.00000000e+00\n",
      "   0.00000000e+00  9.68859236e-05  4.09929223e-03  2.18576037e-02]\n",
      " [ 8.27700385e-03  0.00000000e+00  0.00000000e+00 -6.86747504e-02\n",
      "   1.08826364e-01 -8.17722496e-03 -5.41498510e-03 -4.56652500e-02\n",
      "  -2.20680643e-02  1.27718878e-01 -6.58282974e-02  0.00000000e+00\n",
      "   0.00000000e+00  3.57628120e-04  6.08504554e-03  1.03785349e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.97214955e-02 -1.26907184e-01  0.00000000e+00 -2.78673729e-01\n",
      "   1.85437831e-01 -3.01402554e-02 -4.47345087e-02 -8.78887832e-02\n",
      "  -8.10636172e-02  4.68376166e-01 -1.32355002e-01  0.00000000e+00\n",
      "   0.00000000e+00  1.23527885e-03  9.45114817e-03  9.51310353e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]], shape=(32, 16), dtype=float64)\n",
      "Gradient for gnn_double_output/global_transform/b:0: tf.Tensor([2.9526042 0.       ], shape=(2,), dtype=float64)\n",
      "Gradient for gnn_double_output/global_transform/w:0: tf.Tensor(\n",
      "[[0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.01314949 0.        ]\n",
      " [0.         0.        ]\n",
      " [0.00166326 0.        ]\n",
      " [0.02582604 0.        ]\n",
      " [0.00687789 0.        ]\n",
      " [0.06367457 0.        ]\n",
      " [0.         0.        ]\n",
      " [0.00973802 0.        ]\n",
      " [0.09142929 0.        ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.00976026 0.        ]\n",
      " [0.05237602 0.        ]\n",
      " [0.01610935 0.        ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.         0.        ]\n",
      " [0.04091859 0.        ]\n",
      " [0.01533353 0.        ]\n",
      " [0.02415899 0.        ]\n",
      " [0.         0.        ]\n",
      " [0.02105671 0.        ]\n",
      " [0.         0.        ]\n",
      " [0.00207056 0.        ]\n",
      " [0.         0.        ]\n",
      " [0.00586725 0.        ]], shape=(32, 2), dtype=float64)\n",
      "Gradient for gnn_double_output/linear_pool/b:0: tf.Tensor([2.9526042 0.       ], shape=(2,), dtype=float64)\n",
      "Gradient for gnn_double_output/linear_pool/w:0: tf.Tensor(\n",
      "[[8.78273304e-03 0.00000000e+00]\n",
      " [8.24342786e-03 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [4.97260597e-01 0.00000000e+00]\n",
      " [3.54635809e-01 0.00000000e+00]\n",
      " [1.66251398e+00 0.00000000e+00]\n",
      " [6.14731917e-01 0.00000000e+00]\n",
      " [4.52802365e-01 0.00000000e+00]\n",
      " [8.28491772e-01 0.00000000e+00]\n",
      " [1.26393072e+00 0.00000000e+00]\n",
      " [1.75585826e-01 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [1.47300577e-02 0.00000000e+00]\n",
      " [5.37439695e-02 0.00000000e+00]\n",
      " [4.33632746e-01 0.00000000e+00]\n",
      " [1.15190767e-04 0.00000000e+00]\n",
      " [2.75140201e-02 0.00000000e+00]\n",
      " [3.38082345e-02 0.00000000e+00]\n",
      " [1.33688628e+00 0.00000000e+00]\n",
      " [1.03980750e+00 0.00000000e+00]\n",
      " [2.47053789e+00 0.00000000e+00]\n",
      " [1.63580635e-01 0.00000000e+00]\n",
      " [1.36905466e-01 0.00000000e+00]\n",
      " [1.72227019e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00]\n",
      " [1.37620635e+00 0.00000000e+00]\n",
      " [6.16833660e-01 0.00000000e+00]\n",
      " [3.24054684e+00 0.00000000e+00]\n",
      " [2.07920816e+00 0.00000000e+00]\n",
      " [7.55608159e-01 0.00000000e+00]\n",
      " [5.27584623e-01 0.00000000e+00]], shape=(32, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(gnn.trainable_variables)\n",
    "    psi = compute_wave_function_sparse_tensor(graph_tuples_batch[0:3], gnn, configurations[0:3], system_dim=2**4)\n",
    "    psi=tf.sparse.reorder(psi)\n",
    "    #print(psi)\n",
    "    psi_dense = tf.sparse.to_dense(psi)\n",
    "    #dummy_loss = tf.reduce_mean(tf.square(psi_dense - tf.ones_like(psi_dense)))\n",
    "gradients = tape.gradient(psi_dense, gnn.trainable_variables)\n",
    "optimizer.apply_gradients(zip(gradients, gnn.trainable_variables))\n",
    "\n",
    "for grad, var in zip(gradients, gnn.trainable_variables):\n",
    "    print(f\"Gradient for {var.name}:\", grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dcf4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"psi_norm:\", [(i, psi_tensor[i]) for i in range(len(eigenvector)) if psi_tensor[i]/norm > 0.0003])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111144dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import eigs, eigsh\n",
    "#eigenvalue, eigenvector = eigsh(H, k=1, which='LM')\n",
    "\n",
    "# Find the smallest eigenvalue and its corresponding eigenvector\n",
    "# 'SM' means smallest magnitude\n",
    "eigenvalue, eigenvector = eigsh(H, k=1, which='SM')\n",
    "\n",
    "# For non-Hermitian matrices, use eigs\n",
    "#eigenvalue, eigenvector = eigs(H, k=1, which='LM')\n",
    "\n",
    "print(\"Eigenvalue:\", eigenvalue)\n",
    "print(\"Eigenvector:\", [(i, eigenvector[i]) for i in range(len(eigenvector)) if eigenvector[i] > 0.03])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359f43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_eigen = np.linalg.norm(eigenvector)\n",
    "#print(norm_eigen)\n",
    "sparse_eigenvector_tensor = tf.sparse.from_dense(eigenvector_tensor)\n",
    "\n",
    "eigenvector_tensor = tf.convert_to_tensor(eigenvector, dtype=tf.complex64)  # or tf.complex64 if your eigenvector is complex\n",
    "#print(sparse_eigenvector_tensor, psi_tensor)\n",
    "loss=compute_loss(psi_tensor, sparse_eigenvector_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52a33bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "psi_csr = compute_wave_function_csr(graph_tuples[start:start + batch_size], gnn, configurations)\n",
    "beta = 0.05\n",
    "phi_csr = psi_csr - beta * H.dot(psi_csr)\n",
    "phi_sparse_coo = phi_csr.tocoo()\n",
    "indices = np.column_stack((phi_sparse_coo.row, phi_sparse_coo.col))\n",
    "phi_sparse_tf = tf.cast(tf.sparse.SparseTensor(indices, phi_sparse_coo.data, phi_sparse_coo.shape), dtype=tf.complex64)\n",
    "\n",
    "for _ in range(5):  # Inner loop iterations: here we let psi approximate its ITO phi\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(gnn.trainable_variables)\n",
    "        start_time=time.time()\n",
    "        psi = compute_wave_function_sparse_tensor_u2(graph_tuples[start:start + batch_size], gnn, configurations)\n",
    "        print(\"Elapsed time\", time.time()-start_time)\n",
    "        loss= compute_loss(psi,psi)\n",
    "        print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphNet2",
   "language": "python",
   "name": "graphnet2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
